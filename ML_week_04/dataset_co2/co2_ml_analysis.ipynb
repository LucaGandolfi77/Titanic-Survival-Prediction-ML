{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ Global COâ‚‚ Emissions â€“ Comprehensive ML Analysis\n",
    "\n",
    "**Dataset:** Our World in Data â€“ Global COâ‚‚ and Greenhouse Gas Emissions (1750â€“2021)\n",
    "\n",
    "| Stat | Value |\n",
    "|---|---|\n",
    "| Rows | ~50,600 country-year records |\n",
    "| Columns | 79 features |\n",
    "| Countries | 278 (countries + aggregates) |\n",
    "| Period | 1750 â€“ 2021 |\n",
    "\n",
    "**ML Tasks:** COâ‚‚ Regression Â· Emission-Level Classification Â· Country Clustering Â· Growth-Rate Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, os, base64\n",
    "from io import BytesIO\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "    StratifiedKFold, GridSearchCV, RandomizedSearchCV, learning_curve)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report, roc_curve, auc,\n",
    "    mean_squared_error, mean_absolute_error, r2_score, silhouette_score)\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    VotingClassifier, StackingClassifier, AdaBoostClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "os.makedirs(\"outputs/plots\", exist_ok=True)\n",
    "\n",
    "report_images = {}\n",
    "results = {}          # classification results\n",
    "regression_results = {}\n",
    "growth_results = {}   # growth-rate regression\n",
    "\n",
    "def save_plot(fig, name):\n",
    "    \"\"\"Save figure to PNG and store base64 for the HTML report.\"\"\"\n",
    "    fig.savefig(f\"outputs/plots/{name}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=150, bbox_inches=\"tight\")\n",
    "    buf.seek(0)\n",
    "    report_images[name] = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    plt.close(fig)\n",
    "    print(f\"  \\u2713 {name}.png\")\n",
    "\n",
    "print(\"All imports successful\")\n",
    "print(f\"  scikit-learn {__import__('sklearn').__version__}\")\n",
    "print(f\"  pandas {pd.__version__}, numpy {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"CO2+Emissions/visualizing_global_co2_data.csv\"\n",
    "raw = pd.read_csv(DATA)\n",
    "print(f\"Raw dataset: {raw.shape[0]:,} rows x {raw.shape[1]} columns\")\n",
    "print(f\"Year range:  {raw['year'].min()} â€“ {raw['year'].max()}\")\n",
    "print(f\"Countries:   {raw['country'].nunique()}\")\n",
    "\n",
    "# Show missingness\n",
    "miss = raw.isnull().mean().sort_values(ascending=False)\n",
    "print(f\"\\nTop-15 missing-value columns (%):\")\n",
    "for c, v in miss.head(15).items():\n",
    "    print(f\"  {c:45s} {v*100:5.1f}%\")\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate actual countries from aggregates (continents, income groups, etc.)\n",
    "# Aggregates have no iso_code or iso_code in special codes\n",
    "aggregates = raw[raw[\"iso_code\"].isna() | raw[\"iso_code\"].str.startswith(\"OWID\")]\n",
    "countries  = raw[~raw.index.isin(aggregates.index)].copy()\n",
    "print(f\"Country rows: {len(countries):,}  |  Aggregate rows: {len(aggregates):,}\")\n",
    "print(f\"Unique countries: {countries['country'].nunique()}\")\n",
    "\n",
    "# Focus on modern era with enough data\n",
    "df = countries[countries[\"year\"] >= 1950].copy()\n",
    "print(f\"\\nFiltered to 1950+: {len(df):,} rows, {df['country'].nunique()} countries\")\n",
    "\n",
    "# Key columns for analysis\n",
    "core_cols = [\"country\",\"year\",\"iso_code\",\"population\",\"gdp\",\n",
    "             \"co2\",\"co2_per_capita\",\"coal_co2\",\"oil_co2\",\"gas_co2\",\n",
    "             \"cement_co2\",\"flaring_co2\",\"other_industry_co2\",\n",
    "             \"land_use_change_co2\",\"co2_including_luc\",\n",
    "             \"co2_growth_prct\",\"co2_per_gdp\",\n",
    "             \"primary_energy_consumption\",\"energy_per_capita\",\n",
    "             \"methane\",\"nitrous_oxide\",\"total_ghg\",\n",
    "             \"temperature_change_from_co2\",\"temperature_change_from_ghg\",\n",
    "             \"share_global_co2\",\"cumulative_co2\"]\n",
    "\n",
    "df = df[[c for c in core_cols if c in df.columns]].copy()\n",
    "print(f\"Selected {df.shape[1]} core columns\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum():,} total ({df.isnull().mean().mean()*100:.1f}% avg)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Feature Engineering\n",
    "\n",
    "Filter to 1950+, fill/drop missing values, and create derived features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with no CO2 value (our primary target)\n",
    "df = df.dropna(subset=[\"co2\"]).copy()\n",
    "print(f\"After dropping NaN co2: {len(df):,} rows\")\n",
    "\n",
    "# Fill GDP / population with 0 (will be excluded in models needing them)\n",
    "df[\"gdp\"] = df[\"gdp\"].fillna(0)\n",
    "df[\"population\"] = df[\"population\"].fillna(0)\n",
    "\n",
    "# Fill source-specific CO2 columns with 0 (no data = no emissions from that source)\n",
    "source_cols = [\"coal_co2\",\"oil_co2\",\"gas_co2\",\"cement_co2\",\"flaring_co2\",\n",
    "               \"other_industry_co2\",\"land_use_change_co2\"]\n",
    "for c in source_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(0)\n",
    "\n",
    "# ---- Feature Engineering ----\n",
    "# Fuel mix percentages\n",
    "total_fuel = df[\"coal_co2\"] + df[\"oil_co2\"] + df[\"gas_co2\"] + 0.001  # avoid /0\n",
    "df[\"coal_share\"] = df[\"coal_co2\"] / total_fuel\n",
    "df[\"oil_share\"]  = df[\"oil_co2\"]  / total_fuel\n",
    "df[\"gas_share\"]  = df[\"gas_co2\"]  / total_fuel\n",
    "\n",
    "# GDP per capita (where gdp and population > 0)\n",
    "df[\"gdp_per_capita\"] = np.where(df[\"population\"] > 0, df[\"gdp\"] / df[\"population\"], 0)\n",
    "\n",
    "# Decade\n",
    "df[\"decade\"] = (df[\"year\"] // 10) * 10\n",
    "\n",
    "# CO2 intensity (co2 per unit of energy, where available)\n",
    "df[\"co2_per_gdp\"] = df[\"co2_per_gdp\"].fillna(0)\n",
    "\n",
    "# Log-transform skewed targets\n",
    "df[\"log_co2\"] = np.log1p(df[\"co2\"])\n",
    "df[\"log_population\"] = np.log1p(df[\"population\"])\n",
    "\n",
    "# Emission level categories (for classification)\n",
    "co2_pc = df[\"co2_per_capita\"].fillna(0)\n",
    "df[\"emission_level\"] = pd.cut(co2_pc,\n",
    "    bins=[-np.inf, 1, 5, 15, np.inf],\n",
    "    labels=[\"Low\",\"Medium\",\"High\",\"Very High\"])\n",
    "\n",
    "print(f\"Final dataset: {df.shape}\")\n",
    "print(f\"\\nEmission Level distribution:\")\n",
    "print(df[\"emission_level\"].value_counts().sort_index())\n",
    "\n",
    "df.to_csv(\"outputs/co2_cleaned.csv\", index=False)\n",
    "print(\"\\nCleaned dataset saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Fig 1: Global CO2 over time ----\n",
    "global_ts = df.groupby(\"year\")[\"co2\"].sum().reset_index()\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ax.fill_between(global_ts[\"year\"], global_ts[\"co2\"], alpha=0.3, color=\"steelblue\")\n",
    "ax.plot(global_ts[\"year\"], global_ts[\"co2\"], color=\"steelblue\", linewidth=2)\n",
    "ax.set_title(\"Global CO\\u2082 Emissions Over Time (1950\\u20132021)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Year\"); ax.set_ylabel(\"CO\\u2082 (million tonnes)\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"global_co2_timeline\")\n",
    "\n",
    "# ---- Fig 2: Top 10 emitters (latest year) ----\n",
    "latest = df[df[\"year\"] == df[\"year\"].max()]\n",
    "top10 = latest.nlargest(10, \"co2\")\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "colors = sns.color_palette(\"viridis\", 10)\n",
    "bars = ax.barh(top10[\"country\"][::-1], top10[\"co2\"].values[::-1], color=colors)\n",
    "ax.set_title(f\"Top 10 CO\\u2082 Emitters ({df['year'].max()})\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"CO\\u2082 (million tonnes)\")\n",
    "for b, v in zip(bars, top10[\"co2\"].values[::-1]):\n",
    "    ax.text(b.get_width()+50, b.get_y()+b.get_height()/2, f\"{v:,.0f}\", va=\"center\", fontsize=9)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"top10_emitters\")\n",
    "\n",
    "# ---- Fig 3: CO2 by source over time ----\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "by_year = df.groupby(\"year\")[[\"coal_co2\",\"oil_co2\",\"gas_co2\",\"cement_co2\",\"flaring_co2\"]].sum()\n",
    "ax.stackplot(by_year.index, by_year[\"coal_co2\"], by_year[\"oil_co2\"],\n",
    "             by_year[\"gas_co2\"], by_year[\"cement_co2\"], by_year[\"flaring_co2\"],\n",
    "             labels=[\"Coal\",\"Oil\",\"Gas\",\"Cement\",\"Flaring\"],\n",
    "             colors=sns.color_palette(\"Set2\", 5), alpha=0.85)\n",
    "ax.set_title(\"Global CO\\u2082 by Fuel Source\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Year\"); ax.set_ylabel(\"CO\\u2082 (million tonnes)\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"co2_by_source\")\n",
    "\n",
    "# ---- Fig 4: CO2 per capita distribution ----\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "valid_pc = latest[latest[\"co2_per_capita\"].notna() & (latest[\"co2_per_capita\"] > 0)]\n",
    "axes[0].hist(valid_pc[\"co2_per_capita\"], bins=40, color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[0].set_title(\"CO\\u2082 per Capita Distribution (Latest Year)\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Tonnes per person\"); axes[0].set_ylabel(\"Countries\")\n",
    "# Emission level pie\n",
    "el = df[\"emission_level\"].value_counts().sort_index()\n",
    "axes[1].pie(el.values, labels=el.index, autopct=\"%1.1f%%\",\n",
    "            colors=[\"#2ecc71\",\"#f39c12\",\"#e74c3c\",\"#8e44ad\"], startangle=140)\n",
    "axes[1].set_title(\"Emission Level Distribution\", fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"co2_per_capita_dist\")\n",
    "\n",
    "# ---- Fig 5: Correlation heatmap ----\n",
    "num_cols = [\"co2\",\"co2_per_capita\",\"coal_co2\",\"oil_co2\",\"gas_co2\",\n",
    "            \"cement_co2\",\"population\",\"gdp\",\"gdp_per_capita\",\n",
    "            \"coal_share\",\"oil_share\",\"gas_share\",\"log_co2\"]\n",
    "corr = df[num_cols].corr()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
    "            center=0, ax=ax, square=True, linewidths=0.5, annot_kws={\"size\": 8})\n",
    "ax.set_title(\"Feature Correlation Heatmap\", fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"correlation_heatmap\")\n",
    "\n",
    "# ---- Fig 6: Top 5 countries timeline ----\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "top5_names = top10[\"country\"].head(5).tolist()\n",
    "for name in top5_names:\n",
    "    cdf = df[df[\"country\"] == name]\n",
    "    ax.plot(cdf[\"year\"], cdf[\"co2\"], linewidth=2, label=name)\n",
    "ax.set_title(\"CO\\u2082 Emissions \\u2013 Top 5 Countries\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Year\"); ax.set_ylabel(\"CO\\u2082 (million tonnes)\")\n",
    "ax.legend(); fig.tight_layout()\n",
    "save_plot(fig, \"top5_timeline\")\n",
    "\n",
    "print(\"All EDA plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. COâ‚‚ Emissions Prediction (Regression)\n",
    "\n",
    "Predict total COâ‚‚ emissions from economic, demographic, and energy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build regression dataset â€“ rows with GDP, population, and energy data\n",
    "reg_df = df[(df[\"gdp\"] > 0) & (df[\"population\"] > 0)].copy()\n",
    "print(f\"Regression dataset: {len(reg_df):,} rows\")\n",
    "\n",
    "reg_features = [\"population\",\"gdp\",\"gdp_per_capita\",\"year\",\n",
    "                \"coal_co2\",\"oil_co2\",\"gas_co2\",\"cement_co2\",\"flaring_co2\"]\n",
    "X_r = reg_df[reg_features].values\n",
    "y_r = reg_df[\"co2\"].values\n",
    "\n",
    "X_r_tr, X_r_te, y_r_tr, y_r_te = train_test_split(\n",
    "    X_r, y_r, test_size=0.2, random_state=SEED)\n",
    "sc_r = StandardScaler()\n",
    "X_r_tr_s = sc_r.fit_transform(X_r_tr)\n",
    "X_r_te_s = sc_r.transform(X_r_te)\n",
    "print(f\"Train: {len(y_r_tr):,}  |  Test: {len(y_r_te):,}\")\n",
    "\n",
    "def evaluate_reg(name, model, Xtr, Xte, ytr, yte, store=regression_results):\n",
    "    model.fit(Xtr, ytr)\n",
    "    yp = model.predict(Xte)\n",
    "    r2  = r2_score(yte, yp)\n",
    "    mae = mean_absolute_error(yte, yp)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, yp))\n",
    "    store[name] = {\"r2\": r2, \"mae\": mae, \"rmse\": rmse, \"y_pred\": yp, \"model\": model}\n",
    "    print(f\"  {name:30s}  R\\u00b2={r2:.4f}  MAE={mae:.2f}  RMSE={rmse:.2f}\")\n",
    "    return model\n",
    "\n",
    "print(\"\\nCO\\u2082 Regression Results:\")\n",
    "print(\"=\" * 80)\n",
    "evaluate_reg(\"Linear Regression\", LinearRegression(), X_r_tr_s, X_r_te_s, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"Ridge Regression\", Ridge(alpha=1.0), X_r_tr_s, X_r_te_s, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"Lasso Regression\", Lasso(alpha=1.0, max_iter=5000), X_r_tr_s, X_r_te_s, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"Decision Tree\", DecisionTreeRegressor(max_depth=15, random_state=SEED),\n",
    "             X_r_tr, X_r_te, y_r_tr, y_r_te)\n",
    "rf_reg = evaluate_reg(\"Random Forest\",\n",
    "    RandomForestRegressor(n_estimators=200, max_depth=20, random_state=SEED, n_jobs=-1),\n",
    "    X_r_tr, X_r_te, y_r_tr, y_r_te)\n",
    "gb_reg = evaluate_reg(\"Gradient Boosting\",\n",
    "    GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=SEED),\n",
    "    X_r_tr, X_r_te, y_r_tr, y_r_te)\n",
    "\n",
    "# Actual vs Predicted\n",
    "best_reg = max(regression_results, key=lambda k: regression_results[k][\"r2\"])\n",
    "yp_best = regression_results[best_reg][\"y_pred\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].scatter(y_r_te, yp_best, alpha=0.2, s=8, color=\"steelblue\")\n",
    "lim = max(y_r_te.max(), yp_best.max())\n",
    "axes[0].plot([0, lim], [0, lim], \"r--\", linewidth=1)\n",
    "axes[0].set_xlabel(\"Actual CO\\u2082\"); axes[0].set_ylabel(\"Predicted CO\\u2082\")\n",
    "axes[0].set_title(f\"Actual vs Predicted \\u2013 {best_reg}\", fontweight=\"bold\")\n",
    "\n",
    "reg_comp = pd.DataFrame({n: {k: v for k, v in d.items() if k not in (\"y_pred\",\"model\")}\n",
    "                          for n, d in regression_results.items()}).T.sort_values(\"r2\")\n",
    "reg_comp[\"r2\"].plot(kind=\"barh\", ax=axes[1], color=\"steelblue\")\n",
    "axes[1].set_title(\"Regression R\\u00b2 Comparison\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"R\\u00b2\"); axes[1].set_xlim(0, 1.05)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"regression_results\")\n",
    "\n",
    "# Feature importance for RF regressor\n",
    "rf_imp = pd.Series(rf_reg.feature_importances_, index=reg_features)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "rf_imp.sort_values().plot(kind=\"barh\", ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Random Forest Regressor \\u2013 Feature Importance\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"regression_feature_importance\")\n",
    "\n",
    "print(f\"\\nBest: {best_reg} (R\\u00b2 = {regression_results[best_reg]['r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Emission-Level Classification\n",
    "\n",
    "Classify country-year records into **Low / Medium / High / Very High** emission levels\n",
    "based on per-capita COâ‚‚."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare classification dataset\n",
    "clf_df = df.dropna(subset=[\"emission_level\"]).copy()\n",
    "clf_df = clf_df[(clf_df[\"gdp\"] > 0) & (clf_df[\"population\"] > 0)]\n",
    "print(f\"Classification dataset: {len(clf_df):,} rows\")\n",
    "print(clf_df[\"emission_level\"].value_counts().sort_index())\n",
    "\n",
    "le_el = LabelEncoder()\n",
    "y_c = le_el.fit_transform(clf_df[\"emission_level\"])\n",
    "class_names = le_el.classes_\n",
    "print(f\"Classes: {list(class_names)}\")\n",
    "\n",
    "clf_features = [\"population\",\"gdp\",\"gdp_per_capita\",\"year\",\n",
    "                \"coal_share\",\"oil_share\",\"gas_share\",\n",
    "                \"co2\",\"coal_co2\",\"oil_co2\",\"gas_co2\",\n",
    "                \"log_population\",\"log_co2\"]\n",
    "X_c = clf_df[clf_features].values\n",
    "\n",
    "X_c_tr, X_c_te, y_c_tr, y_c_te = train_test_split(\n",
    "    X_c, y_c, test_size=0.2, random_state=SEED, stratify=y_c)\n",
    "sc_c = StandardScaler()\n",
    "X_c_tr_s = sc_c.fit_transform(X_c_tr)\n",
    "X_c_te_s = sc_c.transform(X_c_te)\n",
    "print(f\"\\nTrain: {len(y_c_tr):,}  |  Test: {len(y_c_te):,}\")\n",
    "\n",
    "def evaluate_clf(name, model, Xtr, Xte, ytr, yte, store=results):\n",
    "    model.fit(Xtr, ytr)\n",
    "    yp = model.predict(Xte)\n",
    "    acc  = accuracy_score(yte, yp)\n",
    "    prec = precision_score(yte, yp, average=\"weighted\", zero_division=0)\n",
    "    rec  = recall_score(yte, yp, average=\"weighted\", zero_division=0)\n",
    "    f1   = f1_score(yte, yp, average=\"weighted\", zero_division=0)\n",
    "    store[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec,\n",
    "                   \"f1_score\": f1, \"y_pred\": yp, \"model\": model}\n",
    "    print(f\"  {name:28s}  Acc={acc:.4f}  F1={f1:.4f}\")\n",
    "    return model, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Emission-Level Classification\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Logistic Regression\n",
    "evaluate_clf(\"Logistic Regression\",\n",
    "    LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt, _ = evaluate_clf(\"Decision Tree\",\n",
    "    DecisionTreeClassifier(max_depth=15, random_state=SEED),\n",
    "    X_c_tr, X_c_te, y_c_tr, y_c_te)\n",
    "dt_imp = pd.Series(dt.feature_importances_, index=clf_features)\n",
    "\n",
    "# 3. Random Forest\n",
    "rf, _ = evaluate_clf(\"Random Forest\",\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=20, random_state=SEED, n_jobs=-1),\n",
    "    X_c_tr, X_c_te, y_c_tr, y_c_te)\n",
    "rf_clf_imp = pd.Series(rf.feature_importances_, index=clf_features)\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "gb, _ = evaluate_clf(\"Gradient Boosting\",\n",
    "    GradientBoostingClassifier(n_estimators=200, learning_rate=0.1,\n",
    "                                max_depth=5, random_state=SEED),\n",
    "    X_c_tr, X_c_te, y_c_tr, y_c_te)\n",
    "gb_clf_imp = pd.Series(gb.feature_importances_, index=clf_features)\n",
    "\n",
    "# 5. AdaBoost\n",
    "evaluate_clf(\"AdaBoost\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=SEED),\n",
    "    X_c_tr, X_c_te, y_c_tr, y_c_te)\n",
    "\n",
    "# 6-7. SVM\n",
    "evaluate_clf(\"SVM (linear)\",\n",
    "    SVC(kernel=\"linear\", random_state=SEED, probability=True, max_iter=5000),\n",
    "    X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "evaluate_clf(\"SVM (rbf)\",\n",
    "    SVC(kernel=\"rbf\", random_state=SEED, probability=True),\n",
    "    X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "# 8. KNN\n",
    "k_scores = {}\n",
    "for k in [3, 5, 7, 9, 11]:\n",
    "    tmp = KNeighborsClassifier(n_neighbors=k)\n",
    "    tmp.fit(X_c_tr_s, y_c_tr)\n",
    "    k_scores[k] = accuracy_score(y_c_te, tmp.predict(X_c_te_s))\n",
    "best_k = max(k_scores, key=k_scores.get)\n",
    "print(f\"  KNN by k: { {k: round(v,4) for k,v in k_scores.items()} } -> best k={best_k}\")\n",
    "evaluate_clf(f\"KNN (k={best_k})\",\n",
    "    KNeighborsClassifier(n_neighbors=best_k),\n",
    "    X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "# 9. Naive Bayes\n",
    "evaluate_clf(\"Naive Bayes\", GaussianNB(), X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "# 10. MLP\n",
    "evaluate_clf(\"MLP Neural Network\",\n",
    "    MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=500,\n",
    "                  random_state=SEED, early_stopping=True),\n",
    "    X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "print(f\"\\nAll {len(results)} classifiers trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. COâ‚‚ Growth-Rate Forecasting\n",
    "\n",
    "Predict `co2_growth_prct` (year-over-year COâ‚‚ change %) using lagged features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build lagged features per country\n",
    "gr_df = df[df[\"co2_growth_prct\"].notna() & (df[\"gdp\"] > 0)].copy()\n",
    "gr_df = gr_df.sort_values([\"country\",\"year\"])\n",
    "\n",
    "# Lag-1 CO2 and GDP\n",
    "gr_df[\"co2_lag1\"]  = gr_df.groupby(\"country\")[\"co2\"].shift(1)\n",
    "gr_df[\"gdp_lag1\"]  = gr_df.groupby(\"country\")[\"gdp\"].shift(1)\n",
    "gr_df[\"pop_lag1\"]  = gr_df.groupby(\"country\")[\"population\"].shift(1)\n",
    "gr_df[\"co2_diff\"]  = gr_df[\"co2\"] - gr_df[\"co2_lag1\"]\n",
    "gr_df = gr_df.dropna(subset=[\"co2_lag1\"])\n",
    "print(f\"Growth-rate dataset: {len(gr_df):,} rows\")\n",
    "\n",
    "gr_features = [\"co2_lag1\",\"gdp_lag1\",\"pop_lag1\",\"gdp_per_capita\",\n",
    "               \"coal_share\",\"oil_share\",\"gas_share\",\"year\"]\n",
    "X_g = gr_df[gr_features].values\n",
    "y_g = gr_df[\"co2_growth_prct\"].values\n",
    "\n",
    "# Clip extreme outliers for stability\n",
    "y_g = np.clip(y_g, np.percentile(y_g, 1), np.percentile(y_g, 99))\n",
    "\n",
    "X_g_tr, X_g_te, y_g_tr, y_g_te = train_test_split(\n",
    "    X_g, y_g, test_size=0.2, random_state=SEED)\n",
    "sc_g = StandardScaler()\n",
    "X_g_tr_s = sc_g.fit_transform(X_g_tr)\n",
    "X_g_te_s = sc_g.transform(X_g_te)\n",
    "print(f\"Train: {len(y_g_tr):,}  |  Test: {len(y_g_te):,}\")\n",
    "\n",
    "print(\"\\nGrowth-Rate Regression:\")\n",
    "print(\"=\" * 80)\n",
    "evaluate_reg(\"GR \\u2013 Linear\", LinearRegression(), X_g_tr_s, X_g_te_s, y_g_tr, y_g_te, growth_results)\n",
    "evaluate_reg(\"GR \\u2013 Ridge\", Ridge(alpha=10.0), X_g_tr_s, X_g_te_s, y_g_tr, y_g_te, growth_results)\n",
    "evaluate_reg(\"GR \\u2013 Random Forest\",\n",
    "    RandomForestRegressor(n_estimators=200, max_depth=10, random_state=SEED, n_jobs=-1),\n",
    "    X_g_tr, X_g_te, y_g_tr, y_g_te, growth_results)\n",
    "evaluate_reg(\"GR \\u2013 Gradient Boosting\",\n",
    "    GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=SEED),\n",
    "    X_g_tr, X_g_te, y_g_tr, y_g_te, growth_results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "gr_comp = pd.DataFrame({n: {k: v for k, v in d.items() if k not in (\"y_pred\",\"model\")}\n",
    "                         for n, d in growth_results.items()}).T.sort_values(\"r2\")\n",
    "gr_comp[\"r2\"].plot(kind=\"barh\", ax=ax, color=\"coral\")\n",
    "ax.set_title(\"Growth-Rate Forecasting \\u2013 R\\u00b2 Comparison\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"R\\u00b2\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"growth_regression\")\n",
    "\n",
    "best_gr = max(growth_results, key=lambda k: growth_results[k][\"r2\"])\n",
    "print(f\"\\nBest: {best_gr} (R\\u00b2 = {growth_results[best_gr]['r2']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Country Clustering (Unsupervised)\n",
    "\n",
    "Group countries by their emission profile using K-Means, PCA, and DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate latest-year data per country\n",
    "cl_df = latest[(latest[\"co2\"].notna()) & (latest[\"population\"] > 0)].copy()\n",
    "cl_features = [\"co2\",\"co2_per_capita\",\"coal_share\",\"oil_share\",\"gas_share\",\n",
    "               \"gdp_per_capita\",\"log_co2\",\"log_population\"]\n",
    "cl_df = cl_df.dropna(subset=cl_features)\n",
    "print(f\"Clustering: {len(cl_df)} countries\")\n",
    "\n",
    "X_cl = cl_df[cl_features].values\n",
    "sc_cl = StandardScaler()\n",
    "X_cl_s = sc_cl.fit_transform(X_cl)\n",
    "\n",
    "# Elbow + Silhouette\n",
    "inertias, sils = [], []\n",
    "K_range = range(2, 11)\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=SEED, n_init=10)\n",
    "    lbl = km.fit_predict(X_cl_s)\n",
    "    inertias.append(km.inertia_)\n",
    "    sils.append(silhouette_score(X_cl_s, lbl))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(list(K_range), inertias, \"bo-\")\n",
    "axes[0].set_title(\"Elbow Method\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"k\"); axes[0].set_ylabel(\"Inertia\")\n",
    "axes[1].plot(list(K_range), sils, \"ro-\")\n",
    "axes[1].set_title(\"Silhouette Score\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"k\"); axes[1].set_ylabel(\"Score\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"elbow_silhouette\")\n",
    "\n",
    "best_k_cl = list(K_range)[int(np.argmax(sils))]\n",
    "print(f\"Best k = {best_k_cl} (silhouette = {max(sils):.4f})\")\n",
    "km_final = KMeans(n_clusters=best_k_cl, random_state=SEED, n_init=10)\n",
    "cl_df[\"Cluster\"] = km_final.fit_predict(X_cl_s)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2, random_state=SEED)\n",
    "X_pca = pca.fit_transform(X_cl_s)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sc1 = axes[0].scatter(X_pca[:,0], X_pca[:,1], c=cl_df[\"Cluster\"].values,\n",
    "                       cmap=\"Set2\", s=40, alpha=0.8)\n",
    "# label top emitters\n",
    "for _, row in cl_df.nlargest(8, \"co2\").iterrows():\n",
    "    idx = cl_df.index.get_loc(row.name)\n",
    "    axes[0].annotate(row[\"country\"], (X_pca[idx, 0], X_pca[idx, 1]),\n",
    "                     fontsize=7, alpha=0.8)\n",
    "axes[0].set_title(f\"K-Means (k={best_k_cl}) \\u2013 PCA\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "axes[0].set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "plt.colorbar(sc1, ax=axes[0], label=\"Cluster\")\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=2.0, min_samples=3)\n",
    "db_lbl = dbscan.fit_predict(X_cl_s)\n",
    "n_db = len(set(db_lbl)) - (1 if -1 in db_lbl else 0)\n",
    "noise = (db_lbl == -1).sum()\n",
    "sc2 = axes[1].scatter(X_pca[:,0], X_pca[:,1], c=db_lbl, cmap=\"Set1\", s=40, alpha=0.8)\n",
    "axes[1].set_title(f\"DBSCAN ({n_db} clusters, {noise} noise)\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"PC1\"); axes[1].set_ylabel(\"PC2\")\n",
    "plt.colorbar(sc2, ax=axes[1], label=\"Cluster\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"clustering_results\")\n",
    "\n",
    "print(\"\\nCluster profiles:\")\n",
    "profile = cl_df.groupby(\"Cluster\")[[\"co2\",\"co2_per_capita\",\"coal_share\",\"gdp_per_capita\"]].agg([\"mean\",\"count\"])\n",
    "print(profile.round(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning\n",
    "\n",
    "GridSearchCV (Random Forest) and RandomizedSearchCV (Gradient Boosting)\n",
    "for emission-level classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GridSearchCV: Random Forest ...\")\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [10, 15, 20], \"min_samples_split\": [2, 5]},\n",
    "    cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=0)\n",
    "grid_rf.fit(X_c_tr, y_c_tr)\n",
    "print(f\"  Best params: {grid_rf.best_params_}\")\n",
    "print(f\"  Best CV F1:  {grid_rf.best_score_:.4f}\")\n",
    "\n",
    "yp_rf = grid_rf.predict(X_c_te)\n",
    "results[\"RF (Tuned)\"] = {\n",
    "    \"accuracy\": accuracy_score(y_c_te, yp_rf),\n",
    "    \"precision\": precision_score(y_c_te, yp_rf, average=\"weighted\", zero_division=0),\n",
    "    \"recall\": recall_score(y_c_te, yp_rf, average=\"weighted\", zero_division=0),\n",
    "    \"f1_score\": f1_score(y_c_te, yp_rf, average=\"weighted\", zero_division=0),\n",
    "    \"y_pred\": yp_rf, \"model\": grid_rf.best_estimator_}\n",
    "print(f\"  Test Acc:    {results['RF (Tuned)']['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV: Gradient Boosting ...\")\n",
    "rand_gb = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=SEED),\n",
    "    {\"n_estimators\": [100, 200, 300], \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "     \"max_depth\": [3, 5, 7, 10], \"min_samples_split\": [2, 5, 10]},\n",
    "    n_iter=20, cv=3, scoring=\"f1_weighted\", random_state=SEED, n_jobs=-1, verbose=0)\n",
    "rand_gb.fit(X_c_tr, y_c_tr)\n",
    "print(f\"  Best params: {rand_gb.best_params_}\")\n",
    "\n",
    "yp_gb = rand_gb.predict(X_c_te)\n",
    "results[\"GB (Tuned)\"] = {\n",
    "    \"accuracy\": accuracy_score(y_c_te, yp_gb),\n",
    "    \"precision\": precision_score(y_c_te, yp_gb, average=\"weighted\", zero_division=0),\n",
    "    \"recall\": recall_score(y_c_te, yp_gb, average=\"weighted\", zero_division=0),\n",
    "    \"f1_score\": f1_score(y_c_te, yp_gb, average=\"weighted\", zero_division=0),\n",
    "    \"y_pred\": yp_gb, \"model\": rand_gb.best_estimator_}\n",
    "print(f\"  Test Acc:    {results['GB (Tuned)']['accuracy']:.4f}\")\n",
    "print(\"\\nHyperparameter tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cross-Validation, Confusion Matrices & Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 5-Fold Cross-Validation ----\n",
    "print(\"5-Fold Cross-Validation (Emission Classification)\")\n",
    "print(\"=\" * 70)\n",
    "cv_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=15, random_state=SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=SEED),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "cv_data = []\n",
    "for name, model in cv_models.items():\n",
    "    acc_cv = cross_val_score(model, X_c_tr_s, y_c_tr, cv=5, scoring=\"accuracy\")\n",
    "    f1_cv  = cross_val_score(model, X_c_tr_s, y_c_tr, cv=5, scoring=\"f1_weighted\")\n",
    "    cv_data.append({\"Model\": name, \"Acc_mean\": acc_cv.mean(), \"Acc_std\": acc_cv.std(),\n",
    "                    \"F1_mean\": f1_cv.mean(), \"F1_std\": f1_cv.std()})\n",
    "    print(f\"  {name:25s}  Acc={acc_cv.mean():.4f}\\u00b1{acc_cv.std():.4f}  \"\n",
    "          f\"F1={f1_cv.mean():.4f}\\u00b1{f1_cv.std():.4f}\")\n",
    "cv_df = pd.DataFrame(cv_data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "x = np.arange(len(cv_df)); w = 0.35\n",
    "ax.bar(x-w/2, cv_df[\"Acc_mean\"], w, yerr=cv_df[\"Acc_std\"], capsize=3,\n",
    "       label=\"Accuracy\", color=\"steelblue\")\n",
    "ax.bar(x+w/2, cv_df[\"F1_mean\"], w, yerr=cv_df[\"F1_std\"], capsize=3,\n",
    "       label=\"F1\", color=\"coral\")\n",
    "ax.set_xticks(x); ax.set_xticklabels(cv_df[\"Model\"], rotation=30, ha=\"right\")\n",
    "ax.set_title(\"Cross-Validation: Model Comparison\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Score\"); ax.legend(); ax.set_ylim(0, 1.05)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"cv_comparison\")\n",
    "\n",
    "# ---- Feature Importance ----\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for i, (name, imp) in enumerate([(\"Decision Tree\", dt_imp),\n",
    "                                  (\"Random Forest\", rf_clf_imp),\n",
    "                                  (\"Gradient Boosting\", gb_clf_imp)]):\n",
    "    imp.sort_values().plot(kind=\"barh\", ax=axes[i], color=\"steelblue\")\n",
    "    axes[i].set_title(f\"{name}\\nFeature Importance\", fontweight=\"bold\")\n",
    "    axes[i].set_xlabel(\"Importance\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"feature_importance\")\n",
    "\n",
    "# ---- Confusion Matrices ----\n",
    "cm_models = {k: v for k, v in results.items() if \"y_pred\" in v and \"Tuned\" not in k}\n",
    "n = len(cm_models); ncols = 3; nrows = (n + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(6*ncols, 5*nrows))\n",
    "axes_f = axes.flatten()\n",
    "for i, (name, data) in enumerate(cm_models.items()):\n",
    "    cm = confusion_matrix(y_c_te, data[\"y_pred\"])\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes_f[i],\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    axes_f[i].set_title(f\"{name}\\nAcc={data['accuracy']:.3f}\",\n",
    "                        fontsize=10, fontweight=\"bold\")\n",
    "    axes_f[i].set_xlabel(\"Predicted\"); axes_f[i].set_ylabel(\"Actual\")\n",
    "for i in range(n, len(axes_f)):\n",
    "    axes_f[i].set_visible(False)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"confusion_matrices\")\n",
    "\n",
    "# ---- Learning Curves ----\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "lc_models = [\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "]\n",
    "for i, (name, model) in enumerate(lc_models):\n",
    "    sizes, tr_sc, va_sc = learning_curve(\n",
    "        model, X_c_tr_s, y_c_tr, cv=5,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 8), scoring=\"accuracy\", n_jobs=-1)\n",
    "    axes[i].plot(sizes, tr_sc.mean(1), \"o-\", label=\"Train\", color=\"steelblue\")\n",
    "    axes[i].fill_between(sizes, tr_sc.mean(1)-tr_sc.std(1),\n",
    "                         tr_sc.mean(1)+tr_sc.std(1), alpha=0.1, color=\"steelblue\")\n",
    "    axes[i].plot(sizes, va_sc.mean(1), \"o-\", label=\"Validation\", color=\"coral\")\n",
    "    axes[i].fill_between(sizes, va_sc.mean(1)-va_sc.std(1),\n",
    "                         va_sc.mean(1)+va_sc.std(1), alpha=0.1, color=\"coral\")\n",
    "    axes[i].set_title(f\"Learning Curve: {name}\", fontweight=\"bold\")\n",
    "    axes[i].set_xlabel(\"Training Size\"); axes[i].set_ylabel(\"Accuracy\")\n",
    "    axes[i].legend(loc=\"lower right\"); axes[i].set_ylim(0.3, 1.05)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"learning_curves\")\n",
    "\n",
    "print(\"\\nAll evaluation plots saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ensemble Methods & Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "print(\"Training Voting Classifier ...\")\n",
    "voting = VotingClassifier(estimators=[\n",
    "    (\"lr\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "], voting=\"soft\", n_jobs=-1)\n",
    "evaluate_clf(\"Voting Ensemble\", voting, X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "# Stacking Classifier\n",
    "print(\"Training Stacking Classifier ...\")\n",
    "stacking = StackingClassifier(estimators=[\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=best_k)),\n",
    "], final_estimator=LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "   cv=3, n_jobs=-1)\n",
    "evaluate_clf(\"Stacking Ensemble\", stacking, X_c_tr_s, X_c_te_s, y_c_tr, y_c_te)\n",
    "\n",
    "# ---- Final comparison table ----\n",
    "rows = []\n",
    "for name, data in results.items():\n",
    "    rows.append({\"Model\": name, \"Accuracy\": data[\"accuracy\"],\n",
    "                 \"Precision\": data[\"precision\"], \"Recall\": data[\"recall\"],\n",
    "                 \"F1 Score\": data[\"f1_score\"]})\n",
    "comp_df = pd.DataFrame(rows).sort_values(\"F1 Score\", ascending=False)\n",
    "print(\"\\nFinal Model Comparison:\")\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "comp_s = comp_df.sort_values(\"F1 Score\")\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.9, len(comp_s)))\n",
    "ax.barh(comp_s[\"Model\"], comp_s[\"F1 Score\"], color=colors)\n",
    "ax.set_xlabel(\"F1 Score (Weighted)\"); ax.set_xlim(0, 1.05)\n",
    "ax.set_title(\"All Models \\u2013 F1 Score Comparison\", fontweight=\"bold\")\n",
    "for i, (_, row) in enumerate(comp_s.iterrows()):\n",
    "    ax.text(row[\"F1 Score\"]+0.005, i, f\"{row['F1 Score']:.4f}\", va=\"center\", fontsize=9)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"model_comparison\")\n",
    "\n",
    "best_name = comp_df.iloc[0][\"Model\"]\n",
    "best_f1 = comp_df.iloc[0][\"F1 Score\"]\n",
    "print(f\"\\nBest model: {best_name} (F1 = {best_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. HTML Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "<style>\n",
    "* { margin:0; padding:0; box-sizing:border-box; }\n",
    "body { font-family:'Segoe UI',system-ui,sans-serif; background:#f0f2f5; color:#333; line-height:1.6; }\n",
    ".container { max-width:1200px; margin:0 auto; padding:20px; }\n",
    "header { background:linear-gradient(135deg,#1b4332,#2d6a4f); color:#fff; padding:40px; border-radius:12px; margin-bottom:30px; text-align:center; }\n",
    "header h1 { font-size:2.2em; margin-bottom:10px; }\n",
    "header p  { font-size:1.1em; opacity:.9; }\n",
    ".card { background:#fff; border-radius:12px; padding:30px; margin-bottom:25px; box-shadow:0 2px 10px rgba(0,0,0,.08); }\n",
    ".card h2 { color:#1b4332; border-bottom:3px solid #2d6a4f; padding-bottom:10px; margin-bottom:20px; }\n",
    ".card h3 { color:#2d6a4f; margin:15px 0 10px; }\n",
    "table { width:100%; border-collapse:collapse; margin:15px 0; }\n",
    "th,td { padding:10px 14px; text-align:left; border-bottom:1px solid #eee; }\n",
    "th { background:#f8f9fa; font-weight:600; color:#1b4332; }\n",
    "tr:hover { background:#f8f9fa; }\n",
    ".dashboard { display:grid; grid-template-columns:repeat(auto-fit,minmax(180px,1fr)); gap:15px; margin-bottom:25px; }\n",
    ".stat-box { background:#fff; border-radius:10px; padding:20px; text-align:center; box-shadow:0 2px 8px rgba(0,0,0,.08); }\n",
    ".stat-box .number { font-size:2em; font-weight:700; color:#2d6a4f; }\n",
    ".stat-box .label  { font-size:.9em; color:#666; margin-top:5px; }\n",
    ".plot-img { max-width:100%; border-radius:8px; margin:15px 0; box-shadow:0 2px 8px rgba(0,0,0,.1); }\n",
    ".explanation { background:#d8f3dc; border-left:4px solid #2d6a4f; padding:15px; border-radius:0 8px 8px 0; margin:15px 0; }\n",
    ".best { color:#27ae60; font-weight:700; }\n",
    "footer { text-align:center; padding:30px; color:#999; font-size:.9em; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "html = []\n",
    "html.append(\"<!DOCTYPE html><html lang='en'>\")\n",
    "html.append(\"<head><meta charset='UTF-8'>\")\n",
    "html.append(\"<meta name='viewport' content='width=device-width,initial-scale=1.0'>\")\n",
    "html.append(\"<title>Global CO\\u2082 Emissions \\u2013 ML Report</title>\")\n",
    "html.append(css)\n",
    "html.append(\"</head><body><div class='container'>\")\n",
    "\n",
    "# ---- Header ----\n",
    "html.append(\"<header>\")\n",
    "html.append(\"<h1>\\U0001f30d Global CO\\u2082 Emissions \\u2013 ML Analysis Report</h1>\")\n",
    "html.append(\"<p>Comprehensive Machine Learning Analysis of Global Carbon Emissions Data</p>\")\n",
    "html.append(f\"<p>{len(raw):,} records &middot; {raw['country'].nunique()} countries &middot; \"\n",
    "            f\"{raw['year'].min()}\\u2013{raw['year'].max()}</p>\")\n",
    "html.append(\"</header>\")\n",
    "\n",
    "# ---- Dashboard ----\n",
    "best_clf_name = comp_df.iloc[0][\"Model\"]\n",
    "best_clf_f1   = comp_df.iloc[0][\"F1 Score\"]\n",
    "best_reg_name = max(regression_results, key=lambda k: regression_results[k][\"r2\"])\n",
    "best_reg_r2   = regression_results[best_reg_name][\"r2\"]\n",
    "best_gr_name  = max(growth_results, key=lambda k: growth_results[k][\"r2\"])\n",
    "best_gr_r2    = growth_results[best_gr_name][\"r2\"]\n",
    "\n",
    "html.append(\"<div class='dashboard'>\")\n",
    "for label, value in [\n",
    "    (\"Country-Years\", f\"{len(raw):,}\"),\n",
    "    (\"Countries\", str(raw[\"country\"].nunique())),\n",
    "    (\"ML Models\", str(len(results) + len(regression_results) + len(growth_results))),\n",
    "    (\"Best Clf F1\", f\"{best_clf_f1:.4f}\"),\n",
    "    (\"Best Reg R\\u00b2\", f\"{best_reg_r2:.4f}\"),\n",
    "    (\"Plots Generated\", str(len(report_images))),\n",
    "]:\n",
    "    html.append(f\"<div class='stat-box'><div class='number'>{value}</div>\"\n",
    "                f\"<div class='label'>{label}</div></div>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 1: Dataset ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f4cb 1. Dataset Overview</h2>\")\n",
    "html.append(\"<p>This analysis uses the <strong>Our World in Data</strong> global CO\\u2082 dataset \"\n",
    "            \"covering emissions by country from <strong>1750 to 2021</strong>. The dataset includes \"\n",
    "            \"79 features covering emissions by fuel source, GDP, population, temperature change, \"\n",
    "            \"and land-use change.</p>\")\n",
    "html.append(\"<div class='explanation'><strong>Preprocessing:</strong> \"\n",
    "            \"Filtered to 1950+, removed aggregate regions (e.g. \\u2018Africa\\u2019, \\u2018World\\u2019), \"\n",
    "            \"engineered fuel-mix shares, GDP per capita, emission levels, and log-transforms.</div>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 2: EDA ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f4ca 2. Exploratory Data Analysis</h2>\")\n",
    "for name, caption in [\n",
    "    (\"global_co2_timeline\", \"Global CO\\u2082 emissions trajectory (1950\\u20132021)\"),\n",
    "    (\"top10_emitters\", \"Top 10 CO\\u2082-emitting countries in the latest year\"),\n",
    "    (\"co2_by_source\", \"Global CO\\u2082 breakdown by fuel source over time\"),\n",
    "    (\"co2_per_capita_dist\", \"Per-capita CO\\u2082 distribution and emission-level breakdown\"),\n",
    "    (\"correlation_heatmap\", \"Pearson correlation between numeric features\"),\n",
    "    (\"top5_timeline\", \"Emission timelines for the 5 largest emitters\"),\n",
    "]:\n",
    "    if name in report_images:\n",
    "        html.append(f\"<h3>{caption}</h3>\")\n",
    "        html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images[name]}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 3: Regression ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f4c8 3. CO\\u2082 Emissions Prediction (Regression)</h2>\")\n",
    "html.append(\"<p>Predicting total CO\\u2082 emissions from economic, demographic, and energy features.</p>\")\n",
    "html.append(\"<table><tr><th>Model</th><th>R\\u00b2</th><th>MAE</th><th>RMSE</th></tr>\")\n",
    "for name in sorted(regression_results, key=lambda k: -regression_results[k][\"r2\"]):\n",
    "    d = regression_results[name]\n",
    "    cls = \" class='best'\" if name == best_reg_name else \"\"\n",
    "    html.append(f\"<tr{cls}><td>{name}</td><td>{d['r2']:.4f}</td>\"\n",
    "                f\"<td>{d['mae']:.2f}</td><td>{d['rmse']:.2f}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "if \"regression_results\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['regression_results']}'>\")\n",
    "if \"regression_feature_importance\" in report_images:\n",
    "    html.append(\"<h3>Feature Importance</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['regression_feature_importance']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 4: Classification ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f916 4. Emission-Level Classification</h2>\")\n",
    "html.append(\"<p>Classifying country-year records into Low / Medium / High / Very High \"\n",
    "            \"per-capita CO\\u2082 emission levels.</p>\")\n",
    "html.append(\"<table><tr><th>Model</th><th>Accuracy</th><th>Precision</th>\"\n",
    "            \"<th>Recall</th><th>F1 Score</th></tr>\")\n",
    "for _, row in comp_df.iterrows():\n",
    "    cls = \" class='best'\" if row[\"Model\"] == best_clf_name else \"\"\n",
    "    html.append(f\"<tr{cls}><td>{row['Model']}</td><td>{row['Accuracy']:.4f}</td>\"\n",
    "                f\"<td>{row['Precision']:.4f}</td><td>{row['Recall']:.4f}</td>\"\n",
    "                f\"<td>{row['F1 Score']:.4f}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "if \"confusion_matrices\" in report_images:\n",
    "    html.append(\"<h3>Confusion Matrices</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['confusion_matrices']}'>\")\n",
    "if \"model_comparison\" in report_images:\n",
    "    html.append(\"<h3>Model Comparison</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['model_comparison']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 5: Growth Rate ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f4c9 5. CO\\u2082 Growth-Rate Forecasting</h2>\")\n",
    "html.append(\"<p>Predicting year-over-year CO\\u2082 change (%) using lagged features.</p>\")\n",
    "html.append(\"<table><tr><th>Model</th><th>R\\u00b2</th><th>MAE</th><th>RMSE</th></tr>\")\n",
    "for name in sorted(growth_results, key=lambda k: -growth_results[k][\"r2\"]):\n",
    "    d = growth_results[name]\n",
    "    cls = \" class='best'\" if name == best_gr_name else \"\"\n",
    "    html.append(f\"<tr{cls}><td>{name}</td><td>{d['r2']:.4f}</td>\"\n",
    "                f\"<td>{d['mae']:.2f}</td><td>{d['rmse']:.2f}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "if \"growth_regression\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['growth_regression']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 6: Clustering ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f9e9 6. Country Clustering</h2>\")\n",
    "html.append(f\"<p>K-Means identified <strong>{best_k_cl} country groups</strong> \"\n",
    "            f\"based on emission profiles (silhouette = {max(sils):.4f}).</p>\")\n",
    "if \"elbow_silhouette\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['elbow_silhouette']}'>\")\n",
    "if \"clustering_results\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['clustering_results']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 7: CV & Learning ----\n",
    "html.append(\"<div class='card'><h2>\\u2696\\ufe0f 7. Cross-Validation & Learning Curves</h2>\")\n",
    "if \"cv_comparison\" in report_images:\n",
    "    html.append(\"<h3>5-Fold Cross-Validation</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['cv_comparison']}'>\")\n",
    "if \"feature_importance\" in report_images:\n",
    "    html.append(\"<h3>Feature Importance (Classification)</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['feature_importance']}'>\")\n",
    "if \"learning_curves\" in report_images:\n",
    "    html.append(\"<h3>Learning Curves</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['learning_curves']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# ---- Section 8: Conclusions ----\n",
    "html.append(\"<div class='card'><h2>\\U0001f3af 8. Key Findings & Conclusions</h2>\")\n",
    "html.append(\"<div class='explanation'>\")\n",
    "html.append(\"<h3>CO\\u2082 Regression</h3>\")\n",
    "html.append(f\"<p><strong>{best_reg_name}</strong> achieved R\\u00b2 = {best_reg_r2:.4f}. \"\n",
    "            \"Source-specific CO\\u2082 columns (coal, oil, gas) are the strongest predictors, \"\n",
    "            \"as total CO\\u2082 is largely their sum. Population and GDP provide additional signal.</p>\")\n",
    "html.append(\"<h3>Emission Classification</h3>\")\n",
    "html.append(f\"<p><strong>{best_clf_name}</strong> achieved F1 = {best_clf_f1:.4f}. \"\n",
    "            \"Tree-based models excel at distinguishing emission levels. \"\n",
    "            \"Total CO\\u2082, per-capita metrics, and fuel-mix shares are the key discriminators.</p>\")\n",
    "html.append(\"<h3>Growth-Rate Forecasting</h3>\")\n",
    "html.append(f\"<p><strong>{best_gr_name}</strong> achieved R\\u00b2 = {best_gr_r2:.4f}. \"\n",
    "            \"Year-over-year CO\\u2082 change is inherently noisy and harder to predict; \"\n",
    "            \"lagged CO\\u2082 levels and economic indicators provide moderate predictive power.</p>\")\n",
    "html.append(\"<h3>Country Clustering</h3>\")\n",
    "html.append(f\"<p>K-Means identified {best_k_cl} distinct country clusters. \"\n",
    "            \"Countries group primarily by total emission volume and per-capita intensity, \"\n",
    "            \"revealing a clear divide between industrialised high-emitters and developing nations.</p>\")\n",
    "html.append(\"</div></div>\")\n",
    "\n",
    "# ---- Footer ----\n",
    "html.append(\"<footer>\")\n",
    "html.append(\"<p>Generated with scikit-learn, pandas, matplotlib, seaborn</p>\")\n",
    "html.append(\"<p>Data: Our World in Data \\u2013 Global CO\\u2082 and Greenhouse Gas Emissions</p>\")\n",
    "html.append(\"</footer></div></body></html>\")\n",
    "\n",
    "# ---- Write ----\n",
    "report_path = \"outputs/co2_ml_report.html\"\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(html))\n",
    "\n",
    "size_kb = os.path.getsize(report_path) / 1024\n",
    "print(f\"\\u2705 HTML Report generated: {report_path}\")\n",
    "print(f\"   File size: {size_kb:.1f} KB\")\n",
    "print(f\"   Embedded images: {len(report_images)}\")\n",
    "print(f\"\\n\\U0001f389 Analysis complete! Open the HTML file to view the full report.\")"
   ]
  }
 ]
}