# ðŸ’¬ Sentiment Analysis â€” From TF-IDF to DistilBERT

A complete NLP pipeline comparing classical ML, word embeddings, and
transformer fine-tuning on Amazon product reviews.

## Architecture

```
Raw Text â†’ Clean â†’ TF-IDF â†’ LogReg       â†’ ~93% acc  (Stage 1)
                 â†’ GloVe  â†’ XGBoost      â†’ ~90% acc  (Stage 2)
         â†’ Tokenize â†’ DistilBERT â†’ Fine-tune â†’ ~95% acc  (Stage 3)
```

## Dataset

**Amazon Polarity** (HuggingFace `datasets`):
- Binary: 0 = negative, 1 = positive
- Train: 20,000 (stratified 50/50)
- Test:   4,000 (stratified 50/50)

## Quick Start

```bash
pip install -r requirements.txt
jupyter notebook sentiment_analysis.ipynb
# Run All Cells â€” first run downloads data (~600 MB, cached thereafter)
```

## Stage Comparison (approximate)

| Model                         | Stage | Accuracy | F1    | Train Time |
|-------------------------------|-------|----------|-------|------------|
| Logistic Regression (TF-IDF) | 1     | ~93%     | ~0.93 | < 5 s      |
| Naive Bayes (BoW)            | 1     | ~91%     | ~0.91 | < 1 s      |
| SVM Linear (TF-IDF)          | 1     | ~93%     | ~0.93 | < 10 s     |
| SGD Classifier (TF-IDF)      | 1     | ~92%     | ~0.92 | < 2 s      |
| Logistic Regression (GloVe)  | 2     | ~88%     | ~0.88 | < 5 s      |
| XGBoost (GloVe)              | 2     | ~90%     | ~0.90 | ~30 s      |
| DistilBERT fine-tuned        | 3     | ~95%     | ~0.95 | ~15 min    |

## Project Structure

```
sentiment_analysis/
â”œâ”€â”€ sentiment_analysis.ipynb        # Main notebook (Run All Cells)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ amazon_train.csv            # 20k reviews (saved at runtime)
â”‚   â””â”€â”€ amazon_test.csv             # 4k reviews
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ glove.6B.100d.txt           # Downloaded at runtime (~850 MB)
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                    # All EDA and evaluation plots
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”‚   â”œâ”€â”€ logreg_model.pkl
â”‚   â”‚   â””â”€â”€ distilbert_finetuned/   # HuggingFace save_pretrained
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ stage_comparison.csv
â”‚       â””â”€â”€ inference_demo.html
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Hardware

Optimised for **Apple Silicon M1** (MPS backend).
Falls back to CPU gracefully if MPS is unavailable.
