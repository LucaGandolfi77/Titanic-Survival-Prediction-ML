{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ† New Year's Resolutions â€“ ML & NLP Analysis\n",
    "**Dataset**: 4,723 tweets about New Year's Resolutions with categories, regions, gender, and text.\n",
    "\n",
    "| # | Task | Type | Target / Method |\n",
    "|---|------|------|-----------------|\n",
    "| 1 | Tweet Category Classification | Multi-class (10 classes) | TF-IDF + ML models |\n",
    "| 2 | Gender Prediction | Binary Classification | TF-IDF + metadata features |\n",
    "| 3 | Sentiment Analysis (TextBlob) | NLP | Polarity & subjectivity scores |\n",
    "| 4 | Sentiment Analysis (BERT) | Deep Learning | HuggingFace distilbert-sst2 |\n",
    "| 5 | Tweet Clustering | Unsupervised | K-Means on TF-IDF vectors |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Â· Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports OK\n"
     ]
    }
   ],
   "source": [
    "import warnings, os, pathlib, re, time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV,\n",
    "                                     RandomizedSearchCV, cross_val_score,\n",
    "                                     learning_curve, StratifiedKFold)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (accuracy_score, f1_score, classification_report,\n",
    "                             confusion_matrix, silhouette_score)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                              AdaBoostClassifier, VotingClassifier, StackingClassifier)\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import jinja2, base64\n",
    "from io import BytesIO\n",
    "\n",
    "SEED = 42\n",
    "PLOT_DIR = pathlib.Path(\"outputs/plots\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "print(\"âœ… Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Â· Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4723, 10)\n",
      "Columns: ['Ã¯Â»Â¿tweet_created', 'tweet_text', 'tweet_category', 'tweet_topics', 'tweet_location', 'tweet_state', 'tweet_region', 'user_timezone', 'user_gender', 'retweet_count']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tweet_created'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gandalf/Github/Titanic-Survival-Prediction-ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'tweet_created'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.columns.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Parse date\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtweet_created\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtweet_created\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtweet_hour\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtweet_created\u001b[39m\u001b[33m\"\u001b[39m].dt.hour\n\u001b[32m     11\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mtweet_day\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mtweet_created\u001b[39m\u001b[33m\"\u001b[39m].dt.day\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gandalf/Github/Titanic-Survival-Prediction-ML/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Gandalf/Github/Titanic-Survival-Prediction-ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'tweet_created'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"New_years_resolutions.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Parse date\n",
    "df[\"tweet_created\"] = pd.to_datetime(df[\"tweet_created\"], errors=\"coerce\")\n",
    "df[\"tweet_hour\"] = df[\"tweet_created\"].dt.hour\n",
    "df[\"tweet_day\"] = df[\"tweet_created\"].dt.day\n",
    "\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#(\\w+)\", r\"\\1\", text)  # keep hashtag text, remove #\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "df[\"clean_text\"] = df[\"tweet_text\"].apply(clean_text)\n",
    "df[\"text_length\"] = df[\"clean_text\"].str.len()\n",
    "df[\"word_count\"] = df[\"clean_text\"].str.split().str.len()\n",
    "\n",
    "# Encode categorical\n",
    "le_region = LabelEncoder()\n",
    "df[\"region_enc\"] = le_region.fit_transform(df[\"tweet_region\"])\n",
    "\n",
    "le_gender = LabelEncoder()\n",
    "df[\"gender_enc\"] = le_gender.fit_transform(df[\"user_gender\"])\n",
    "\n",
    "le_cat = LabelEncoder()\n",
    "df[\"category_enc\"] = le_cat.fit_transform(df[\"tweet_category\"])\n",
    "\n",
    "print(f\"\\nCategories ({len(le_cat.classes_)}):\")\n",
    "for c in le_cat.classes_:\n",
    "    print(f\"  {c}: {(df['tweet_category'] == c).sum()}\")\n",
    "\n",
    "print(f\"\\nGender: {df['user_gender'].value_counts().to_dict()}\")\n",
    "print(f\"Regions: {df['tweet_region'].value_counts().to_dict()}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Â· Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1 â€“ Category distribution\n",
    "df[\"tweet_category\"].value_counts().plot.bar(ax=axes[0, 0],\n",
    "    color=sns.color_palette(\"viridis\", df[\"tweet_category\"].nunique()))\n",
    "axes[0, 0].set_title(\"Tweet Category Distribution\")\n",
    "axes[0, 0].set_ylabel(\"Count\"); axes[0, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 2 â€“ Gender distribution\n",
    "df[\"user_gender\"].value_counts().plot.pie(ax=axes[0, 1], autopct=\"%1.1f%%\",\n",
    "    colors=[\"#06b6d4\", \"#f97316\"], startangle=90)\n",
    "axes[0, 1].set_title(\"Gender Distribution\"); axes[0, 1].set_ylabel(\"\")\n",
    "\n",
    "# 3 â€“ Region distribution\n",
    "df[\"tweet_region\"].value_counts().plot.bar(ax=axes[0, 2],\n",
    "    color=sns.color_palette(\"mako\", 4))\n",
    "axes[0, 2].set_title(\"Region Distribution\")\n",
    "axes[0, 2].set_ylabel(\"Count\"); axes[0, 2].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "# 4 â€“ Word count distribution\n",
    "df[\"word_count\"].hist(bins=30, ax=axes[1, 0], color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[1, 0].set_title(\"Word Count Distribution\")\n",
    "axes[1, 0].set_xlabel(\"Words\"); axes[1, 0].set_ylabel(\"Count\")\n",
    "\n",
    "# 5 â€“ Category by gender\n",
    "cat_gender = pd.crosstab(df[\"tweet_category\"], df[\"user_gender\"])\n",
    "cat_gender.plot.barh(ax=axes[1, 1], stacked=True, color=[\"#06b6d4\", \"#f97316\"])\n",
    "axes[1, 1].set_title(\"Categories by Gender\")\n",
    "axes[1, 1].set_xlabel(\"Count\"); axes[1, 1].legend(title=\"Gender\")\n",
    "\n",
    "# 6 â€“ Category by region\n",
    "cat_region = pd.crosstab(df[\"tweet_category\"], df[\"tweet_region\"])\n",
    "cat_region.plot.barh(ax=axes[1, 2], stacked=True, colormap=\"viridis\")\n",
    "axes[1, 2].set_title(\"Categories by Region\")\n",
    "axes[1, 2].set_xlabel(\"Count\"); axes[1, 2].legend(title=\"Region\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"eda_overview.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"âœ… EDA plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Â· Sentiment Analysis â€“ TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running TextBlob sentiment analysis on all tweets...\")\n",
    "df[\"tb_polarity\"] = df[\"tweet_text\"].apply(lambda t: TextBlob(t).sentiment.polarity)\n",
    "df[\"tb_subjectivity\"] = df[\"tweet_text\"].apply(lambda t: TextBlob(t).sentiment.subjectivity)\n",
    "\n",
    "# Classify sentiment\n",
    "df[\"tb_sentiment\"] = pd.cut(df[\"tb_polarity\"], bins=[-1.01, -0.05, 0.05, 1.01],\n",
    "                            labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "\n",
    "print(f\"Sentiment distribution:\\n{df['tb_sentiment'].value_counts()}\")\n",
    "print(f\"\\nPolarity stats:\\n{df['tb_polarity'].describe()}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1 â€“ Sentiment distribution\n",
    "df[\"tb_sentiment\"].value_counts().plot.bar(ax=axes[0],\n",
    "    color=[\"#ef4444\", \"#94a3b8\", \"#22c55e\"])\n",
    "axes[0].set_title(\"TextBlob Sentiment Distribution\")\n",
    "axes[0].set_ylabel(\"Count\"); axes[0].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "# 2 â€“ Polarity histogram\n",
    "df[\"tb_polarity\"].hist(bins=50, ax=axes[1], color=\"teal\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"Polarity Distribution\")\n",
    "axes[1].set_xlabel(\"Polarity\"); axes[1].axvline(0, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "# 3 â€“ Sentiment by category\n",
    "sent_cat = pd.crosstab(df[\"tweet_category\"], df[\"tb_sentiment\"])\n",
    "sent_cat_pct = sent_cat.div(sent_cat.sum(axis=1), axis=0)\n",
    "sent_cat_pct.plot.barh(ax=axes[2], stacked=True,\n",
    "    color=[\"#ef4444\", \"#94a3b8\", \"#22c55e\"])\n",
    "axes[2].set_title(\"Sentiment by Category (TextBlob)\")\n",
    "axes[2].set_xlabel(\"Proportion\"); axes[2].legend(title=\"Sentiment\", bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"textblob_sentiment.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"âœ… TextBlob sentiment plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Â· Sentiment Analysis â€“ BERT (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline as hf_pipeline\n",
    "\n",
    "print(\"Loading DistilBERT sentiment pipeline (distilbert-base-uncased-finetuned-sst-2-english)...\")\n",
    "bert_sentiment = hf_pipeline(\"sentiment-analysis\",\n",
    "                             model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                             device=-1,  # CPU\n",
    "                             truncation=True, max_length=512)\n",
    "\n",
    "# Run BERT on all tweets (batch for speed)\n",
    "print(f\"Running BERT sentiment on {len(df)} tweets...\")\n",
    "t0 = time.time()\n",
    "BATCH = 64\n",
    "bert_labels, bert_scores = [], []\n",
    "texts = df[\"tweet_text\"].tolist()\n",
    "for i in range(0, len(texts), BATCH):\n",
    "    batch = texts[i:i+BATCH]\n",
    "    # Truncate long texts\n",
    "    batch = [t[:500] for t in batch]\n",
    "    results = bert_sentiment(batch)\n",
    "    for r in results:\n",
    "        bert_labels.append(r[\"label\"])\n",
    "        bert_scores.append(r[\"score\"])\n",
    "    if (i // BATCH) % 10 == 0:\n",
    "        print(f\"  Processed {min(i+BATCH, len(texts))}/{len(texts)}...\")\n",
    "\n",
    "df[\"bert_label\"] = bert_labels\n",
    "df[\"bert_score\"] = bert_scores\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nâœ… BERT sentiment done in {elapsed:.1f}s\")\n",
    "print(f\"BERT sentiment distribution:\\n{df['bert_label'].value_counts()}\")\n",
    "\n",
    "# Compare TextBlob vs BERT\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1 â€“ BERT sentiment distribution\n",
    "df[\"bert_label\"].value_counts().plot.bar(ax=axes[0],\n",
    "    color=[\"#22c55e\", \"#ef4444\"])\n",
    "axes[0].set_title(\"BERT Sentiment Distribution\")\n",
    "axes[0].set_ylabel(\"Count\"); axes[0].tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "# 2 â€“ BERT confidence scores\n",
    "df[\"bert_score\"].hist(bins=50, ax=axes[1], color=\"purple\", edgecolor=\"white\")\n",
    "axes[1].set_title(\"BERT Confidence Score Distribution\")\n",
    "axes[1].set_xlabel(\"Confidence\")\n",
    "\n",
    "# 3 â€“ BERT sentiment by category\n",
    "bert_cat = pd.crosstab(df[\"tweet_category\"], df[\"bert_label\"])\n",
    "bert_cat_pct = bert_cat.div(bert_cat.sum(axis=1), axis=0)\n",
    "bert_cat_pct.plot.barh(ax=axes[2], stacked=True,\n",
    "    color=[\"#ef4444\", \"#22c55e\"])\n",
    "axes[2].set_title(\"BERT Sentiment by Category\")\n",
    "axes[2].set_xlabel(\"Proportion\"); axes[2].legend(title=\"Label\", bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"bert_sentiment.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Sentiment comparison summary\n",
    "print(\"\\n=== TextBlob vs BERT Comparison ===\")\n",
    "tb_pos_pct = (df[\"tb_sentiment\"] == \"Positive\").mean() * 100\n",
    "tb_neg_pct = (df[\"tb_sentiment\"] == \"Negative\").mean() * 100\n",
    "tb_neu_pct = (df[\"tb_sentiment\"] == \"Neutral\").mean() * 100\n",
    "bert_pos_pct = (df[\"bert_label\"] == \"POSITIVE\").mean() * 100\n",
    "bert_neg_pct = (df[\"bert_label\"] == \"NEGATIVE\").mean() * 100\n",
    "print(f\"TextBlob: Positive={tb_pos_pct:.1f}%, Neutral={tb_neu_pct:.1f}%, Negative={tb_neg_pct:.1f}%\")\n",
    "print(f\"BERT:     Positive={bert_pos_pct:.1f}%, Negative={bert_neg_pct:.1f}%\")\n",
    "print(\"âœ… BERT sentiment plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Â· Prepare Features (TF-IDF + Metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF on cleaned text\n",
    "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1, 2), stop_words=\"english\")\n",
    "X_tfidf = tfidf.fit_transform(df[\"clean_text\"])\n",
    "print(f\"TF-IDF shape: {X_tfidf.shape}\")\n",
    "\n",
    "# Metadata features\n",
    "meta_cols = [\"text_length\", \"word_count\", \"region_enc\", \"gender_enc\",\n",
    "             \"tweet_hour\", \"tweet_day\", \"tb_polarity\", \"tb_subjectivity\", \"bert_score\"]\n",
    "X_meta = df[meta_cols].fillna(0).values\n",
    "scaler_meta = StandardScaler()\n",
    "X_meta_s = scaler_meta.fit_transform(X_meta)\n",
    "\n",
    "# Combine TF-IDF + metadata\n",
    "X_combined = hstack([X_tfidf, csr_matrix(X_meta_s)])\n",
    "print(f\"Combined feature matrix: {X_combined.shape}\")\n",
    "\n",
    "# Targets\n",
    "y_cat = df[\"category_enc\"].values\n",
    "y_gender = df[\"gender_enc\"].values\n",
    "\n",
    "print(f\"Category classes: {le_cat.classes_}\")\n",
    "print(f\"Gender classes: {le_gender.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Â· Tweet Category Classification (10 Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_combined, y_cat, test_size=0.2, random_state=SEED, stratify=y_cat\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    \"Multinomial NB\": MultinomialNB(alpha=0.1),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=7),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=SEED),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=150, random_state=SEED),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, eval_metric=\"mlogloss\", random_state=SEED, n_jobs=-1),\n",
    "    \"Linear SVM\": LinearSVC(max_iter=2000, random_state=SEED),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=400, random_state=SEED),\n",
    "}\n",
    "\n",
    "# MultinomialNB needs non-negative input â€“ use TF-IDF only\n",
    "X_train_tfidf_only = X_train_c[:, :3000]\n",
    "X_test_tfidf_only = X_test_c[:, :3000]\n",
    "\n",
    "clf_results = {}\n",
    "for name, model in classifiers.items():\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    if name == \"Multinomial NB\":\n",
    "        model.fit(X_train_tfidf_only, y_train_c)\n",
    "        y_pred = model.predict(X_test_tfidf_only)\n",
    "    else:\n",
    "        model.fit(X_train_c, y_train_c)\n",
    "        y_pred = model.predict(X_test_c)\n",
    "    acc = accuracy_score(y_test_c, y_pred)\n",
    "    f1 = f1_score(y_test_c, y_pred, average=\"weighted\")\n",
    "    clf_results[name] = {\"accuracy\": acc, \"f1\": f1, \"model\": model, \"y_pred\": y_pred}\n",
    "    print(f\"Acc={acc:.4f}  F1={f1:.4f}\")\n",
    "\n",
    "best_clf_name = max(clf_results, key=lambda k: clf_results[k][\"f1\"])\n",
    "print(f\"\\nðŸ† Best classifier: {best_clf_name} (F1={clf_results[best_clf_name]['f1']:.4f})\")\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "names = list(clf_results.keys())\n",
    "accs = [clf_results[n][\"accuracy\"] for n in names]\n",
    "f1s = [clf_results[n][\"f1\"] for n in names]\n",
    "x = np.arange(len(names))\n",
    "ax.bar(x - 0.2, accs, 0.4, label=\"Accuracy\", color=\"steelblue\")\n",
    "ax.bar(x + 0.2, f1s, 0.4, label=\"F1 (weighted)\", color=\"coral\")\n",
    "ax.set_xticks(x); ax.set_xticklabels(names, rotation=45, ha=\"right\")\n",
    "ax.set_ylim(0, 1); ax.set_title(\"Category Classification â€“ Model Comparison\")\n",
    "ax.legend(); plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"category_model_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"âœ… Category model comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Â· Gender Prediction from Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "    X_combined, y_gender, test_size=0.2, random_state=SEED, stratify=y_gender\n",
    ")\n",
    "\n",
    "gender_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=SEED),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, eval_metric=\"logloss\", random_state=SEED, n_jobs=-1),\n",
    "    \"Linear SVM\": LinearSVC(max_iter=2000, random_state=SEED),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=400, random_state=SEED),\n",
    "}\n",
    "\n",
    "gender_results = {}\n",
    "for name, model in gender_models.items():\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    model.fit(X_train_g, y_train_g)\n",
    "    y_pred = model.predict(X_test_g)\n",
    "    acc = accuracy_score(y_test_g, y_pred)\n",
    "    f1 = f1_score(y_test_g, y_pred, average=\"weighted\")\n",
    "    gender_results[name] = {\"accuracy\": acc, \"f1\": f1, \"model\": model, \"y_pred\": y_pred}\n",
    "    print(f\"Acc={acc:.4f}  F1={f1:.4f}\")\n",
    "\n",
    "best_gender_name = max(gender_results, key=lambda k: gender_results[k][\"f1\"])\n",
    "print(f\"\\nðŸ† Best gender predictor: {best_gender_name} (F1={gender_results[best_gender_name]['f1']:.4f})\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "names_g = list(gender_results.keys())\n",
    "f1s_g = [gender_results[n][\"f1\"] for n in names_g]\n",
    "ax.barh(names_g, f1s_g, color=sns.color_palette(\"rocket\", len(names_g)))\n",
    "ax.set_title(\"Gender Prediction â€“ F1 Scores\"); ax.set_xlabel(\"F1 (weighted)\")\n",
    "ax.set_xlim(0, 1)\n",
    "for i, v in enumerate(f1s_g):\n",
    "    ax.text(v + 0.01, i, f\"{v:.4f}\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"gender_model_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"âœ… Gender model comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Â· Tweet Clustering (TF-IDF + K-Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce TF-IDF dimensionality for clustering\n",
    "svd = TruncatedSVD(n_components=50, random_state=SEED)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "print(f\"SVD explained variance: {svd.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "K_range = range(2, 12)\n",
    "inertias, sils = [], []\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=SEED, n_init=10)\n",
    "    labels = km.fit_predict(X_svd)\n",
    "    inertias.append(km.inertia_)\n",
    "    sils.append(silhouette_score(X_svd, labels))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax1.plot(list(K_range), inertias, \"bo-\"); ax1.set_title(\"Elbow Method\")\n",
    "ax1.set_xlabel(\"k\"); ax1.set_ylabel(\"Inertia\")\n",
    "ax2.plot(list(K_range), sils, \"rs-\"); ax2.set_title(\"Silhouette Score\")\n",
    "ax2.set_xlabel(\"k\"); ax2.set_ylabel(\"Score\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"elbow_silhouette.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "best_k = list(K_range)[np.argmax(sils)]\n",
    "print(f\"Best k={best_k}, silhouette={max(sils):.4f}\")\n",
    "\n",
    "km_final = KMeans(n_clusters=best_k, random_state=SEED, n_init=10)\n",
    "df[\"cluster\"] = km_final.fit_predict(X_svd)\n",
    "\n",
    "# Cluster vs actual category crosstab\n",
    "clust_cat = pd.crosstab(df[\"cluster\"], df[\"tweet_category\"])\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "clust_cat.plot.bar(ax=ax, stacked=True, colormap=\"viridis\")\n",
    "ax.set_title(f\"Cluster vs Tweet Category (k={best_k})\")\n",
    "ax.set_xlabel(\"Cluster\"); ax.set_ylabel(\"Count\")\n",
    "ax.legend(title=\"Category\", bbox_to_anchor=(1.05, 1), fontsize=8)\n",
    "ax.tick_params(axis=\"x\", rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"clustering_results.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Top words per cluster\n",
    "print(\"\\nTop words per cluster:\")\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "order_centroids = km_final.cluster_centers_.argsort()[:, ::-1]\n",
    "# We need to project centroids back; use SVD components\n",
    "centroids_tfidf = km_final.cluster_centers_ @ svd.components_\n",
    "order_centroids_full = centroids_tfidf.argsort()[:, ::-1]\n",
    "for i in range(best_k):\n",
    "    top_words = [feature_names[j] for j in order_centroids_full[i, :10]]\n",
    "    print(f\"  Cluster {i}: {', '.join(top_words)}\")\n",
    "\n",
    "print(\"âœ… Clustering plots saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Â· Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV â€“ Logistic Regression\n",
    "print(\"GridSearchCV on Logistic Regression (category)...\")\n",
    "lr_grid = {\n",
    "    \"C\": [0.1, 1.0, 10.0],\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"solver\": [\"liblinear\"],\n",
    "}\n",
    "gs_lr = GridSearchCV(LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "                     lr_grid, cv=3, scoring=\"f1_weighted\", n_jobs=-1)\n",
    "gs_lr.fit(X_train_c, y_train_c)\n",
    "print(f\"  Best params: {gs_lr.best_params_}\")\n",
    "print(f\"  Best CV F1:  {gs_lr.best_score_:.4f}\")\n",
    "\n",
    "# RandomizedSearchCV â€“ Random Forest\n",
    "print(\"\\nRandomizedSearchCV on Random Forest (category)...\")\n",
    "rf_dist = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [10, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "}\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "                           rf_dist, n_iter=15, cv=3, scoring=\"f1_weighted\",\n",
    "                           random_state=SEED, n_jobs=-1)\n",
    "rs_rf.fit(X_train_c, y_train_c)\n",
    "print(f\"  Best params: {rs_rf.best_params_}\")\n",
    "print(f\"  Best CV F1:  {rs_rf.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate tuned models\n",
    "for label, model in [(\"Tuned LR (Grid)\", gs_lr.best_estimator_),\n",
    "                     (\"Tuned RF (Random)\", rs_rf.best_estimator_)]:\n",
    "    y_pred = model.predict(X_test_c)\n",
    "    acc = accuracy_score(y_test_c, y_pred)\n",
    "    f1 = f1_score(y_test_c, y_pred, average=\"weighted\")\n",
    "    clf_results[label] = {\"accuracy\": acc, \"f1\": f1, \"model\": model, \"y_pred\": y_pred}\n",
    "    print(f\"  {label}: Acc={acc:.4f}  F1={f1:.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Hyperparameter tuning complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Â· Cross-Validation, Confusion Matrices & Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 5-fold CV â”€â”€\n",
    "cv_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, random_state=SEED),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, eval_metric=\"mlogloss\", random_state=SEED, n_jobs=-1),\n",
    "}\n",
    "cv_scores = {}\n",
    "for name, model in cv_models.items():\n",
    "    scores = cross_val_score(model, X_combined, y_cat, cv=5, scoring=\"f1_weighted\", n_jobs=-1)\n",
    "    cv_scores[name] = scores\n",
    "    print(f\"{name}: mean F1={scores.mean():.4f} Â± {scores.std():.4f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.boxplot(cv_scores.values(), labels=cv_scores.keys())\n",
    "ax.set_title(\"5-Fold Cross-Validation F1 Scores (Category)\")\n",
    "ax.set_ylabel(\"F1 (weighted)\"); ax.tick_params(axis=\"x\", rotation=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"cv_comparison.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# â”€â”€ Confusion matrices (top 4) â”€â”€\n",
    "top4 = sorted(clf_results, key=lambda k: clf_results[k][\"f1\"], reverse=True)[:4]\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "for ax, name in zip(axes, top4):\n",
    "    cm = confusion_matrix(y_test_c, clf_results[name][\"y_pred\"])\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=le_cat.classes_, yticklabels=le_cat.classes_)\n",
    "    ax.set_title(f\"{name}\\nF1={clf_results[name]['f1']:.4f}\", fontsize=9)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "    ax.tick_params(axis=\"both\", labelsize=6, rotation=45)\n",
    "plt.suptitle(\"Confusion Matrices â€“ Top 4 Models\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"confusion_matrices.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# â”€â”€ Learning curves â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for ax, (name, model) in zip(axes, [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "]):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X_combined, y_cat, cv=3, n_jobs=-1,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 8), scoring=\"f1_weighted\"\n",
    "    )\n",
    "    ax.plot(train_sizes, train_scores.mean(axis=1), \"o-\", label=\"Train\")\n",
    "    ax.plot(train_sizes, val_scores.mean(axis=1), \"s-\", label=\"Validation\")\n",
    "    ax.set_title(f\"Learning Curve â€“ {name}\")\n",
    "    ax.set_xlabel(\"Training Size\"); ax.set_ylabel(\"F1 (weighted)\")\n",
    "    ax.legend(); ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOT_DIR / \"learning_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"âœ… CV, confusion matrices & learning curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Â· Voting & Stacking Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "print(\"Training Voting Classifier...\")\n",
    "voting = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lr\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "        (\"rf\", RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1)),\n",
    "        (\"gb\", GradientBoostingClassifier(n_estimators=200, random_state=SEED)),\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")\n",
    "voting.fit(X_train_c, y_train_c)\n",
    "y_pred_v = voting.predict(X_test_c)\n",
    "acc_v = accuracy_score(y_test_c, y_pred_v)\n",
    "f1_v = f1_score(y_test_c, y_pred_v, average=\"weighted\")\n",
    "clf_results[\"Voting Ensemble\"] = {\"accuracy\": acc_v, \"f1\": f1_v, \"model\": voting, \"y_pred\": y_pred_v}\n",
    "print(f\"  Voting: Acc={acc_v:.4f}  F1={f1_v:.4f}\")\n",
    "\n",
    "# Stacking Classifier\n",
    "print(\"Training Stacking Classifier...\")\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"lr\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "        (\"rf\", RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1)),\n",
    "        (\"gb\", GradientBoostingClassifier(n_estimators=200, random_state=SEED)),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    cv=3, n_jobs=-1\n",
    ")\n",
    "stacking.fit(X_train_c, y_train_c)\n",
    "y_pred_s = stacking.predict(X_test_c)\n",
    "acc_s = accuracy_score(y_test_c, y_pred_s)\n",
    "f1_s = f1_score(y_test_c, y_pred_s, average=\"weighted\")\n",
    "clf_results[\"Stacking Ensemble\"] = {\"accuracy\": acc_s, \"f1\": f1_s, \"model\": stacking, \"y_pred\": y_pred_s}\n",
    "print(f\"  Stacking: Acc={acc_s:.4f}  F1={f1_s:.4f}\")\n",
    "\n",
    "# Final rankings\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL MODEL RANKING â€“ Category Classification\")\n",
    "print(\"=\"*60)\n",
    "ranking = sorted(clf_results.items(), key=lambda x: x[1][\"f1\"], reverse=True)\n",
    "for i, (name, res) in enumerate(ranking, 1):\n",
    "    print(f\"  {i:>2}. {name:<25s} Acc={res['accuracy']:.4f}  F1={res['f1']:.4f}\")\n",
    "best_overall = ranking[0][0]\n",
    "print(f\"\\nðŸ† Best overall: {best_overall} (F1={clf_results[best_overall]['f1']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENDER PREDICTION RANKING\")\n",
    "print(\"=\"*60)\n",
    "g_ranking = sorted(gender_results.items(), key=lambda x: x[1][\"f1\"], reverse=True)\n",
    "for i, (name, res) in enumerate(g_ranking, 1):\n",
    "    print(f\"  {i:>2}. {name:<25s} Acc={res['accuracy']:.4f}  F1={res['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Â· Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_base64(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode()\n",
    "\n",
    "images = {}\n",
    "for p in sorted(PLOT_DIR.glob(\"*.png\")):\n",
    "    images[p.stem] = img_to_base64(p)\n",
    "\n",
    "TEMPLATE = \"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\"><head><meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
    "<title>ðŸŽ† New Year's Resolutions â€“ ML & NLP Report</title>\n",
    "<style>\n",
    ":root{--bg:#0f172a;--card:#1e293b;--accent:#06b6d4;--text:#e2e8f0;--muted:#94a3b8}\n",
    "*{margin:0;padding:0;box-sizing:border-box}\n",
    "body{background:var(--bg);color:var(--text);font-family:'Segoe UI',system-ui,sans-serif;padding:2rem}\n",
    "h1{text-align:center;font-size:2.2rem;margin-bottom:.4rem;color:var(--accent)}\n",
    ".subtitle{text-align:center;color:var(--muted);margin-bottom:2rem}\n",
    ".card{background:var(--card);border-radius:12px;padding:1.5rem;margin-bottom:1.5rem;box-shadow:0 4px 24px #0004}\n",
    ".card h2{color:var(--accent);margin-bottom:1rem;font-size:1.3rem}\n",
    "table{width:100%;border-collapse:collapse;margin:1rem 0}\n",
    "th,td{padding:.55rem .8rem;text-align:left;border-bottom:1px solid #334155}\n",
    "th{color:var(--accent);font-size:.85rem;text-transform:uppercase}\n",
    "tr:hover{background:#ffffff08}\n",
    ".best{background:#06b6d415;font-weight:700}\n",
    "img{width:100%;border-radius:8px;margin:.8rem 0}\n",
    ".grid2{display:grid;grid-template-columns:1fr 1fr;gap:1.2rem}\n",
    "@media(max-width:800px){.grid2{grid-template-columns:1fr}}\n",
    ".tag{display:inline-block;padding:2px 10px;border-radius:6px;font-size:.82rem;background:#06b6d422;color:var(--accent);margin:2px}\n",
    ".stat-row{display:flex;gap:1.5rem;flex-wrap:wrap;margin:.8rem 0}\n",
    ".stat-box{background:#06b6d410;border:1px solid #06b6d433;border-radius:8px;padding:1rem 1.5rem;text-align:center;flex:1;min-width:150px}\n",
    ".stat-box .val{font-size:1.6rem;font-weight:700;color:var(--accent)}\n",
    ".stat-box .lbl{font-size:.8rem;color:var(--muted);margin-top:.3rem}\n",
    "</style></head><body>\n",
    "<h1>ðŸŽ† New Year's Resolutions â€“ ML & NLP Report</h1>\n",
    "<p class=\"subtitle\">4,723 tweets Â· 10 categories Â· Sentiment Analysis (TextBlob + BERT)</p>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸ“Š Exploratory Data Analysis</h2>\n",
    "<img src=\"data:image/png;base64,{{images.eda_overview}}\" alt=\"EDA Overview\">\n",
    "</div>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸ’¬ Sentiment Analysis â€“ TextBlob</h2>\n",
    "<div class=\"stat-row\">\n",
    "<div class=\"stat-box\"><div class=\"val\">{{\"{:.1f}%\".format(tb_pos_pct)}}</div><div class=\"lbl\">Positive</div></div>\n",
    "<div class=\"stat-box\"><div class=\"val\">{{\"{:.1f}%\".format(tb_neu_pct)}}</div><div class=\"lbl\">Neutral</div></div>\n",
    "<div class=\"stat-box\"><div class=\"val\">{{\"{:.1f}%\".format(tb_neg_pct)}}</div><div class=\"lbl\">Negative</div></div>\n",
    "</div>\n",
    "<img src=\"data:image/png;base64,{{images.textblob_sentiment}}\" alt=\"TextBlob Sentiment\">\n",
    "</div>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸ¤– Sentiment Analysis â€“ BERT (DistilBERT)</h2>\n",
    "<div class=\"stat-row\">\n",
    "<div class=\"stat-box\"><div class=\"val\">{{\"{:.1f}%\".format(bert_pos_pct)}}</div><div class=\"lbl\">Positive</div></div>\n",
    "<div class=\"stat-box\"><div class=\"val\">{{\"{:.1f}%\".format(bert_neg_pct)}}</div><div class=\"lbl\">Negative</div></div>\n",
    "<div class=\"stat-box\"><div class=\"val\">{{\"{:.3f}\".format(bert_avg_conf)}}</div><div class=\"lbl\">Avg Confidence</div></div>\n",
    "</div>\n",
    "<img src=\"data:image/png;base64,{{images.bert_sentiment}}\" alt=\"BERT Sentiment\">\n",
    "</div>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸŽ¯ Task 1 â€“ Tweet Category Classification (10 categories)</h2>\n",
    "<table><tr><th>#</th><th>Model</th><th>Accuracy</th><th>F1 (weighted)</th></tr>\n",
    "{% for name, res in clf_ranking %}\n",
    "<tr{% if loop.first %} class=\"best\"{% endif %}>\n",
    "<td>{{loop.index}}</td><td>{{name}}</td>\n",
    "<td>{{\"{:.4f}\".format(res.accuracy)}}</td><td>{{\"{:.4f}\".format(res.f1)}}</td></tr>\n",
    "{% endfor %}</table>\n",
    "<img src=\"data:image/png;base64,{{images.category_model_comparison}}\" alt=\"Category Model Comparison\">\n",
    "</div>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸ‘¤ Task 2 â€“ Gender Prediction from Tweets</h2>\n",
    "<table><tr><th>#</th><th>Model</th><th>Accuracy</th><th>F1 (weighted)</th></tr>\n",
    "{% for name, res in gender_ranking %}\n",
    "<tr{% if loop.first %} class=\"best\"{% endif %}>\n",
    "<td>{{loop.index}}</td><td>{{name}}</td>\n",
    "<td>{{\"{:.4f}\".format(res.accuracy)}}</td><td>{{\"{:.4f}\".format(res.f1)}}</td></tr>\n",
    "{% endfor %}</table>\n",
    "<img src=\"data:image/png;base64,{{images.gender_model_comparison}}\" alt=\"Gender Model Comparison\">\n",
    "</div>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸ”¬ Task 3 â€“ Tweet Clustering</h2>\n",
    "<p>Best k={{best_k}}, Silhouette={{\"{:.4f}\".format(best_sil)}}</p>\n",
    "<div class=\"grid2\">\n",
    "<img src=\"data:image/png;base64,{{images.elbow_silhouette}}\" alt=\"Elbow & Silhouette\">\n",
    "<img src=\"data:image/png;base64,{{images.clustering_results}}\" alt=\"Clustering Results\">\n",
    "</div></div>\n",
    "\n",
    "<div class=\"card\"><h2>ðŸ”§ Hyperparameter Tuning & Cross-Validation</h2>\n",
    "<img src=\"data:image/png;base64,{{images.cv_comparison}}\" alt=\"CV Comparison\">\n",
    "<img src=\"data:image/png;base64,{{images.confusion_matrices}}\" alt=\"Confusion Matrices\">\n",
    "<img src=\"data:image/png;base64,{{images.learning_curves}}\" alt=\"Learning Curves\">\n",
    "</div>\n",
    "\n",
    "</body></html>\"\"\"\n",
    "\n",
    "from types import SimpleNamespace\n",
    "clf_ranking = [(n, SimpleNamespace(**{k: v for k, v in r.items() if k != \"model\" and k != \"y_pred\"}))\n",
    "               for n, r in sorted(clf_results.items(), key=lambda x: x[1][\"f1\"], reverse=True)]\n",
    "gender_ranking = [(n, SimpleNamespace(**{k: v for k, v in r.items() if k != \"model\" and k != \"y_pred\"}))\n",
    "                  for n, r in sorted(gender_results.items(), key=lambda x: x[1][\"f1\"], reverse=True)]\n",
    "\n",
    "html = jinja2.Template(TEMPLATE).render(\n",
    "    images=images,\n",
    "    clf_ranking=clf_ranking,\n",
    "    gender_ranking=gender_ranking,\n",
    "    tb_pos_pct=tb_pos_pct, tb_neu_pct=tb_neu_pct, tb_neg_pct=tb_neg_pct,\n",
    "    bert_pos_pct=bert_pos_pct, bert_neg_pct=bert_neg_pct,\n",
    "    bert_avg_conf=df[\"bert_score\"].mean(),\n",
    "    best_k=best_k, best_sil=max(sils),\n",
    ")\n",
    "\n",
    "out_path = pathlib.Path(\"outputs/nyr_ml_report.html\")\n",
    "out_path.write_text(html)\n",
    "print(f\"âœ… HTML Report generated: {out_path}\")\n",
    "print(f\"   File size: {out_path.stat().st_size / 1024:.1f} KB\")\n",
    "print(f\"   Embedded images: {len(images)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
