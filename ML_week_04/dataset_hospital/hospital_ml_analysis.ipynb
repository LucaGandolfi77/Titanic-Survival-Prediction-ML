{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Hospital Patient Records ‚Äì Comprehensive ML Analysis\n",
    "\n",
    "**Dataset:** Synthea-generated records from Massachusetts General Hospital\n",
    "| Table | Rows | Key Fields |\n",
    "|---|---|---|\n",
    "| Patients | 974 | Demographics, birth/death, location |\n",
    "| Encounters | 27,891 | Visit type, costs, diagnosis, payer |\n",
    "| Procedures | 47,701 | Medical procedures, costs |\n",
    "| Payers | 10 | Insurance providers |\n",
    "\n",
    "**ML Tasks:** Encounter Classification ¬∑ Mortality Prediction ¬∑ Cost Regression ¬∑ Patient Clustering\n",
    "**Techniques:** 10+ algorithms, cross-validation, hyperparameter tuning, ensemble methods, feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n",
      "  scikit-learn 1.8.0\n",
      "  pandas 3.0.1, numpy 2.4.2\n",
      "  Jinja2: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, os, base64\n",
    "from io import BytesIO\n",
    "\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "    StratifiedKFold, GridSearchCV, RandomizedSearchCV, learning_curve)\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report, roc_curve, auc,\n",
    "    mean_squared_error, mean_absolute_error, r2_score, silhouette_score)\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    VotingClassifier, StackingClassifier, AdaBoostClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "try:\n",
    "    from jinja2 import Template\n",
    "    HAS_JINJA2 = True\n",
    "except ImportError:\n",
    "    HAS_JINJA2 = False\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "os.makedirs(\"outputs/plots\", exist_ok=True)\n",
    "\n",
    "report_images = {}\n",
    "\n",
    "def save_plot(fig, name):\n",
    "    \"\"\"Save a figure to PNG and store base64 for the report.\"\"\"\n",
    "    fig.savefig(f\"outputs/plots/{name}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=150, bbox_inches=\"tight\")\n",
    "    buf.seek(0)\n",
    "    report_images[name] = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    plt.close(fig)\n",
    "    print(f\"  Plot saved: {name}.png\")\n",
    "\n",
    "# Result dictionaries\n",
    "results = {}\n",
    "regression_results = {}\n",
    "mortality_results = {}\n",
    "\n",
    "print(\"All imports successful\")\n",
    "print(f\"  scikit-learn {__import__('sklearn').__version__}\")\n",
    "print(f\"  pandas {pd.__version__}, numpy {np.__version__}\")\n",
    "print(f\"  Jinja2: {HAS_JINJA2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded:\n",
      "  patients       :    974 rows x 20 columns\n",
      "  encounters     : 27,891 rows x 14 columns\n",
      "  procedures     : 47,701 rows x  9 columns\n",
      "  organizations  :      1 rows x  8 columns\n",
      "  payers         :     10 rows x  7 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>BIRTHDATE</th>\n",
       "      <th>DEATHDATE</th>\n",
       "      <th>PREFIX</th>\n",
       "      <th>FIRST</th>\n",
       "      <th>LAST</th>\n",
       "      <th>SUFFIX</th>\n",
       "      <th>MAIDEN</th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>RACE</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>BIRTHPLACE</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5605b66b-e92d-c16c-1b83-b8bf7040d51f</td>\n",
       "      <td>1977-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Nikita578</td>\n",
       "      <td>Erdman779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leannon79</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>F</td>\n",
       "      <td>Wakefield&nbsp;&nbsp;Massachusetts&nbsp;&nbsp;US</td>\n",
       "      <td>510 Little Station Unit 69</td>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Norfolk County</td>\n",
       "      <td>2186.0</td>\n",
       "      <td>42.290937</td>\n",
       "      <td>-70.975503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6e5ae27c-8038-7988-e2c0-25a103f01bfa</td>\n",
       "      <td>1940-02-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Zane918</td>\n",
       "      <td>Hodkiewicz467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>Brookline&nbsp;&nbsp;Massachusetts&nbsp;&nbsp;US</td>\n",
       "      <td>747 Conn Throughway</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Suffolk County</td>\n",
       "      <td>2135.0</td>\n",
       "      <td>42.308831</td>\n",
       "      <td>-71.063162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8123d076-0886-9007-e956-d5864aa121a7</td>\n",
       "      <td>1958-06-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Quinn173</td>\n",
       "      <td>Marquardt819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>nonhispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>Gardner&nbsp;&nbsp;Massachusetts&nbsp;&nbsp;US</td>\n",
       "      <td>816 Okuneva Extension Apt 91</td>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Norfolk County</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>42.265177</td>\n",
       "      <td>-70.967085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>770518e4-6133-648e-60c9-071eb2f0e2ce</td>\n",
       "      <td>1928-12-25</td>\n",
       "      <td>2017-09-29</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Abel832</td>\n",
       "      <td>Smitham825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>Randolph&nbsp;&nbsp;Massachusetts&nbsp;&nbsp;US</td>\n",
       "      <td>127 Cole Way Unit 95</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Suffolk County</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>42.334304</td>\n",
       "      <td>-71.066801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f96addf5-81b9-0aab-7855-d208d3d352c5</td>\n",
       "      <td>1928-12-25</td>\n",
       "      <td>2014-02-23</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>Edwin773</td>\n",
       "      <td>Labadie908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>white</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>M</td>\n",
       "      <td>Stow&nbsp;&nbsp;Massachusetts&nbsp;&nbsp;US</td>\n",
       "      <td>976 Ziemann Gateway</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Suffolk County</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>42.346771</td>\n",
       "      <td>-71.058813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   BIRTHDATE   DEATHDATE PREFIX  \\\n",
       "0  5605b66b-e92d-c16c-1b83-b8bf7040d51f  1977-03-19         NaN   Mrs.   \n",
       "1  6e5ae27c-8038-7988-e2c0-25a103f01bfa  1940-02-19         NaN    Mr.   \n",
       "2  8123d076-0886-9007-e956-d5864aa121a7  1958-06-04         NaN    Mr.   \n",
       "3  770518e4-6133-648e-60c9-071eb2f0e2ce  1928-12-25  2017-09-29    Mr.   \n",
       "4  f96addf5-81b9-0aab-7855-d208d3d352c5  1928-12-25  2014-02-23    Mr.   \n",
       "\n",
       "       FIRST           LAST SUFFIX     MAIDEN MARITAL   RACE    ETHNICITY  \\\n",
       "0  Nikita578      Erdman779    NaN  Leannon79       M  white  nonhispanic   \n",
       "1    Zane918  Hodkiewicz467    NaN        NaN       M  white  nonhispanic   \n",
       "2   Quinn173   Marquardt819    NaN        NaN       M  white  nonhispanic   \n",
       "3    Abel832     Smitham825    NaN        NaN       M  white     hispanic   \n",
       "4   Edwin773     Labadie908    NaN        NaN       M  white     hispanic   \n",
       "\n",
       "  GENDER                    BIRTHPLACE                       ADDRESS    CITY  \\\n",
       "0      F  Wakefield  Massachusetts  US    510 Little Station Unit 69  Quincy   \n",
       "1      M  Brookline  Massachusetts  US           747 Conn Throughway  Boston   \n",
       "2      M    Gardner  Massachusetts  US  816 Okuneva Extension Apt 91  Quincy   \n",
       "3      M   Randolph  Massachusetts  US          127 Cole Way Unit 95  Boston   \n",
       "4      M       Stow  Massachusetts  US           976 Ziemann Gateway  Boston   \n",
       "\n",
       "           STATE          COUNTY     ZIP        LAT        LON  \n",
       "0  Massachusetts  Norfolk County  2186.0  42.290937 -70.975503  \n",
       "1  Massachusetts  Suffolk County  2135.0  42.308831 -71.063162  \n",
       "2  Massachusetts  Norfolk County  2170.0  42.265177 -70.967085  \n",
       "3  Massachusetts  Suffolk County  2118.0  42.334304 -71.066801  \n",
       "4  Massachusetts  Suffolk County  2125.0  42.346771 -71.058813  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"Hospital+Patient+Records\"\n",
    "patients    = pd.read_csv(f\"{DATA_DIR}/patients.csv\")\n",
    "encounters  = pd.read_csv(f\"{DATA_DIR}/encounters.csv\")\n",
    "procedures  = pd.read_csv(f\"{DATA_DIR}/procedures.csv\")\n",
    "organizations = pd.read_csv(f\"{DATA_DIR}/organizations.csv\")\n",
    "payers      = pd.read_csv(f\"{DATA_DIR}/payers.csv\")\n",
    "\n",
    "print(\"Dataset Loaded:\")\n",
    "for name, df in [(\"patients\", patients), (\"encounters\", encounters),\n",
    "                  (\"procedures\", procedures), (\"organizations\", organizations),\n",
    "                  (\"payers\", payers)]:\n",
    "    print(f\"  {name:15s}: {df.shape[0]:>6,} rows x {df.shape[1]:>2} columns\")\n",
    "\n",
    "patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PATIENTS TABLE\n",
      "============================================================\n",
      "Missing values:\n",
      "DEATHDATE    820\n",
      "SUFFIX       953\n",
      "MAIDEN       588\n",
      "MARITAL        1\n",
      "ZIP          142\n",
      "dtype: int64\n",
      "\n",
      "Gender:    {'M': 494, 'F': 480}\n",
      "Race:      {'white': 680, 'black': 163, 'asian': 91, 'other': 16, 'hawaiian': 13, 'native': 11}\n",
      "Marital:   {'M': 784, 'S': 189}\n",
      "Deceased:  154 / 974 (15.8%)\n",
      "\n",
      "============================================================\n",
      "ENCOUNTERS TABLE\n",
      "============================================================\n",
      "Classes:  {'ambulatory': 12537, 'outpatient': 6300, 'urgentcare': 3666, 'emergency': 2322, 'wellness': 1931, 'inpatient': 1135}\n",
      "Date range: 2011-01-02 to 2022-02-05\n",
      "       BASE_ENCOUNTER_COST  TOTAL_CLAIM_COST  PAYER_COVERAGE\n",
      "count             27891.00          27891.00        27891.00\n",
      "mean                116.18           3639.68         1114.97\n",
      "std                  28.41           9205.60         4768.62\n",
      "min                  85.55              0.00            0.00\n",
      "25%                  85.55            142.58            0.00\n",
      "50%                 136.80            278.58           28.44\n",
      "75%                 142.58           1412.53          155.77\n",
      "max                 146.18         641882.70       247751.42\n",
      "\n",
      "============================================================\n",
      "TOP 10 PROCEDURES\n",
      "============================================================\n",
      "DESCRIPTION\n",
      "Assessment of health and social care needs (procedure)                                4596\n",
      "Hospice care (regime/therapy)                                                         4098\n",
      "Depression screening (procedure)                                                      3614\n",
      "Depression screening using Patient Health Questionnaire Two-Item score (procedure)    3614\n",
      "Assessment of substance use (procedure)                                               2906\n",
      "Renal dialysis (procedure)                                                            2746\n",
      "Assessment using Morse Fall Scale (procedure)                                         2422\n",
      "Assessment of anxiety (procedure)                                                     2288\n",
      "Medication Reconciliation (procedure)                                                 2284\n",
      "Screening for drug abuse (procedure)                                                  1484\n",
      "Name: count, dtype: int64\n",
      "\n",
      "PAYERS:\n",
      "                     NAME\n",
      "0           Dual Eligible\n",
      "1                Medicare\n",
      "2                Medicaid\n",
      "3                  Humana\n",
      "4  Blue Cross Blue Shield\n",
      "5        UnitedHealthcare\n",
      "6                   Aetna\n",
      "7            Cigna Health\n",
      "8                  Anthem\n",
      "9            NO_INSURANCE\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PATIENTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "missing = patients.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "print(f\"Missing values:\\n{missing}\" if len(missing) else \"No missing values (required fields)\")\n",
    "print(f\"\\nGender:    {patients['GENDER'].value_counts().to_dict()}\")\n",
    "print(f\"Race:      {patients['RACE'].value_counts().to_dict()}\")\n",
    "print(f\"Marital:   {patients['MARITAL'].value_counts().to_dict()}\")\n",
    "deceased_n = patients[\"DEATHDATE\"].notna().sum()\n",
    "print(f\"Deceased:  {deceased_n} / {len(patients)} ({deceased_n/len(patients)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENCOUNTERS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Classes:  {encounters['ENCOUNTERCLASS'].value_counts().to_dict()}\")\n",
    "print(f\"Date range: {encounters['START'].min()[:10]} to {encounters['START'].max()[:10]}\")\n",
    "print(encounters[[\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\"]].describe().round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 10 PROCEDURES\")\n",
    "print(\"=\" * 60)\n",
    "print(procedures[\"DESCRIPTION\"].value_counts().head(10))\n",
    "print(\"\\nPAYERS:\")\n",
    "print(payers[[\"NAME\"]].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Integration & Feature Engineering\n",
    "\n",
    "Merge all five tables and create derived features for ML modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounter-level dataset: (27891, 43)\n",
      "Patient-level dataset:   (974, 28)\n",
      "\n",
      "Encounter classes:\n",
      "ENCOUNTERCLASS\n",
      "ambulatory    12537\n",
      "outpatient     6300\n",
      "urgentcare     3666\n",
      "emergency      2322\n",
      "wellness       1931\n",
      "inpatient      1135\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mortality: {0: 820, 1: 154}\n",
      "\n",
      "Merged datasets saved to outputs/\n"
     ]
    }
   ],
   "source": [
    "# --- Parse dates ---\n",
    "patients[\"BIRTHDATE\"] = pd.to_datetime(patients[\"BIRTHDATE\"])\n",
    "patients[\"DEATHDATE\"] = pd.to_datetime(patients[\"DEATHDATE\"])\n",
    "patients[\"Is_Deceased\"] = patients[\"DEATHDATE\"].notna().astype(int)\n",
    "encounters[\"START\"] = pd.to_datetime(encounters[\"START\"], utc=True)\n",
    "encounters[\"STOP\"]  = pd.to_datetime(encounters[\"STOP\"], utc=True)\n",
    "\n",
    "ref_date = encounters[\"START\"].max()\n",
    "patients[\"BIRTHDATE\"] = patients[\"BIRTHDATE\"].dt.tz_localize(\"UTC\")\n",
    "patients[\"DEATHDATE\"] = patients[\"DEATHDATE\"].dt.tz_localize(\"UTC\")\n",
    "patients[\"Age\"] = ((ref_date - patients[\"BIRTHDATE\"]).dt.days / 365.25).astype(int)\n",
    "\n",
    "# --- Aggregate procedures per encounter ---\n",
    "proc_agg = procedures.groupby(\"ENCOUNTER\").agg(\n",
    "    num_procedures=(\"CODE\", \"count\"),\n",
    "    total_proc_cost=(\"BASE_COST\", \"sum\"),\n",
    "    avg_proc_cost=(\"BASE_COST\", \"mean\"),\n",
    "    unique_procs=(\"CODE\", \"nunique\"),\n",
    ").reset_index()\n",
    "\n",
    "# --- Merge encounters <- patients ---\n",
    "enc = encounters.merge(\n",
    "    patients[[\"Id\",\"BIRTHDATE\",\"GENDER\",\"RACE\",\"ETHNICITY\",\"MARITAL\",\"Age\",\"Is_Deceased\"]],\n",
    "    left_on=\"PATIENT\", right_on=\"Id\", how=\"left\", suffixes=(\"\",\"_p\")\n",
    ").drop(columns=[\"Id_p\"], errors=\"ignore\")\n",
    "\n",
    "# --- Merge <- payers ---\n",
    "enc = enc.merge(\n",
    "    payers[[\"Id\",\"NAME\"]].rename(columns={\"NAME\": \"Payer_Name\"}),\n",
    "    left_on=\"PAYER\", right_on=\"Id\", how=\"left\", suffixes=(\"\",\"_pay\")\n",
    ").drop(columns=[\"Id_pay\"], errors=\"ignore\")\n",
    "\n",
    "# --- Merge <- procedures aggregation ---\n",
    "enc = enc.merge(proc_agg, left_on=\"Id\", right_on=\"ENCOUNTER\", how=\"left\")\n",
    "for c in [\"num_procedures\",\"unique_procs\"]:\n",
    "    enc[c] = enc[c].fillna(0).astype(int)\n",
    "for c in [\"total_proc_cost\",\"avg_proc_cost\"]:\n",
    "    enc[c] = enc[c].fillna(0.0)\n",
    "\n",
    "# --- Temporal features ---\n",
    "enc[\"Duration_hours\"] = (enc[\"STOP\"] - enc[\"START\"]).dt.total_seconds() / 3600\n",
    "enc[\"Hour\"]      = enc[\"START\"].dt.hour\n",
    "enc[\"DayOfWeek\"] = enc[\"START\"].dt.dayofweek\n",
    "enc[\"Month\"]     = enc[\"START\"].dt.month\n",
    "enc[\"Year\"]      = enc[\"START\"].dt.year\n",
    "enc[\"Is_Weekend\"] = (enc[\"DayOfWeek\"] >= 5).astype(int)\n",
    "\n",
    "# --- Cost features ---\n",
    "enc[\"Out_of_pocket\"]  = enc[\"TOTAL_CLAIM_COST\"] - enc[\"PAYER_COVERAGE\"]\n",
    "enc[\"Coverage_ratio\"] = np.where(\n",
    "    enc[\"TOTAL_CLAIM_COST\"] > 0,\n",
    "    enc[\"PAYER_COVERAGE\"] / enc[\"TOTAL_CLAIM_COST\"], 0)\n",
    "enc[\"Has_reason\"] = enc[\"REASONCODE\"].notna().astype(int)\n",
    "enc[\"Log_cost\"]   = np.log1p(enc[\"TOTAL_CLAIM_COST\"])\n",
    "\n",
    "# --- Encode categoricals ---\n",
    "le_enc_class = LabelEncoder()\n",
    "enc[\"EncClass_enc\"] = le_enc_class.fit_transform(enc[\"ENCOUNTERCLASS\"])\n",
    "encounter_names = le_enc_class.classes_\n",
    "\n",
    "for col in [\"GENDER\",\"RACE\",\"ETHNICITY\"]:\n",
    "    enc[f\"{col}_enc\"] = LabelEncoder().fit_transform(enc[col])\n",
    "enc[\"MARITAL_enc\"] = LabelEncoder().fit_transform(enc[\"MARITAL\"].fillna(\"U\"))\n",
    "enc[\"Payer_enc\"]   = LabelEncoder().fit_transform(enc[\"Payer_Name\"].fillna(\"Unknown\"))\n",
    "\n",
    "# --- Patient-level aggregation ---\n",
    "pat = enc.groupby(\"PATIENT\").agg(\n",
    "    total_encounters=(\"Id\",\"count\"),\n",
    "    total_cost=(\"TOTAL_CLAIM_COST\",\"sum\"),\n",
    "    avg_cost=(\"TOTAL_CLAIM_COST\",\"mean\"),\n",
    "    max_cost=(\"TOTAL_CLAIM_COST\",\"max\"),\n",
    "    total_procs=(\"num_procedures\",\"sum\"),\n",
    "    avg_procs=(\"num_procedures\",\"mean\"),\n",
    "    emergency_n=(\"ENCOUNTERCLASS\", lambda x: (x==\"emergency\").sum()),\n",
    "    inpatient_n=(\"ENCOUNTERCLASS\", lambda x: (x==\"inpatient\").sum()),\n",
    "    ambulatory_n=(\"ENCOUNTERCLASS\", lambda x: (x==\"ambulatory\").sum()),\n",
    "    wellness_n=(\"ENCOUNTERCLASS\", lambda x: (x==\"wellness\").sum()),\n",
    "    n_enc_types=(\"ENCOUNTERCLASS\",\"nunique\"),\n",
    "    total_coverage=(\"PAYER_COVERAGE\",\"sum\"),\n",
    "    avg_duration=(\"Duration_hours\",\"mean\"),\n",
    "    reason_n=(\"Has_reason\",\"sum\"),\n",
    ").reset_index()\n",
    "\n",
    "pat = pat.merge(\n",
    "    patients[[\"Id\",\"Age\",\"GENDER\",\"RACE\",\"ETHNICITY\",\"MARITAL\",\"Is_Deceased\"]],\n",
    "    left_on=\"PATIENT\", right_on=\"Id\", how=\"left\")\n",
    "pat[\"Gender_enc\"]    = LabelEncoder().fit_transform(pat[\"GENDER\"])\n",
    "pat[\"Race_enc\"]      = LabelEncoder().fit_transform(pat[\"RACE\"])\n",
    "pat[\"Ethnicity_enc\"] = LabelEncoder().fit_transform(pat[\"ETHNICITY\"])\n",
    "pat[\"Marital_enc\"]   = LabelEncoder().fit_transform(pat[\"MARITAL\"].fillna(\"U\"))\n",
    "pat[\"Emergency_ratio\"] = pat[\"emergency_n\"] / pat[\"total_encounters\"]\n",
    "pat[\"Cost_per_enc\"]    = pat[\"total_cost\"] / pat[\"total_encounters\"]\n",
    "\n",
    "print(f\"Encounter-level dataset: {enc.shape}\")\n",
    "print(f\"Patient-level dataset:   {pat.shape}\")\n",
    "print(f\"\\nEncounter classes:\\n{enc['ENCOUNTERCLASS'].value_counts()}\")\n",
    "print(f\"\\nMortality: {pat['Is_Deceased'].value_counts().to_dict()}\")\n",
    "\n",
    "enc.to_csv(\"outputs/encounters_merged.csv\", index=False)\n",
    "pat.to_csv(\"outputs/patients_aggregated.csv\", index=False)\n",
    "print(\"\\nMerged datasets saved to outputs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Plot saved: overview_dashboard.png\n",
      "  Plot saved: encounters_timeline.png\n",
      "  Plot saved: correlation_heatmap.png\n",
      "  Plot saved: payer_distribution.png\n",
      "  Plot saved: top_procedures.png\n",
      "  Plot saved: gender_encounter_heatmap.png\n",
      "All EDA visualisations saved!\n"
     ]
    }
   ],
   "source": [
    "# ---- Figure 1: Overview dashboard (2x2) ----\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1a  Encounter type distribution\n",
    "ec = enc[\"ENCOUNTERCLASS\"].value_counts()\n",
    "colors = sns.color_palette(\"Set2\", len(ec))\n",
    "bars = axes[0,0].bar(ec.index, ec.values, color=colors)\n",
    "axes[0,0].set_title(\"Encounter Type Distribution\", fontweight=\"bold\")\n",
    "axes[0,0].set_ylabel(\"Count\")\n",
    "axes[0,0].tick_params(axis=\"x\", rotation=45)\n",
    "for b, v in zip(bars, ec.values):\n",
    "    axes[0,0].text(b.get_x()+b.get_width()/2, b.get_height()+200,\n",
    "                   f\"{v:,}\", ha=\"center\", fontsize=9)\n",
    "\n",
    "# 1b  Patient race\n",
    "demo = patients[\"RACE\"].value_counts()\n",
    "axes[0,1].pie(demo.values, labels=demo.index, autopct=\"%1.1f%%\",\n",
    "              colors=sns.color_palette(\"pastel\"), startangle=140)\n",
    "axes[0,1].set_title(\"Patient Race Distribution\", fontweight=\"bold\")\n",
    "\n",
    "# 1c  Cost box-plot\n",
    "sns.boxplot(data=enc, x=\"ENCOUNTERCLASS\", y=\"TOTAL_CLAIM_COST\",\n",
    "            ax=axes[1,0], palette=\"Set2\", showfliers=False)\n",
    "axes[1,0].set_title(\"Cost by Encounter Type\", fontweight=\"bold\")\n",
    "axes[1,0].set_ylabel(\"Total Claim Cost ($)\")\n",
    "axes[1,0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 1d  Age by mortality\n",
    "for lbl, grp in pat.groupby(\"Is_Deceased\"):\n",
    "    name = \"Deceased\" if lbl else \"Alive\"\n",
    "    axes[1,1].hist(grp[\"Age\"], bins=25, alpha=0.6, label=name, density=True)\n",
    "axes[1,1].set_title(\"Age Distribution by Mortality\", fontweight=\"bold\")\n",
    "axes[1,1].set_xlabel(\"Age\"); axes[1,1].set_ylabel(\"Density\")\n",
    "axes[1,1].legend()\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"overview_dashboard\")\n",
    "\n",
    "# ---- Figure 2: Encounters over time ----\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "monthly = enc.set_index(\"START\").resample(\"ME\").size()\n",
    "ax.plot(monthly.index, monthly.values, color=\"steelblue\", linewidth=1.5)\n",
    "ax.fill_between(monthly.index, monthly.values, alpha=0.15, color=\"steelblue\")\n",
    "ax.set_title(\"Monthly Encounter Volume\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Date\"); ax.set_ylabel(\"Encounters\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"encounters_timeline\")\n",
    "\n",
    "# ---- Figure 3: Correlation heatmap ----\n",
    "num_cols = [\"Age\",\"Duration_hours\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\n",
    "            \"PAYER_COVERAGE\",\"Out_of_pocket\",\"Coverage_ratio\",\n",
    "            \"num_procedures\",\"total_proc_cost\",\"Hour\",\"Month\"]\n",
    "corr = enc[num_cols].corr()\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
    "            center=0, ax=ax, square=True, linewidths=0.5)\n",
    "ax.set_title(\"Feature Correlation Heatmap\", fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"correlation_heatmap\")\n",
    "\n",
    "# ---- Figure 4: Payer distribution ----\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "pc = enc[\"Payer_Name\"].value_counts()\n",
    "bars = ax.barh(pc.index, pc.values, color=sns.color_palette(\"viridis\", len(pc)))\n",
    "ax.set_title(\"Encounters by Insurance Payer\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Count\")\n",
    "for b, v in zip(bars, pc.values):\n",
    "    ax.text(b.get_width()+50, b.get_y()+b.get_height()/2,\n",
    "            f\"{v:,}\", va=\"center\", fontsize=9)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"payer_distribution\")\n",
    "\n",
    "# ---- Figure 5: Top procedures ----\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "tp = procedures[\"DESCRIPTION\"].value_counts().head(15)\n",
    "ax.barh(tp.index[::-1], tp.values[::-1], color=\"steelblue\")\n",
    "ax.set_title(\"Top 15 Medical Procedures\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Count\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"top_procedures\")\n",
    "\n",
    "# ---- Figure 6: Gender / encounter heatmap ----\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ct = pd.crosstab(enc[\"GENDER\"], enc[\"ENCOUNTERCLASS\"], normalize=\"index\")\n",
    "sns.heatmap(ct, annot=True, fmt=\".3f\", cmap=\"YlOrRd\", ax=ax)\n",
    "ax.set_title(\"Encounter Type Proportion by Gender\", fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"gender_encounter_heatmap\")\n",
    "\n",
    "print(\"All EDA visualisations saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encounter-Type Classification\n",
    "\n",
    "Predict the type of hospital encounter (ambulatory, emergency, inpatient, outpatient,\n",
    "urgentcare, wellness) using patient demographics, temporal features, and procedure data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 22,312  |  Test: 5,579\n",
      "Features: 13\n",
      "Classes (6): ['ambulatory', 'emergency', 'inpatient', 'outpatient', 'urgentcare', 'wellness']\n"
     ]
    }
   ],
   "source": [
    "enc_features = [\"Age\",\"GENDER_enc\",\"RACE_enc\",\"ETHNICITY_enc\",\"MARITAL_enc\",\n",
    "                \"Payer_enc\",\"Hour\",\"DayOfWeek\",\"Month\",\"Is_Weekend\",\n",
    "                \"Has_reason\",\"num_procedures\",\"total_proc_cost\"]\n",
    "\n",
    "X = enc[enc_features].values\n",
    "y = enc[\"EncClass_enc\"].values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_tr_s = scaler.fit_transform(X_tr)\n",
    "X_te_s = scaler.transform(X_te)\n",
    "\n",
    "print(f\"Train: {X_tr.shape[0]:,}  |  Test: {X_te.shape[0]:,}\")\n",
    "print(f\"Features: {len(enc_features)}\")\n",
    "print(f\"Classes ({len(encounter_names)}): {list(encounter_names)}\")\n",
    "\n",
    "def evaluate_clf(name, model, Xtr, Xte, ytr, yte, store=results):\n",
    "    \"\"\"Train, predict, evaluate, and store a classifier.\"\"\"\n",
    "    model.fit(Xtr, ytr)\n",
    "    yp = model.predict(Xte)\n",
    "    acc  = accuracy_score(yte, yp)\n",
    "    prec = precision_score(yte, yp, average=\"weighted\", zero_division=0)\n",
    "    rec  = recall_score(yte, yp, average=\"weighted\", zero_division=0)\n",
    "    f1   = f1_score(yte, yp, average=\"weighted\", zero_division=0)\n",
    "    store[name] = {\"accuracy\": acc, \"precision\": prec, \"recall\": rec,\n",
    "                   \"f1_score\": f1, \"y_pred\": yp, \"model\": model}\n",
    "    print(f\"  {name:28s}  Acc={acc:.4f}  Prec={prec:.4f}  Rec={rec:.4f}  F1={f1:.4f}\")\n",
    "    return model, yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Encounter-Type Classifiers\n",
      "==========================================================================================\n",
      "  Logistic Regression           Acc=0.6474  Prec=0.5739  Rec=0.6474  F1=0.5892\n",
      "  Decision Tree                 Acc=0.8536  Prec=0.8505  Rec=0.8536  F1=0.8510\n",
      "  Random Forest                 Acc=0.8853  Prec=0.8834  Rec=0.8853  F1=0.8811\n",
      "  Gradient Boosting             Acc=0.8847  Prec=0.8835  Rec=0.8847  F1=0.8810\n",
      "  AdaBoost                      Acc=0.6408  Prec=0.6007  Rec=0.6408  F1=0.5966\n",
      "  SVM (linear)                  Acc=0.5673  Prec=0.5478  Rec=0.5673  F1=0.5408\n",
      "  SVM (rbf)                     Acc=0.7634  Prec=0.7587  Rec=0.7634  F1=0.7496\n",
      "\n",
      "  KNN by k: {3: 0.7962000358487185, 5: 0.7944075999283026, 7: 0.7920774332317619, 9: 0.7870586126545976, 11: 0.7800681125649758, 15: 0.7675210611220649}\n",
      "  Best k = 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Encounter-Type Classifiers\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# 1. Logistic Regression\n",
    "evaluate_clf(\"Logistic Regression\",\n",
    "    LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt, _ = evaluate_clf(\"Decision Tree\",\n",
    "    DecisionTreeClassifier(max_depth=15, random_state=SEED),\n",
    "    X_tr, X_te, y_tr, y_te)\n",
    "dt_imp = pd.Series(dt.feature_importances_, index=enc_features)\n",
    "\n",
    "# 3. Random Forest\n",
    "rf, _ = evaluate_clf(\"Random Forest\",\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=20,\n",
    "                           random_state=SEED, n_jobs=-1),\n",
    "    X_tr, X_te, y_tr, y_te)\n",
    "rf_imp = pd.Series(rf.feature_importances_, index=enc_features)\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "gb, _ = evaluate_clf(\"Gradient Boosting\",\n",
    "    GradientBoostingClassifier(n_estimators=200, learning_rate=0.1,\n",
    "                                max_depth=5, random_state=SEED),\n",
    "    X_tr, X_te, y_tr, y_te)\n",
    "gb_imp = pd.Series(gb.feature_importances_, index=enc_features)\n",
    "\n",
    "# 5. AdaBoost\n",
    "evaluate_clf(\"AdaBoost\",\n",
    "    AdaBoostClassifier(n_estimators=100, random_state=SEED),\n",
    "    X_tr, X_te, y_tr, y_te)\n",
    "\n",
    "# 6-7. SVM\n",
    "evaluate_clf(\"SVM (linear)\",\n",
    "    SVC(kernel=\"linear\", random_state=SEED, probability=True, max_iter=5000),\n",
    "    X_tr_s, X_te_s, y_tr, y_te)\n",
    "evaluate_clf(\"SVM (rbf)\",\n",
    "    SVC(kernel=\"rbf\", random_state=SEED, probability=True),\n",
    "    X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "# 8. KNN ‚Äì search for best k\n",
    "k_scores = {}\n",
    "for k in [3, 5, 7, 9, 11, 15]:\n",
    "    tmp = KNeighborsClassifier(n_neighbors=k)\n",
    "    tmp.fit(X_tr_s, y_tr)\n",
    "    k_scores[k] = accuracy_score(y_te, tmp.predict(X_te_s))\n",
    "best_k = max(k_scores, key=k_scores.get)\n",
    "print(f\"\\n  KNN by k: {k_scores}\")\n",
    "print(f\"  Best k = {best_k}\\n\")\n",
    "evaluate_clf(f\"KNN (k={best_k})\",\n",
    "    KNeighborsClassifier(n_neighbors=best_k),\n",
    "    X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "# 9. Naive Bayes\n",
    "evaluate_clf(\"Naive Bayes\", GaussianNB(), X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "# 10. MLP Neural Network\n",
    "evaluate_clf(\"MLP Neural Network\",\n",
    "    MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=500,\n",
    "                  random_state=SEED, early_stopping=True),\n",
    "    X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "print(f\"\\nAll {len(results)} encounter classifiers trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Mortality Prediction (Binary Classification)\n",
    "\n",
    "Predict patient mortality from aggregated healthcare-utilisation features.\n",
    "Class imbalance handled with `class_weight='balanced'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mort_features = [\n",
    "    \"Age\",\"Gender_enc\",\"Race_enc\",\"Ethnicity_enc\",\"Marital_enc\",\n",
    "    \"total_encounters\",\"total_cost\",\"avg_cost\",\"max_cost\",\n",
    "    \"total_procs\",\"avg_procs\",\n",
    "    \"emergency_n\",\"inpatient_n\",\"ambulatory_n\",\"wellness_n\",\n",
    "    \"n_enc_types\",\"total_coverage\",\"avg_duration\",\"reason_n\",\n",
    "    \"Emergency_ratio\",\"Cost_per_enc\"]\n",
    "\n",
    "X_m = pat[mort_features].values\n",
    "y_m = pat[\"Is_Deceased\"].values\n",
    "\n",
    "X_m_tr, X_m_te, y_m_tr, y_m_te = train_test_split(\n",
    "    X_m, y_m, test_size=0.2, random_state=SEED, stratify=y_m)\n",
    "sc_m = StandardScaler()\n",
    "X_m_tr_s = sc_m.fit_transform(X_m_tr)\n",
    "X_m_te_s = sc_m.transform(X_m_te)\n",
    "\n",
    "print(f\"Mortality ‚Äì Train: {len(y_m_tr)} (deceased {y_m_tr.sum()}, \"\n",
    "      f\"{y_m_tr.mean()*100:.1f}%)\")\n",
    "print(f\"Mortality ‚Äì Test:  {len(y_m_te)} (deceased {y_m_te.sum()}, \"\n",
    "      f\"{y_m_te.mean()*100:.1f}%)\")\n",
    "print(\"\\nResults:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "evaluate_clf(\"Mort ‚Äì Logistic Reg.\",\n",
    "    LogisticRegression(max_iter=1000, random_state=SEED, class_weight=\"balanced\"),\n",
    "    X_m_tr_s, X_m_te_s, y_m_tr, y_m_te, store=mortality_results)\n",
    "\n",
    "mort_rf, _ = evaluate_clf(\"Mort ‚Äì Random Forest\",\n",
    "    RandomForestClassifier(n_estimators=200, random_state=SEED,\n",
    "                           class_weight=\"balanced\", n_jobs=-1),\n",
    "    X_m_tr, X_m_te, y_m_tr, y_m_te, store=mortality_results)\n",
    "\n",
    "evaluate_clf(\"Mort ‚Äì Gradient Boosting\",\n",
    "    GradientBoostingClassifier(n_estimators=200, random_state=SEED),\n",
    "    X_m_tr, X_m_te, y_m_tr, y_m_te, store=mortality_results)\n",
    "\n",
    "evaluate_clf(\"Mort ‚Äì SVM (rbf)\",\n",
    "    SVC(kernel=\"rbf\", random_state=SEED, probability=True, class_weight=\"balanced\"),\n",
    "    X_m_tr_s, X_m_te_s, y_m_tr, y_m_te, store=mortality_results)\n",
    "\n",
    "evaluate_clf(\"Mort ‚Äì KNN\",\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    X_m_tr_s, X_m_te_s, y_m_tr, y_m_te, store=mortality_results)\n",
    "\n",
    "evaluate_clf(\"Mort ‚Äì MLP\",\n",
    "    MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500,\n",
    "                  random_state=SEED, early_stopping=True),\n",
    "    X_m_tr_s, X_m_te_s, y_m_tr, y_m_te, store=mortality_results)\n",
    "\n",
    "# ---- ROC Curves ----\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for name, data in mortality_results.items():\n",
    "    model = data[\"model\"]\n",
    "    needs_scaled = any(k in name for k in [\"Logistic\",\"SVM\",\"KNN\",\"MLP\"])\n",
    "    X_roc = X_m_te_s if needs_scaled else X_m_te\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_roc)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        y_prob = model.decision_function(X_roc)\n",
    "    else:\n",
    "        continue\n",
    "    fpr, tpr, _ = roc_curve(y_m_te, y_prob)\n",
    "    short = name.replace(\"Mort ‚Äì \", \"\")\n",
    "    ax.plot(fpr, tpr, linewidth=2, label=f\"{short} (AUC={auc(fpr,tpr):.3f})\")\n",
    "\n",
    "ax.plot([0,1],[0,1], \"k--\", linewidth=1, label=\"Random\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.set_title(\"ROC Curves \\u2013 Mortality Prediction\", fontweight=\"bold\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"mortality_roc\")\n",
    "\n",
    "# ---- Mortality feature importance ----\n",
    "mort_imp = pd.Series(mort_rf.feature_importances_, index=mort_features)\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "mort_imp.sort_values().plot(kind=\"barh\", ax=ax, color=\"steelblue\")\n",
    "ax.set_title(\"Mortality \\u2013 Feature Importance (Random Forest)\", fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"mortality_feature_importance\")\n",
    "\n",
    "print(\"\\nMortality prediction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Healthcare Cost Prediction (Regression)\n",
    "\n",
    "Predict `TOTAL_CLAIM_COST` from encounter and patient features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_features = [\"Age\",\"GENDER_enc\",\"RACE_enc\",\"EncClass_enc\",\n",
    "                \"Payer_enc\",\"Hour\",\"DayOfWeek\",\"Month\",\n",
    "                \"Has_reason\",\"num_procedures\",\"total_proc_cost\",\"Duration_hours\"]\n",
    "\n",
    "X_r = enc[reg_features].values\n",
    "y_r = enc[\"TOTAL_CLAIM_COST\"].values\n",
    "X_r_tr, X_r_te, y_r_tr, y_r_te = train_test_split(\n",
    "    X_r, y_r, test_size=0.2, random_state=SEED)\n",
    "sc_r = StandardScaler()\n",
    "X_r_tr_s = sc_r.fit_transform(X_r_tr)\n",
    "X_r_te_s = sc_r.transform(X_r_te)\n",
    "\n",
    "def evaluate_reg(name, model, Xtr, Xte, ytr, yte):\n",
    "    model.fit(Xtr, ytr)\n",
    "    yp = model.predict(Xte)\n",
    "    r2  = r2_score(yte, yp)\n",
    "    mae = mean_absolute_error(yte, yp)\n",
    "    rmse = np.sqrt(mean_squared_error(yte, yp))\n",
    "    regression_results[name] = {\"r2\": r2, \"mae\": mae, \"rmse\": rmse,\n",
    "                                \"y_pred\": yp, \"model\": model}\n",
    "    print(f\"  {name:30s}  R\\u00b2={r2:.4f}  MAE={mae:.2f}  RMSE={rmse:.2f}\")\n",
    "    return model\n",
    "\n",
    "print(\"Cost Prediction (Regression):\")\n",
    "print(\"=\" * 80)\n",
    "evaluate_reg(\"Linear Regression\", LinearRegression(), X_r_tr_s, X_r_te_s, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"Ridge Regression\", Ridge(alpha=1.0), X_r_tr_s, X_r_te_s, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"Lasso Regression\", Lasso(alpha=1.0, max_iter=5000), X_r_tr_s, X_r_te_s, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"RF Regressor\",\n",
    "    RandomForestRegressor(n_estimators=200, max_depth=15, random_state=SEED, n_jobs=-1),\n",
    "    X_r_tr, X_r_te, y_r_tr, y_r_te)\n",
    "evaluate_reg(\"GB Regressor\",\n",
    "    GradientBoostingRegressor(n_estimators=200, learning_rate=0.1,\n",
    "                               max_depth=5, random_state=SEED),\n",
    "    X_r_tr, X_r_te, y_r_tr, y_r_te)\n",
    "\n",
    "# ---- Actual vs Predicted ----\n",
    "best_reg = max(regression_results, key=lambda k: regression_results[k][\"r2\"])\n",
    "yp_best = regression_results[best_reg][\"y_pred\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].scatter(y_r_te, yp_best, alpha=0.15, s=6, color=\"steelblue\")\n",
    "lim = max(y_r_te.max(), yp_best.max())\n",
    "axes[0].plot([0, lim], [0, lim], \"r--\", linewidth=1)\n",
    "axes[0].set_xlabel(\"Actual Cost ($)\"); axes[0].set_ylabel(\"Predicted Cost ($)\")\n",
    "axes[0].set_title(f\"Actual vs Predicted \\u2013 {best_reg}\", fontweight=\"bold\")\n",
    "\n",
    "# R-squared comparison\n",
    "reg_df = pd.DataFrame({n: {k: v for k, v in d.items() if k not in (\"y_pred\",\"model\")}\n",
    "                        for n, d in regression_results.items()}).T\n",
    "reg_sorted = reg_df.sort_values(\"r2\")\n",
    "reg_sorted[\"r2\"].plot(kind=\"barh\", ax=axes[1], color=\"steelblue\")\n",
    "axes[1].set_title(\"Regression Model Comparison (R\\u00b2)\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"R\\u00b2 Score\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"regression_results\")\n",
    "\n",
    "print(f\"\\nBest: {best_reg} (R\\u00b2 = {regression_results[best_reg]['r2']:.4f})\")\n",
    "print(\"\\n\" + reg_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Patient Segmentation (Unsupervised Clustering)\n",
    "\n",
    "Identify natural patient groups using K-Means, PCA, and DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_feats = [\"Age\",\"total_encounters\",\"total_cost\",\"avg_cost\",\n",
    "                  \"total_procs\",\"emergency_n\",\"inpatient_n\",\n",
    "                  \"Emergency_ratio\",\"avg_duration\",\"Cost_per_enc\"]\n",
    "\n",
    "X_cl = pat[cluster_feats].values\n",
    "sc_cl = StandardScaler()\n",
    "X_cl_s = sc_cl.fit_transform(X_cl)\n",
    "\n",
    "# ---- Elbow + Silhouette ----\n",
    "inertias, sils = [], []\n",
    "K_range = range(2, 11)\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=SEED, n_init=10)\n",
    "    lbl = km.fit_predict(X_cl_s)\n",
    "    inertias.append(km.inertia_)\n",
    "    sils.append(silhouette_score(X_cl_s, lbl))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(list(K_range), inertias, \"bo-\")\n",
    "axes[0].set_title(\"Elbow Method\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"k\"); axes[0].set_ylabel(\"Inertia\")\n",
    "axes[1].plot(list(K_range), sils, \"ro-\")\n",
    "axes[1].set_title(\"Silhouette Score\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"k\"); axes[1].set_ylabel(\"Score\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"elbow_silhouette\")\n",
    "\n",
    "best_k_cl = list(K_range)[int(np.argmax(sils))]\n",
    "print(f\"Best k = {best_k_cl}  (silhouette = {max(sils):.4f})\")\n",
    "km_final = KMeans(n_clusters=best_k_cl, random_state=SEED, n_init=10)\n",
    "pat[\"Cluster\"] = km_final.fit_predict(X_cl_s)\n",
    "\n",
    "# ---- PCA visualisation ----\n",
    "pca = PCA(n_components=2, random_state=SEED)\n",
    "X_pca = pca.fit_transform(X_cl_s)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sc1 = axes[0].scatter(X_pca[:,0], X_pca[:,1], c=pat[\"Cluster\"],\n",
    "                       cmap=\"Set2\", s=30, alpha=0.7)\n",
    "axes[0].set_title(f\"K-Means (k={best_k_cl}) \\u2013 PCA\", fontweight=\"bold\")\n",
    "axes[0].set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)\")\n",
    "axes[0].set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)\")\n",
    "plt.colorbar(sc1, ax=axes[0], label=\"Cluster\")\n",
    "\n",
    "# ---- DBSCAN ----\n",
    "dbscan = DBSCAN(eps=2.5, min_samples=5)\n",
    "db_lbl = dbscan.fit_predict(X_cl_s)\n",
    "n_db = len(set(db_lbl)) - (1 if -1 in db_lbl else 0)\n",
    "sc2 = axes[1].scatter(X_pca[:,0], X_pca[:,1], c=db_lbl, cmap=\"Set1\", s=30, alpha=0.7)\n",
    "axes[1].set_title(f\"DBSCAN ({n_db} clusters)\", fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"PC1\"); axes[1].set_ylabel(\"PC2\")\n",
    "plt.colorbar(sc2, ax=axes[1], label=\"Cluster\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"clustering_results\")\n",
    "\n",
    "print(\"\\nCluster profiles (K-Means):\")\n",
    "profile = pat.groupby(\"Cluster\")[cluster_feats].mean()\n",
    "print(profile.round(2).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning\n",
    "\n",
    "GridSearchCV (Random Forest) and RandomizedSearchCV (Gradient Boosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GridSearchCV: Random Forest ...\")\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=SEED, n_jobs=-1),\n",
    "    {\"n_estimators\": [100, 200], \"max_depth\": [10, 15, 20],\n",
    "     \"min_samples_split\": [2, 5]},\n",
    "    cv=3, scoring=\"f1_weighted\", n_jobs=-1, verbose=0)\n",
    "grid_rf.fit(X_tr, y_tr)\n",
    "print(f\"  Best params: {grid_rf.best_params_}\")\n",
    "print(f\"  Best CV F1:  {grid_rf.best_score_:.4f}\")\n",
    "\n",
    "yp_rf = grid_rf.predict(X_te)\n",
    "results[\"RF (Tuned)\"] = {\n",
    "    \"accuracy\": accuracy_score(y_te, yp_rf),\n",
    "    \"precision\": precision_score(y_te, yp_rf, average=\"weighted\", zero_division=0),\n",
    "    \"recall\": recall_score(y_te, yp_rf, average=\"weighted\", zero_division=0),\n",
    "    \"f1_score\": f1_score(y_te, yp_rf, average=\"weighted\", zero_division=0),\n",
    "    \"y_pred\": yp_rf, \"model\": grid_rf.best_estimator_}\n",
    "print(f\"  Test Acc:    {results['RF (Tuned)']['accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nRandomizedSearchCV: Gradient Boosting ...\")\n",
    "rand_gb = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=SEED),\n",
    "    {\"n_estimators\": [100, 200, 300], \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "     \"max_depth\": [3, 5, 7, 10], \"min_samples_split\": [2, 5, 10]},\n",
    "    n_iter=20, cv=3, scoring=\"f1_weighted\", random_state=SEED, n_jobs=-1, verbose=0)\n",
    "rand_gb.fit(X_tr, y_tr)\n",
    "print(f\"  Best params: {rand_gb.best_params_}\")\n",
    "print(f\"  Best CV F1:  {rand_gb.best_score_:.4f}\")\n",
    "\n",
    "yp_gb = rand_gb.predict(X_te)\n",
    "results[\"GB (Tuned)\"] = {\n",
    "    \"accuracy\": accuracy_score(y_te, yp_gb),\n",
    "    \"precision\": precision_score(y_te, yp_gb, average=\"weighted\", zero_division=0),\n",
    "    \"recall\": recall_score(y_te, yp_gb, average=\"weighted\", zero_division=0),\n",
    "    \"f1_score\": f1_score(y_te, yp_gb, average=\"weighted\", zero_division=0),\n",
    "    \"y_pred\": yp_gb, \"model\": rand_gb.best_estimator_}\n",
    "print(f\"  Test Acc:    {results['GB (Tuned)']['accuracy']:.4f}\")\n",
    "print(\"\\nHyperparameter tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cross-Validation & Advanced Evaluation\n",
    "\n",
    "Stratified 5-fold CV, confusion matrices, feature importance, and learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 5-Fold Cross-Validation ----\n",
    "print(\"5-Fold Cross-Validation (Encounter Classification)\")\n",
    "print(\"=\" * 70)\n",
    "cv_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=15, random_state=SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=SEED, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=SEED),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "cv_data = []\n",
    "for name, model in cv_models.items():\n",
    "    acc_cv = cross_val_score(model, X_tr_s, y_tr, cv=5, scoring=\"accuracy\")\n",
    "    f1_cv  = cross_val_score(model, X_tr_s, y_tr, cv=5, scoring=\"f1_weighted\")\n",
    "    cv_data.append({\"Model\": name,\n",
    "                    \"Acc_mean\": acc_cv.mean(), \"Acc_std\": acc_cv.std(),\n",
    "                    \"F1_mean\": f1_cv.mean(), \"F1_std\": f1_cv.std()})\n",
    "    print(f\"  {name:25s}  Acc={acc_cv.mean():.4f}+/-{acc_cv.std():.4f}  \"\n",
    "          f\"F1={f1_cv.mean():.4f}+/-{f1_cv.std():.4f}\")\n",
    "cv_df = pd.DataFrame(cv_data)\n",
    "\n",
    "# CV bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "x = np.arange(len(cv_df)); w = 0.35\n",
    "ax.bar(x-w/2, cv_df[\"Acc_mean\"], w, yerr=cv_df[\"Acc_std\"], capsize=3,\n",
    "       label=\"Accuracy\", color=\"steelblue\")\n",
    "ax.bar(x+w/2, cv_df[\"F1_mean\"], w, yerr=cv_df[\"F1_std\"], capsize=3,\n",
    "       label=\"F1\", color=\"coral\")\n",
    "ax.set_xticks(x); ax.set_xticklabels(cv_df[\"Model\"], rotation=30, ha=\"right\")\n",
    "ax.set_title(\"Cross-Validation: Model Comparison\", fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Score\"); ax.legend(); ax.set_ylim(0, 1.05)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"cv_comparison\")\n",
    "\n",
    "# ---- Feature Importance ----\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for i, (name, imp) in enumerate([(\"Decision Tree\", dt_imp),\n",
    "                                  (\"Random Forest\", rf_imp),\n",
    "                                  (\"Gradient Boosting\", gb_imp)]):\n",
    "    imp.sort_values().plot(kind=\"barh\", ax=axes[i], color=\"steelblue\")\n",
    "    axes[i].set_title(f\"{name}\\nFeature Importance\", fontweight=\"bold\")\n",
    "    axes[i].set_xlabel(\"Importance\")\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"feature_importance\")\n",
    "print(\"\\nFeature importance saved!\")\n",
    "\n",
    "# ---- Confusion Matrices ----\n",
    "cm_models = {k: v for k, v in results.items()\n",
    "             if \"y_pred\" in v and \"Tuned\" not in k}\n",
    "n = len(cm_models); ncols = 3; nrows = (n + ncols - 1) // ncols\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(6*ncols, 5*nrows))\n",
    "axes_f = axes.flatten()\n",
    "for i, (name, data) in enumerate(cm_models.items()):\n",
    "    cm = confusion_matrix(y_te, data[\"y_pred\"])\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes_f[i],\n",
    "                xticklabels=encounter_names, yticklabels=encounter_names)\n",
    "    axes_f[i].set_title(f\"{name}\\nAcc={data['accuracy']:.3f}\",\n",
    "                        fontsize=10, fontweight=\"bold\")\n",
    "    axes_f[i].set_xlabel(\"Predicted\"); axes_f[i].set_ylabel(\"Actual\")\n",
    "    axes_f[i].tick_params(axis=\"both\", labelsize=7)\n",
    "for i in range(n, len(axes_f)):\n",
    "    axes_f[i].set_visible(False)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"confusion_matrices\")\n",
    "print(\"Confusion matrices saved!\")\n",
    "\n",
    "# ---- Learning Curves ----\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "lc_models = [\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "]\n",
    "for i, (name, model) in enumerate(lc_models):\n",
    "    sizes, tr_sc, va_sc = learning_curve(\n",
    "        model, X_tr_s, y_tr, cv=5,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 8), scoring=\"accuracy\", n_jobs=-1)\n",
    "    axes[i].plot(sizes, tr_sc.mean(1), \"o-\", label=\"Train\", color=\"steelblue\")\n",
    "    axes[i].fill_between(sizes, tr_sc.mean(1)-tr_sc.std(1),\n",
    "                         tr_sc.mean(1)+tr_sc.std(1), alpha=0.1, color=\"steelblue\")\n",
    "    axes[i].plot(sizes, va_sc.mean(1), \"o-\", label=\"Validation\", color=\"coral\")\n",
    "    axes[i].fill_between(sizes, va_sc.mean(1)-va_sc.std(1),\n",
    "                         va_sc.mean(1)+va_sc.std(1), alpha=0.1, color=\"coral\")\n",
    "    axes[i].set_title(f\"Learning Curve: {name}\", fontweight=\"bold\")\n",
    "    axes[i].set_xlabel(\"Training Size\"); axes[i].set_ylabel(\"Accuracy\")\n",
    "    axes[i].legend(loc=\"lower right\"); axes[i].set_ylim(0, 1.05)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"learning_curves\")\n",
    "print(\"Learning curves saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Ensemble Methods & Final Comparison\n",
    "\n",
    "Voting and Stacking ensemble classifiers, plus a comprehensive model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "print(\"Training Voting Classifier ...\")\n",
    "voting = VotingClassifier(estimators=[\n",
    "    (\"lr\", LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "], voting=\"soft\", n_jobs=-1)\n",
    "evaluate_clf(\"Voting Ensemble\", voting, X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "# Stacking Classifier\n",
    "print(\"\\nTraining Stacking Classifier ...\")\n",
    "stacking = StackingClassifier(estimators=[\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "    (\"knn\", KNeighborsClassifier(n_neighbors=best_k)),\n",
    "], final_estimator=LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "   cv=3, n_jobs=-1)\n",
    "evaluate_clf(\"Stacking Ensemble\", stacking, X_tr_s, X_te_s, y_tr, y_te)\n",
    "\n",
    "# ---- Final Model Comparison Table ----\n",
    "rows = []\n",
    "for name, data in results.items():\n",
    "    rows.append({\"Model\": name, \"Accuracy\": data[\"accuracy\"],\n",
    "                 \"Precision\": data[\"precision\"], \"Recall\": data[\"recall\"],\n",
    "                 \"F1 Score\": data[\"f1_score\"]})\n",
    "comp_df = pd.DataFrame(rows).sort_values(\"F1 Score\", ascending=False)\n",
    "print(\"\\nFinal Model Comparison (Encounter Classification):\")\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "# Comparison chart\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "comp_s = comp_df.sort_values(\"F1 Score\")\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.9, len(comp_s)))\n",
    "ax.barh(comp_s[\"Model\"], comp_s[\"F1 Score\"], color=colors)\n",
    "ax.set_xlabel(\"F1 Score (Weighted)\")\n",
    "ax.set_title(\"All Models \\u2013 F1 Score Comparison\", fontweight=\"bold\")\n",
    "ax.set_xlim(0, 1.05)\n",
    "for i, (_, row) in enumerate(comp_s.iterrows()):\n",
    "    ax.text(row[\"F1 Score\"]+0.005, i, f\"{row['F1 Score']:.4f}\", va=\"center\", fontsize=9)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, \"model_comparison\")\n",
    "\n",
    "best_name = comp_df.iloc[0][\"Model\"]\n",
    "best_f1   = comp_df.iloc[0][\"F1 Score\"]\n",
    "print(f\"\\nBest model: {best_name} (F1 = {best_f1:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. HTML Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the HTML report using string concatenation\n",
    "# (avoids f-string / CSS curly-brace conflicts)\n",
    "\n",
    "css = \"\"\"\n",
    "<style>\n",
    "* { margin:0; padding:0; box-sizing:border-box; }\n",
    "body { font-family:'Segoe UI',system-ui,sans-serif; background:#f0f2f5; color:#333; line-height:1.6; }\n",
    ".container { max-width:1200px; margin:0 auto; padding:20px; }\n",
    "header { background:linear-gradient(135deg,#1a5276,#2e86c1); color:#fff; padding:40px; border-radius:12px; margin-bottom:30px; text-align:center; }\n",
    "header h1 { font-size:2.2em; margin-bottom:10px; }\n",
    "header p  { font-size:1.1em; opacity:.9; }\n",
    ".card { background:#fff; border-radius:12px; padding:30px; margin-bottom:25px; box-shadow:0 2px 10px rgba(0,0,0,.08); }\n",
    ".card h2 { color:#1a5276; border-bottom:3px solid #2e86c1; padding-bottom:10px; margin-bottom:20px; }\n",
    ".card h3 { color:#2e86c1; margin:15px 0 10px; }\n",
    "table { width:100%; border-collapse:collapse; margin:15px 0; }\n",
    "th,td { padding:10px 14px; text-align:left; border-bottom:1px solid #eee; }\n",
    "th { background:#f8f9fa; font-weight:600; color:#1a5276; }\n",
    "tr:hover { background:#f8f9fa; }\n",
    ".dashboard { display:grid; grid-template-columns:repeat(auto-fit,minmax(180px,1fr)); gap:15px; margin-bottom:25px; }\n",
    ".stat-box { background:#fff; border-radius:10px; padding:20px; text-align:center; box-shadow:0 2px 8px rgba(0,0,0,.08); }\n",
    ".stat-box .number { font-size:2em; font-weight:700; color:#2e86c1; }\n",
    ".stat-box .label  { font-size:.9em; color:#666; margin-top:5px; }\n",
    ".plot-img { max-width:100%; border-radius:8px; margin:15px 0; box-shadow:0 2px 8px rgba(0,0,0,.1); }\n",
    ".explanation { background:#eaf2f8; border-left:4px solid #2e86c1; padding:15px; border-radius:0 8px 8px 0; margin:15px 0; }\n",
    ".best { color:#27ae60; font-weight:700; }\n",
    "footer { text-align:center; padding:30px; color:#999; font-size:.9em; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "html = []\n",
    "html.append(\"<!DOCTYPE html>\")\n",
    "html.append(\"<html lang='en'>\")\n",
    "html.append(\"<head><meta charset='UTF-8'>\")\n",
    "html.append(\"<meta name='viewport' content='width=device-width,initial-scale=1.0'>\")\n",
    "html.append(\"<title>Hospital Patient Records \\u2013 ML Report</title>\")\n",
    "html.append(css)\n",
    "html.append(\"</head><body><div class='container'>\")\n",
    "\n",
    "# --- Header ---\n",
    "html.append(\"<header>\")\n",
    "html.append(\"<h1>\\U0001f3e5 Hospital Patient Records \\u2013 ML Analysis Report</h1>\")\n",
    "html.append(\"<p>Comprehensive Machine Learning Analysis of Synthea Healthcare Data</p>\")\n",
    "html.append(f\"<p>{len(patients):,} patients &middot; {len(encounters):,} encounters &middot; {len(procedures):,} procedures</p>\")\n",
    "html.append(\"</header>\")\n",
    "\n",
    "# --- Dashboard ---\n",
    "best_clf_name = comp_df.iloc[0][\"Model\"]\n",
    "best_clf_f1   = comp_df.iloc[0][\"F1 Score\"]\n",
    "best_reg_name = max(regression_results, key=lambda k: regression_results[k][\"r2\"])\n",
    "best_reg_r2   = regression_results[best_reg_name][\"r2\"]\n",
    "best_mort     = max(mortality_results, key=lambda k: mortality_results[k][\"f1_score\"])\n",
    "best_mort_f1  = mortality_results[best_mort][\"f1_score\"]\n",
    "\n",
    "html.append(\"<div class='dashboard'>\")\n",
    "for label, value in [\n",
    "    (\"Patients\", f\"{len(patients):,}\"),\n",
    "    (\"Encounters\", f\"{len(encounters):,}\"),\n",
    "    (\"ML Models Trained\", str(len(results) + len(mortality_results) + len(regression_results))),\n",
    "    (\"Best Classifier F1\", f\"{best_clf_f1:.4f}\"),\n",
    "    (\"Best Regression R\\u00b2\", f\"{best_reg_r2:.4f}\"),\n",
    "    (\"Plots Generated\", str(len(report_images))),\n",
    "]:\n",
    "    html.append(f\"<div class='stat-box'><div class='number'>{value}</div><div class='label'>{label}</div></div>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 1: Dataset ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f4cb 1. Dataset Overview</h2>\")\n",
    "html.append(\"<p>This analysis uses <strong>Synthea</strong>-generated synthetic hospital records \"\n",
    "            \"from Massachusetts General Hospital, Boston, MA.</p>\")\n",
    "html.append(\"<table><tr><th>Table</th><th>Rows</th><th>Columns</th><th>Description</th></tr>\")\n",
    "for tname, tdf, tdesc in [\n",
    "    (\"patients\", patients, \"Demographics, birth/death dates, location\"),\n",
    "    (\"encounters\", encounters, \"Hospital visits, costs, payer, diagnosis\"),\n",
    "    (\"procedures\", procedures, \"Medical procedures linked to encounters\"),\n",
    "    (\"payers\", payers, \"Insurance providers\"),\n",
    "    (\"organizations\", organizations, \"Hospital information\"),\n",
    "]:\n",
    "    html.append(f\"<tr><td><strong>{tname}</strong></td><td>{len(tdf):,}</td>\"\n",
    "                f\"<td>{tdf.shape[1]}</td><td>{tdesc}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "html.append(\"<div class='explanation'><strong>Key insight:</strong> \"\n",
    "            \"All encounters occur at a single hospital. The dataset spans 2011\\u20132022 \"\n",
    "            \"with 10 insurance payers (including uninsured).</div>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 2: EDA ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f4ca 2. Exploratory Data Analysis</h2>\")\n",
    "for name, caption in [\n",
    "    (\"overview_dashboard\", \"Overview: encounter types, demographics, costs, and mortality age distributions\"),\n",
    "    (\"encounters_timeline\", \"Monthly encounter volume across the 11-year period\"),\n",
    "    (\"correlation_heatmap\", \"Pearson correlation between numeric features\"),\n",
    "    (\"payer_distribution\", \"Encounters broken down by insurance payer\"),\n",
    "    (\"top_procedures\", \"The 15 most frequently performed medical procedures\"),\n",
    "    (\"gender_encounter_heatmap\", \"Encounter-type proportions by patient gender\"),\n",
    "]:\n",
    "    if name in report_images:\n",
    "        html.append(f\"<h3>{caption}</h3>\")\n",
    "        html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images[name]}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 3: Encounter Classification ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f916 3. Encounter-Type Classification</h2>\")\n",
    "html.append(\"<p>Predicting encounter type (ambulatory, emergency, inpatient, outpatient, \"\n",
    "            \"urgentcare, wellness) from patient demographics, temporal features, and procedure data.</p>\")\n",
    "html.append(\"<table><tr><th>Model</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1 Score</th></tr>\")\n",
    "for _, row in comp_df.iterrows():\n",
    "    best_cls = \" class='best'\" if row[\"Model\"] == best_clf_name else \"\"\n",
    "    html.append(f\"<tr{best_cls}><td>{row['Model']}</td>\"\n",
    "                f\"<td>{row['Accuracy']:.4f}</td><td>{row['Precision']:.4f}</td>\"\n",
    "                f\"<td>{row['Recall']:.4f}</td><td>{row['F1 Score']:.4f}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "if \"confusion_matrices\" in report_images:\n",
    "    html.append(\"<h3>Confusion Matrices</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['confusion_matrices']}'>\")\n",
    "if \"model_comparison\" in report_images:\n",
    "    html.append(\"<h3>Model Comparison</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['model_comparison']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 4: Mortality ---\n",
    "html.append(\"<div class='card'><h2>\\u2695\\ufe0f 4. Mortality Prediction</h2>\")\n",
    "html.append(\"<p>Binary classification predicting patient mortality from aggregated \"\n",
    "            \"healthcare utilisation features. Class imbalance handled with balanced class weights.</p>\")\n",
    "html.append(\"<table><tr><th>Model</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1 Score</th></tr>\")\n",
    "for name, data in sorted(mortality_results.items(), key=lambda x: -x[1][\"f1_score\"]):\n",
    "    best_cls = \" class='best'\" if name == best_mort else \"\"\n",
    "    html.append(f\"<tr{best_cls}><td>{name}</td>\"\n",
    "                f\"<td>{data['accuracy']:.4f}</td><td>{data['precision']:.4f}</td>\"\n",
    "                f\"<td>{data['recall']:.4f}</td><td>{data['f1_score']:.4f}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "if \"mortality_roc\" in report_images:\n",
    "    html.append(\"<h3>ROC Curves</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['mortality_roc']}'>\")\n",
    "if \"mortality_feature_importance\" in report_images:\n",
    "    html.append(\"<h3>Feature Importance</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['mortality_feature_importance']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 5: Regression ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f4b0 5. Cost Prediction (Regression)</h2>\")\n",
    "html.append(\"<p>Predicting TOTAL_CLAIM_COST from encounter and patient features.</p>\")\n",
    "html.append(\"<table><tr><th>Model</th><th>R\\u00b2</th><th>MAE ($)</th><th>RMSE ($)</th></tr>\")\n",
    "for name in sorted(regression_results, key=lambda k: -regression_results[k][\"r2\"]):\n",
    "    d = regression_results[name]\n",
    "    best_cls = \" class='best'\" if name == best_reg_name else \"\"\n",
    "    html.append(f\"<tr{best_cls}><td>{name}</td>\"\n",
    "                f\"<td>{d['r2']:.4f}</td><td>{d['mae']:.2f}</td><td>{d['rmse']:.2f}</td></tr>\")\n",
    "html.append(\"</table>\")\n",
    "if \"regression_results\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['regression_results']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 6: Clustering ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f9e9 6. Patient Segmentation</h2>\")\n",
    "html.append(f\"<p>K-Means clustering identified <strong>{best_k_cl} patient segments</strong> \"\n",
    "            f\"(silhouette = {max(sils):.4f}). DBSCAN was used for density-based comparison.</p>\")\n",
    "if \"elbow_silhouette\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['elbow_silhouette']}'>\")\n",
    "if \"clustering_results\" in report_images:\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['clustering_results']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 7: CV & Learning Curves ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f4c8 7. Cross-Validation & Learning Curves</h2>\")\n",
    "if \"cv_comparison\" in report_images:\n",
    "    html.append(\"<h3>5-Fold Cross-Validation</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['cv_comparison']}'>\")\n",
    "if \"feature_importance\" in report_images:\n",
    "    html.append(\"<h3>Feature Importance (3 tree-based models)</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['feature_importance']}'>\")\n",
    "if \"learning_curves\" in report_images:\n",
    "    html.append(\"<h3>Learning Curves</h3>\")\n",
    "    html.append(f\"<img class='plot-img' src='data:image/png;base64,{report_images['learning_curves']}'>\")\n",
    "html.append(\"</div>\")\n",
    "\n",
    "# --- Section 8: Conclusions ---\n",
    "html.append(\"<div class='card'><h2>\\U0001f3af 8. Key Findings & Conclusions</h2>\")\n",
    "html.append(\"<div class='explanation'>\")\n",
    "html.append(\"<h3>Encounter Classification</h3>\")\n",
    "html.append(f\"<p>The best classifier was <strong>{best_clf_name}</strong> with F1 = {best_clf_f1:.4f}. \"\n",
    "            \"Tree-based and ensemble methods consistently outperformed linear models. \"\n",
    "            \"The most important features were procedure count and total procedure cost, \"\n",
    "            \"confirming that the type of care delivered strongly signals the encounter class.</p>\")\n",
    "html.append(\"<h3>Mortality Prediction</h3>\")\n",
    "html.append(f\"<p>The best mortality predictor was <strong>{best_mort.replace('Mort \\u2013 ','')}</strong> \"\n",
    "            f\"(F1 = {best_mort_f1:.4f}). Age and total healthcare cost emerged as the strongest \"\n",
    "            \"predictors. Using balanced class weights was essential due to the low mortality rate.</p>\")\n",
    "html.append(\"<h3>Cost Prediction</h3>\")\n",
    "html.append(f\"<p><strong>{best_reg_name}</strong> achieved R\\u00b2 = {best_reg_r2:.4f}. \"\n",
    "            \"Procedure cost and duration were the dominant predictors, as expected in a \"\n",
    "            \"fee-for-service cost model.</p>\")\n",
    "html.append(\"<h3>Patient Segmentation</h3>\")\n",
    "html.append(f\"<p>K-Means identified {best_k_cl} distinct patient segments. Clusters differ primarily \"\n",
    "            \"in healthcare utilisation intensity (total encounters, emergency visits, costs). \"\n",
    "            \"These segments can support targeted intervention strategies.</p>\")\n",
    "html.append(\"</div></div>\")\n",
    "\n",
    "# --- Footer ---\n",
    "html.append(\"<footer>\")\n",
    "html.append(\"<p>Generated with scikit-learn, pandas, matplotlib, seaborn</p>\")\n",
    "html.append(\"<p>Dataset: Synthea \\u2013 Walonoski et al., JAMIA 2018</p>\")\n",
    "html.append(\"</footer>\")\n",
    "html.append(\"</div></body></html>\")\n",
    "\n",
    "# ---- Write ----\n",
    "report_path = \"outputs/hospital_ml_report.html\"\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(html))\n",
    "\n",
    "size_kb = os.path.getsize(report_path) / 1024\n",
    "print(f\"\\u2705 HTML Report generated: {report_path}\")\n",
    "print(f\"   File size: {size_kb:.1f} KB\")\n",
    "print(f\"   Embedded images: {len(report_images)}\")\n",
    "print(f\"\\n\\U0001f389 Analysis complete! Open the HTML file in a browser to view the full report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
