{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f268c4e0",
   "metadata": {},
   "source": [
    "# Stage 3 — Conditional GAN Demo\n",
    "\n",
    "This notebook demonstrates **class-conditioned image generation** using the\n",
    "Conditional DCGAN with a Projection Discriminator.\n",
    "\n",
    "Key features:\n",
    "- Generate specific digit classes on demand\n",
    "- Projection Discriminator (Miyato & Koyama, 2018)\n",
    "- Class embedding concatenated with latent vector\n",
    "- Per-class quality analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a103a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from src.utils.config_loader import load_config, get_device\n",
    "from src.utils.checkpointing import load_checkpoint, find_latest_checkpoint\n",
    "from src.models.conditional_gan import build_conditional_gan\n",
    "from src.data.dataloaders import get_dataloader_from_config\n",
    "from src.evaluation.visualization import GANVisualizer\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ffcdd8",
   "metadata": {},
   "source": [
    "## 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(PROJECT_ROOT / \"config\" / \"conditional_gan.yaml\")\n",
    "device = get_device(config)\n",
    "latent_dim = config['model']['latent_dim']\n",
    "n_classes = config['model']['n_classes']\n",
    "\n",
    "generator, discriminator = build_conditional_gan(config)\n",
    "generator = generator.to(device)\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Classes: {n_classes}\")\n",
    "print(f\"Generator params:     {sum(p.numel() for p in generator.parameters()):>10,}\")\n",
    "print(f\"Discriminator params: {sum(p.numel() for p in discriminator.parameters()):>10,}\")\n",
    "\n",
    "ckpt_path = find_latest_checkpoint(config['paths']['models_dir'])\n",
    "if ckpt_path:\n",
    "    info = load_checkpoint(ckpt_path, generator, discriminator, device=device)\n",
    "    print(f\"Loaded: epoch {info['epoch']}\")\n",
    "else:\n",
    "    print(\"No checkpoint found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69923cc7",
   "metadata": {},
   "source": [
    "## 2. Class-Conditioned Generation Grid\n",
    "\n",
    "Each row = one class (0–9). Same noise vector across columns to see\n",
    "how the same latent code is interpreted per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6aaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "n_samples_per_class = 10\n",
    "\n",
    "# Use same noise for all classes → shows class control\n",
    "fixed_z = torch.randn(n_samples_per_class, latent_dim, device=device)\n",
    "all_images = []\n",
    "\n",
    "for class_idx in range(n_classes):\n",
    "    labels = torch.full((n_samples_per_class,), class_idx, dtype=torch.long, device=device)\n",
    "    with torch.no_grad():\n",
    "        imgs = generator(fixed_z, labels)\n",
    "    all_images.append(imgs)\n",
    "\n",
    "grid = make_grid(\n",
    "    torch.cat(all_images).cpu(),\n",
    "    nrow=n_samples_per_class,\n",
    "    normalize=True, value_range=(-1, 1), padding=2\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "plt.title('Conditional GAN — Same Noise, Different Classes (rows 0-9)', fontsize=14)\n",
    "\n",
    "# Add class labels on y-axis\n",
    "img_size = 64 + 2  # padding\n",
    "for i in range(n_classes):\n",
    "    plt.text(-15, i * img_size + img_size // 2, str(i),\n",
    "             fontsize=12, ha='center', va='center', fontweight='bold')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f21e9",
   "metadata": {},
   "source": [
    "## 3. Generate Specific Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit(digit: int, n: int = 16):\n",
    "    \"\"\"Generate N images of a specific digit.\"\"\"\n",
    "    z = torch.randn(n, latent_dim, device=device)\n",
    "    labels = torch.full((n,), digit, dtype=torch.long, device=device)\n",
    "    with torch.no_grad():\n",
    "        return generator(z, labels).cpu()\n",
    "\n",
    "# Generate specific digits\n",
    "for digit in [0, 3, 7, 9]:\n",
    "    imgs = generate_digit(digit, n=8)\n",
    "    grid = make_grid(imgs, nrow=8, normalize=True, value_range=(-1, 1))\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    plt.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "    plt.title(f'Generated digit: {digit}', fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3ef7f",
   "metadata": {},
   "source": [
    "## 4. Class-Conditioned Interpolation\n",
    "\n",
    "Interpolate in latent space while keeping the class label fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = GANVisualizer(output_dir=str(PROJECT_ROOT / \"outputs\"))\n",
    "n_steps = 12\n",
    "\n",
    "fig, axes = plt.subplots(n_classes, 1, figsize=(16, n_classes * 1.5))\n",
    "fig.suptitle('Latent Interpolation per Class', fontsize=14, y=1.01)\n",
    "\n",
    "for class_idx in range(n_classes):\n",
    "    z1 = torch.randn(latent_dim, device=device)\n",
    "    z2 = torch.randn(latent_dim, device=device)\n",
    "    z_interp = visualizer.spherical_interpolation(z1, z2, n_steps)\n",
    "    labels = torch.full((n_steps,), class_idx, dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        imgs = generator(z_interp, labels)\n",
    "\n",
    "    grid = make_grid(imgs.cpu(), nrow=n_steps, normalize=True, value_range=(-1, 1))\n",
    "    axes[class_idx].imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "    axes[class_idx].set_ylabel(str(class_idx), fontsize=12, rotation=0, labelpad=15)\n",
    "    axes[class_idx].set_xticks([])\n",
    "    axes[class_idx].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce373737",
   "metadata": {},
   "source": [
    "## 5. Label Morphing — Smooth Transition Between Classes\n",
    "\n",
    "Fix the noise vector and change the class label to see how the generator\n",
    "interprets different classes for the same latent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeda5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed noise, varying labels\n",
    "n_noise_samples = 5\n",
    "all_morphs = []\n",
    "\n",
    "for i in range(n_noise_samples):\n",
    "    z = torch.randn(1, latent_dim, device=device).expand(n_classes, -1)\n",
    "    labels = torch.arange(n_classes, device=device)\n",
    "    with torch.no_grad():\n",
    "        imgs = generator(z, labels)\n",
    "    all_morphs.append(imgs)\n",
    "\n",
    "morph_grid = make_grid(\n",
    "    torch.cat(all_morphs).cpu(),\n",
    "    nrow=n_classes, normalize=True, value_range=(-1, 1)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(morph_grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "plt.title('Label Morphing — Same noise (rows), different classes (columns 0→9)', fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c57d1",
   "metadata": {},
   "source": [
    "## 6. Per-Class FID Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31807b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.fid_score import FIDCalculator\n",
    "from src.evaluation.inception_score import InceptionScoreCalculator\n",
    "\n",
    "N_EVAL = 500  # per class\n",
    "dataloader = get_dataloader_from_config(config)\n",
    "\n",
    "# Organize real images by class\n",
    "real_by_class = {i: [] for i in range(n_classes)}\n",
    "for imgs, labels in dataloader:\n",
    "    for img, lbl in zip(imgs, labels):\n",
    "        c = lbl.item()\n",
    "        if len(real_by_class[c]) < N_EVAL:\n",
    "            real_by_class[c].append(img)\n",
    "    if all(len(v) >= N_EVAL for v in real_by_class.values()):\n",
    "        break\n",
    "\n",
    "print(\"Computing FID per class (this may take a while)...\")\n",
    "fid_calc = FIDCalculator(device=str(device), batch_size=32)\n",
    "class_fids = {}\n",
    "\n",
    "for c in range(n_classes):\n",
    "    real_imgs = torch.stack(real_by_class[c][:N_EVAL])\n",
    "    fake_imgs = generate_digit(c, N_EVAL)\n",
    "    fid = fid_calc.compute_fid(real_imgs, fake_imgs)\n",
    "    class_fids[c] = fid\n",
    "    print(f\"  Class {c}: FID = {fid:.2f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(n_classes), [class_fids[c] for c in range(n_classes)])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('FID Score')\n",
    "plt.title('Per-Class FID Scores (Conditional GAN)')\n",
    "plt.xticks(range(n_classes))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125d30f",
   "metadata": {},
   "source": [
    "## 7. Summary — Three-Stage Comparison\n",
    "\n",
    "| Stage | Architecture | Key Feature | Expected FID |\n",
    "|-------|-------------|-------------|-------------|\n",
    "| 1. Vanilla GAN | MLP | Baseline | ~150-200 |\n",
    "| 2. DCGAN | ConvNet | Spatial hierarchy | ~50-100 |\n",
    "| 3. Conditional GAN | cDCGAN + Projection D | Class control | ~30-80 |\n",
    "\n",
    "Lower FID = better quality. The convolutional backbone and conditioning\n",
    "provide substantial improvements over the MLP baseline."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
