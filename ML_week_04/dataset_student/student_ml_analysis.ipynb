{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe828d77",
   "metadata": {},
   "source": [
    "# üéì Student Performance ML Analysis\n",
    "## Comprehensive Machine Learning Pipeline\n",
    "\n",
    "This notebook applies **state-of-the-art machine learning techniques** to analyze a student performance dataset containing Math, Physics, and Chemistry scores with grade labels (A+ to F).\n",
    "\n",
    "### Techniques covered:\n",
    "- **Classification**: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost, SVM, KNN, Naive Bayes, MLP Neural Network\n",
    "- **Regression**: Linear, Ridge, Lasso, Random Forest Regressor, Gradient Boosting Regressor\n",
    "- **Clustering**: K-Means, DBSCAN\n",
    "- **Dimensionality Reduction**: PCA\n",
    "- **Ensemble Methods**: Voting Classifier, Stacking Classifier\n",
    "- **Evaluation**: Cross-validation, Confusion Matrices, ROC Curves, Learning Curves, Feature Importance\n",
    "- **Hyperparameter Tuning**: GridSearchCV, RandomizedSearchCV\n",
    "- **Final Output**: Interactive HTML report with all results and explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54346c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è XGBoost not available (needs libomp), will use sklearn GradientBoosting instead\n",
      "‚úÖ Jinja2 available\n",
      "‚úÖ All libraries loaded successfully!\n",
      "NumPy: 2.4.2\n",
      "Pandas: 3.0.1\n",
      "Scikit-learn: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 1: Import Libraries and Configure Environment\n",
    "# ============================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Scikit-learn: Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,\n",
    "                              VotingClassifier, StackingClassifier,\n",
    "                              RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Scikit-learn: Regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "# Scikit-learn: Clustering & Dimensionality Reduction\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scikit-learn: Preprocessing & Evaluation\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "                                     GridSearchCV, RandomizedSearchCV,\n",
    "                                     StratifiedKFold, learning_curve)\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, classification_report, confusion_matrix,\n",
    "                             roc_curve, auc, roc_auc_score,\n",
    "                             mean_absolute_error, mean_squared_error, r2_score,\n",
    "                             silhouette_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# XGBoost (optional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGBOOST = True\n",
    "    print(\"‚úÖ XGBoost available\")\n",
    "except (ImportError, OSError, Exception):\n",
    "    HAS_XGBOOST = False\n",
    "    print(\"‚ö†Ô∏è XGBoost not available (needs libomp), will use sklearn GradientBoosting instead\")\n",
    "\n",
    "# Jinja2 for HTML report\n",
    "try:\n",
    "    from jinja2 import Template\n",
    "    HAS_JINJA2 = True\n",
    "    print(\"‚úÖ Jinja2 available\")\n",
    "except ImportError:\n",
    "    HAS_JINJA2 = False\n",
    "    print(\"‚ö†Ô∏è Jinja2 not available, will use string formatting for HTML report\")\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Output directory\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/plots', exist_ok=True)\n",
    "\n",
    "# Dictionary to store all model results\n",
    "results = {}\n",
    "report_images = {}\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"Scikit-learn: {__import__('sklearn').__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2e127",
   "metadata": {},
   "source": [
    "## Section 2: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859298dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "\n",
      "üìä Shape: 9000 rows √ó 10 columns\n",
      "\n",
      "üìã Columns: ['Student_Names', 'Phone_No.', 'Math', 'Physics', 'Chemistry', 'Grade', 'Comment', 'Roll No.', 'School Name', 'Student Address']\n",
      "\n",
      "üîç Data Types:\n",
      "Student_Names        str\n",
      "Phone_No.          int64\n",
      "Math               int64\n",
      "Physics            int64\n",
      "Chemistry          int64\n",
      "Grade                str\n",
      "Comment              str\n",
      "Roll No.           int64\n",
      "School Name          str\n",
      "Student Address      str\n",
      "dtype: object\n",
      "\n",
      "‚ùì Missing Values:\n",
      "Student_Names      0\n",
      "Phone_No.          0\n",
      "Math               0\n",
      "Physics            0\n",
      "Chemistry          0\n",
      "Grade              0\n",
      "Comment            0\n",
      "Roll No.           0\n",
      "School Name        0\n",
      "Student Address    0\n",
      "dtype: int64\n",
      "\n",
      "üîÑ Duplicates: 0\n",
      "\n",
      "üìà Statistical Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone_No.</th>\n",
       "      <th>Math</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Roll No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.000000e+03</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "      <td>9000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.498521e+09</td>\n",
       "      <td>55.276111</td>\n",
       "      <td>54.697556</td>\n",
       "      <td>54.854889</td>\n",
       "      <td>550174.095667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.865630e+08</td>\n",
       "      <td>26.109140</td>\n",
       "      <td>26.232446</td>\n",
       "      <td>26.261320</td>\n",
       "      <td>28955.471076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000052e+09</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>500002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.251158e+09</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>524968.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.498910e+09</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>550274.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.745590e+09</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>575254.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999838e+09</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>599994.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Phone_No.         Math      Physics    Chemistry       Roll No.\n",
       "count  9.000000e+03  9000.000000  9000.000000  9000.000000    9000.000000\n",
       "mean   9.498521e+09    55.276111    54.697556    54.854889  550174.095667\n",
       "std    2.865630e+08    26.109140    26.232446    26.261320   28955.471076\n",
       "min    9.000052e+09    10.000000    10.000000    10.000000  500002.000000\n",
       "25%    9.251158e+09    33.000000    32.000000    32.000000  524968.250000\n",
       "50%    9.498910e+09    56.000000    55.000000    55.000000  550274.500000\n",
       "75%    9.745590e+09    78.000000    77.000000    77.000000  575254.750000\n",
       "max    9.999838e+09   100.000000   100.000000   100.000000  599994.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 2: Load and Explore the Dataset\n",
    "# ============================================================\n",
    "df = pd.read_csv('student_dataset.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Shape: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"\\nüìã Columns: {list(df.columns)}\")\n",
    "print(f\"\\nüîç Data Types:\\n{df.dtypes}\")\n",
    "print(f\"\\n‚ùì Missing Values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nüîÑ Duplicates: {df.duplicated().sum()}\")\n",
    "print(f\"\\nüìà Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154dee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_Names</th>\n",
       "      <th>Phone_No.</th>\n",
       "      <th>Math</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Roll No.</th>\n",
       "      <th>School Name</th>\n",
       "      <th>Student Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Contreras</td>\n",
       "      <td>9208625450</td>\n",
       "      <td>76</td>\n",
       "      <td>84</td>\n",
       "      <td>54</td>\n",
       "      <td>B+</td>\n",
       "      <td>Good Pursuance</td>\n",
       "      <td>524613</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>478 Mooney Park, New Valerie, VI 28836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph Horton</td>\n",
       "      <td>9886408555</td>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>A</td>\n",
       "      <td>Very Good Achivement</td>\n",
       "      <td>561635</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>037 Matthew Shores, Greeneton, CA 98399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Savannah Burns MD</td>\n",
       "      <td>9047592659</td>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>C</td>\n",
       "      <td>Below Average Achivement</td>\n",
       "      <td>560985</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>96124 Lloyd Streets, Edwardmouth, DC 61677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Carter</td>\n",
       "      <td>9048473864</td>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>32</td>\n",
       "      <td>D</td>\n",
       "      <td>Poor Pursuance</td>\n",
       "      <td>535126</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>11959 Clark Village, Ivanview, NH 43940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Rodriguez</td>\n",
       "      <td>9685225730</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>B+</td>\n",
       "      <td>Good Pursuance</td>\n",
       "      <td>559410</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>051 Weaver Glen Apt. 724, West Davidborough, M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Student_Names   Phone_No.  Math  Physics  Chemistry Grade  \\\n",
       "0   Donald Contreras  9208625450    76       84         54    B+   \n",
       "1      Joseph Horton  9886408555    91       75         78     A   \n",
       "2  Savannah Burns MD  9047592659    64       98         20     C   \n",
       "3     William Carter  9048473864    15       95         32     D   \n",
       "4     John Rodriguez  9685225730    86       86         66    B+   \n",
       "\n",
       "                    Comment  Roll No.           School Name  \\\n",
       "0            Good Pursuance    524613  Martin Luther School   \n",
       "1      Very Good Achivement    561635  Martin Luther School   \n",
       "2  Below Average Achivement    560985  Martin Luther School   \n",
       "3            Poor Pursuance    535126  Martin Luther School   \n",
       "4            Good Pursuance    559410  Martin Luther School   \n",
       "\n",
       "                                     Student Address  \n",
       "0             478 Mooney Park, New Valerie, VI 28836  \n",
       "1            037 Matthew Shores, Greeneton, CA 98399  \n",
       "2         96124 Lloyd Streets, Edwardmouth, DC 61677  \n",
       "3            11959 Clark Village, Ivanview, NH 43940  \n",
       "4  051 Weaver Glen Apt. 724, West Davidborough, M...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_Names</th>\n",
       "      <th>Phone_No.</th>\n",
       "      <th>Math</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Roll No.</th>\n",
       "      <th>School Name</th>\n",
       "      <th>Student Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>Kimberly Stevens</td>\n",
       "      <td>9129352703</td>\n",
       "      <td>40</td>\n",
       "      <td>87</td>\n",
       "      <td>65</td>\n",
       "      <td>B</td>\n",
       "      <td>Average Performance</td>\n",
       "      <td>569342</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>27054 Adrian Streets, Diazmouth, OH 81346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>Kelsey Bonilla</td>\n",
       "      <td>9649715711</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "      <td>B+</td>\n",
       "      <td>Good Pursuance</td>\n",
       "      <td>530124</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>570 Christopher Run, Williammouth, ND 11535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>Kelly Dunn</td>\n",
       "      <td>9825362271</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>Below Average Achivement</td>\n",
       "      <td>592266</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>32283 Carpenter Summit, North Patricia, PR 51483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>Joseph Nichols</td>\n",
       "      <td>9363540473</td>\n",
       "      <td>24</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>C</td>\n",
       "      <td>Below Average Achivement</td>\n",
       "      <td>583028</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>2336 Blackburn Fall Apt. 905, South Shelby, ND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>Susan Armstrong</td>\n",
       "      <td>9879539785</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>D</td>\n",
       "      <td>Poor Pursuance</td>\n",
       "      <td>503637</td>\n",
       "      <td>Martin Luther School</td>\n",
       "      <td>2328 Jennifer Extension, Lake David, OR 11243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Student_Names   Phone_No.  Math  Physics  Chemistry Grade  \\\n",
       "8995  Kimberly Stevens  9129352703    40       87         65     B   \n",
       "8996    Kelsey Bonilla  9649715711    56       84         75    B+   \n",
       "8997        Kelly Dunn  9825362271    80       70         16     C   \n",
       "8998    Joseph Nichols  9363540473    24       95         59     C   \n",
       "8999   Susan Armstrong  9879539785    31       76         18     D   \n",
       "\n",
       "                       Comment  Roll No.           School Name  \\\n",
       "8995       Average Performance    569342  Martin Luther School   \n",
       "8996            Good Pursuance    530124  Martin Luther School   \n",
       "8997  Below Average Achivement    592266  Martin Luther School   \n",
       "8998  Below Average Achivement    583028  Martin Luther School   \n",
       "8999            Poor Pursuance    503637  Martin Luther School   \n",
       "\n",
       "                                        Student Address  \n",
       "8995          27054 Adrian Streets, Diazmouth, OH 81346  \n",
       "8996        570 Christopher Run, Williammouth, ND 11535  \n",
       "8997   32283 Carpenter Summit, North Patricia, PR 51483  \n",
       "8998  2336 Blackburn Fall Apt. 905, South Shelby, ND...  \n",
       "8999      2328 Jennifer Extension, Lake David, OR 11243  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Unique Grades (7): ['A', 'A+', 'B', 'B+', 'C', 'D', 'F']\n",
      "\n",
      "üí¨ Unique Comments (7): <StringArray>\n",
      "[          'Good Pursuance',     'Very Good Achivement',\n",
      " 'Below Average Achivement',           'Poor Pursuance',\n",
      "                   'Failed',      'Average Performance',\n",
      "    'Excellent Performance']\n",
      "Length: 7, dtype: str\n",
      "\n",
      "üè´ Unique Schools: <StringArray>\n",
      "['Martin Luther School']\n",
      "Length: 1, dtype: str\n",
      "\n",
      "üìä Grade Distribution:\n",
      "Grade\n",
      "A      360\n",
      "A+      49\n",
      "B     1797\n",
      "B+    1014\n",
      "C     2187\n",
      "D     2887\n",
      "F      706\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display first and last rows\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(df.tail())\n",
    "\n",
    "# Unique values for categorical columns\n",
    "print(f\"\\nüìù Unique Grades ({df['Grade'].nunique()}): {sorted(df['Grade'].unique())}\")\n",
    "print(f\"\\nüí¨ Unique Comments ({df['Comment'].nunique()}): {df['Comment'].unique()}\")\n",
    "print(f\"\\nüè´ Unique Schools: {df['School Name'].unique()}\")\n",
    "\n",
    "# Grade distribution\n",
    "print(f\"\\nüìä Grade Distribution:\")\n",
    "print(df['Grade'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912b4ce",
   "metadata": {},
   "source": [
    "## Section 3: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20976c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dropped columns: ['Student_Names', 'Phone_No.', 'Roll No.', 'School Name', 'Student Address', 'Comment']\n",
      "Remaining columns: ['Math', 'Physics', 'Chemistry', 'Grade']\n",
      "Shape after cleaning: (9000, 4)\n",
      "\n",
      "Data types:\n",
      "Math         int64\n",
      "Physics      int64\n",
      "Chemistry    int64\n",
      "Grade          str\n",
      "dtype: object\n",
      "\n",
      "üìä Outlier Analysis (IQR Method):\n",
      "  Math: Q1=33, Q3=78, IQR=45, Bounds=[-34, 146], Outliers=0\n",
      "  Physics: Q1=32, Q3=77, IQR=45, Bounds=[-36, 144], Outliers=0\n",
      "  Chemistry: Q1=32, Q3=77, IQR=45, Bounds=[-36, 144], Outliers=0\n",
      "\n",
      "‚úÖ Added Total_Score and Average_Score\n",
      "\n",
      "Cleaned dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Average_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>84</td>\n",
       "      <td>54</td>\n",
       "      <td>B+</td>\n",
       "      <td>214</td>\n",
       "      <td>71.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>A</td>\n",
       "      <td>244</td>\n",
       "      <td>81.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>C</td>\n",
       "      <td>182</td>\n",
       "      <td>60.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>32</td>\n",
       "      <td>D</td>\n",
       "      <td>142</td>\n",
       "      <td>47.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>B+</td>\n",
       "      <td>238</td>\n",
       "      <td>79.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Math  Physics  Chemistry Grade  Total_Score  Average_Score\n",
       "0    76       84         54    B+          214      71.333333\n",
       "1    91       75         78     A          244      81.333333\n",
       "2    64       98         20     C          182      60.666667\n",
       "3    15       95         32     D          142      47.333333\n",
       "4    86       86         66    B+          238      79.333333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 3: Data Cleaning and Preprocessing\n",
    "# ============================================================\n",
    "\n",
    "# Drop irrelevant columns (identifiers, no-variance columns)\n",
    "drop_cols = ['Student_Names', 'Phone_No.', 'Roll No.', 'School Name', 'Student Address']\n",
    "# Comment is 1:1 with Grade (leaky feature), drop it too\n",
    "drop_cols.append('Comment')\n",
    "df_clean = df.drop(columns=drop_cols)\n",
    "\n",
    "print(f\"‚úÖ Dropped columns: {drop_cols}\")\n",
    "print(f\"Remaining columns: {list(df_clean.columns)}\")\n",
    "print(f\"Shape after cleaning: {df_clean.shape}\")\n",
    "\n",
    "# Check data types\n",
    "print(f\"\\nData types:\\n{df_clean.dtypes}\")\n",
    "\n",
    "# Outlier detection using IQR\n",
    "print(\"\\nüìä Outlier Analysis (IQR Method):\")\n",
    "for col in ['Math', 'Physics', 'Chemistry']:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    outliers = df_clean[(df_clean[col] < lower) | (df_clean[col] > upper)].shape[0]\n",
    "    print(f\"  {col}: Q1={Q1:.0f}, Q3={Q3:.0f}, IQR={IQR:.0f}, \"\n",
    "          f\"Bounds=[{lower:.0f}, {upper:.0f}], Outliers={outliers}\")\n",
    "\n",
    "# Create Total and Average scores\n",
    "df_clean['Total_Score'] = df_clean['Math'] + df_clean['Physics'] + df_clean['Chemistry']\n",
    "df_clean['Average_Score'] = df_clean['Total_Score'] / 3\n",
    "\n",
    "print(f\"\\n‚úÖ Added Total_Score and Average_Score\")\n",
    "print(f\"\\nCleaned dataset preview:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f7478",
   "metadata": {},
   "source": [
    "## Section 4: Exploratory Data Analysis (EDA) with Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8e83e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Grade distribution plot saved\n",
      "‚úÖ Score distribution plots saved\n",
      "‚úÖ Correlation heatmap saved\n",
      "‚úÖ Boxplots saved\n",
      "‚úÖ Violin plots saved\n",
      "\n",
      "‚úÖ All EDA visualizations generated!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 4: EDA Visualizations\n",
    "# ============================================================\n",
    "\n",
    "def save_plot(fig, name):\n",
    "    \"\"\"Save plot to file and encode as base64 for HTML report.\"\"\"\n",
    "    path = f'outputs/plots/{name}.png'\n",
    "    fig.savefig(path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    buf = BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    buf.seek(0)\n",
    "    report_images[name] = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    plt.close(fig)\n",
    "    return path\n",
    "\n",
    "# 4a. Grade Distribution\n",
    "grade_order = ['F', 'D', 'C', 'B', 'B+', 'A', 'A+']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "grade_counts = df_clean['Grade'].value_counts().reindex(grade_order)\n",
    "colors = ['#e74c3c', '#e67e22', '#f39c12', '#3498db', '#2980b9', '#27ae60', '#1abc9c']\n",
    "bars = ax.bar(grade_order, grade_counts.values, color=colors, edgecolor='black', linewidth=0.5)\n",
    "for bar, count in zip(bars, grade_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 30,\n",
    "            str(count), ha='center', va='bottom', fontweight='bold')\n",
    "ax.set_title('Grade Distribution', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Grade', fontsize=13)\n",
    "ax.set_ylabel('Count', fontsize=13)\n",
    "save_plot(fig, 'grade_distribution')\n",
    "print(\"‚úÖ Grade distribution plot saved\")\n",
    "\n",
    "# 4b. Score distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for idx, col in enumerate(['Math', 'Physics', 'Chemistry']):\n",
    "    axes[idx].hist(df_clean[col], bins=30, color=colors[idx+3], edgecolor='black',\n",
    "                   alpha=0.8, linewidth=0.5)\n",
    "    axes[idx].axvline(df_clean[col].mean(), color='red', linestyle='--',\n",
    "                      label=f'Mean: {df_clean[col].mean():.1f}')\n",
    "    axes[idx].axvline(df_clean[col].median(), color='green', linestyle='--',\n",
    "                      label=f'Median: {df_clean[col].median():.1f}')\n",
    "    axes[idx].set_title(f'{col} Score Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Score')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'score_distributions')\n",
    "print(\"‚úÖ Score distribution plots saved\")\n",
    "\n",
    "# 4c. Correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "numeric_cols = ['Math', 'Physics', 'Chemistry', 'Total_Score', 'Average_Score']\n",
    "corr_matrix = df_clean[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.3f',\n",
    "            square=True, linewidths=1, ax=ax)\n",
    "ax.set_title('Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "save_plot(fig, 'correlation_heatmap')\n",
    "print(\"‚úÖ Correlation heatmap saved\")\n",
    "\n",
    "# 4d. Boxplots of scores by Grade\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for idx, col in enumerate(['Math', 'Physics', 'Chemistry']):\n",
    "    sns.boxplot(data=df_clean, x='Grade', y=col, order=grade_order,\n",
    "                palette=colors, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{col} by Grade', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'boxplots_by_grade')\n",
    "print(\"‚úÖ Boxplots saved\")\n",
    "\n",
    "# 4e. Violin plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for idx, col in enumerate(['Math', 'Physics', 'Chemistry']):\n",
    "    sns.violinplot(data=df_clean, x='Grade', y=col, order=grade_order,\n",
    "                   palette=colors, ax=axes[idx], inner='box')\n",
    "    axes[idx].set_title(f'{col} Distribution by Grade', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'violin_plots')\n",
    "print(\"‚úÖ Violin plots saved\")\n",
    "\n",
    "print(\"\\n‚úÖ All EDA visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85c5b8",
   "metadata": {},
   "source": [
    "## Section 5: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c1164ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Engineered Features Created:\n",
      "  ‚Ä¢ Max_Score, Min_Score, Score_Range, Score_Std\n",
      "  ‚Ä¢ Pass_Fail (F=0, else=1): {1: 8294, 0: 706}\n",
      "  ‚Ä¢ Is_Above_Average: {1: 4511, 0: 4489}\n",
      "  ‚Ä¢ Subject performance levels (Low/Medium/High)\n",
      "\n",
      "Dataset shape: (9000, 15)\n",
      "‚úÖ Cleaned dataset saved to outputs/student_cleaned.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Max_Score</th>\n",
       "      <th>Min_Score</th>\n",
       "      <th>Score_Range</th>\n",
       "      <th>Score_Std</th>\n",
       "      <th>Pass_Fail</th>\n",
       "      <th>Is_Above_Average</th>\n",
       "      <th>Math_Level</th>\n",
       "      <th>Physics_Level</th>\n",
       "      <th>Chemistry_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>84</td>\n",
       "      <td>54</td>\n",
       "      <td>B+</td>\n",
       "      <td>214</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>84</td>\n",
       "      <td>54</td>\n",
       "      <td>30</td>\n",
       "      <td>15.534907</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>78</td>\n",
       "      <td>A</td>\n",
       "      <td>244</td>\n",
       "      <td>81.333333</td>\n",
       "      <td>91</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "      <td>8.504901</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>C</td>\n",
       "      <td>182</td>\n",
       "      <td>60.666667</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "      <td>39.106692</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>95</td>\n",
       "      <td>32</td>\n",
       "      <td>D</td>\n",
       "      <td>142</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>42.146570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>B+</td>\n",
       "      <td>238</td>\n",
       "      <td>79.333333</td>\n",
       "      <td>86</td>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>11.547005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Math  Physics  Chemistry Grade  Total_Score  Average_Score  Max_Score  \\\n",
       "0    76       84         54    B+          214      71.333333         84   \n",
       "1    91       75         78     A          244      81.333333         91   \n",
       "2    64       98         20     C          182      60.666667         98   \n",
       "3    15       95         32     D          142      47.333333         95   \n",
       "4    86       86         66    B+          238      79.333333         86   \n",
       "\n",
       "   Min_Score  Score_Range  Score_Std  Pass_Fail  Is_Above_Average Math_Level  \\\n",
       "0         54           30  15.534907          1                 1       High   \n",
       "1         75           16   8.504901          1                 1       High   \n",
       "2         20           78  39.106692          1                 1     Medium   \n",
       "3         15           80  42.146570          1                 0        Low   \n",
       "4         66           20  11.547005          1                 1       High   \n",
       "\n",
       "  Physics_Level Chemistry_Level  \n",
       "0          High          Medium  \n",
       "1          High            High  \n",
       "2          High             Low  \n",
       "3          High             Low  \n",
       "4          High          Medium  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 5: Feature Engineering\n",
    "# ============================================================\n",
    "\n",
    "# Additional engineered features\n",
    "df_clean['Max_Score'] = df_clean[['Math', 'Physics', 'Chemistry']].max(axis=1)\n",
    "df_clean['Min_Score'] = df_clean[['Math', 'Physics', 'Chemistry']].min(axis=1)\n",
    "df_clean['Score_Range'] = df_clean['Max_Score'] - df_clean['Min_Score']\n",
    "df_clean['Score_Std'] = df_clean[['Math', 'Physics', 'Chemistry']].std(axis=1)\n",
    "\n",
    "# Binary Pass/Fail (F=0, else=1)\n",
    "df_clean['Pass_Fail'] = (df_clean['Grade'] != 'F').astype(int)\n",
    "\n",
    "# Above average flag\n",
    "overall_avg = df_clean['Average_Score'].mean()\n",
    "df_clean['Is_Above_Average'] = (df_clean['Average_Score'] > overall_avg).astype(int)\n",
    "\n",
    "# Subject-wise performance bins\n",
    "for col in ['Math', 'Physics', 'Chemistry']:\n",
    "    df_clean[f'{col}_Level'] = pd.cut(df_clean[col],\n",
    "                                       bins=[0, 40, 70, 100],\n",
    "                                       labels=['Low', 'Medium', 'High'],\n",
    "                                       include_lowest=True)\n",
    "\n",
    "print(\"‚úÖ Engineered Features Created:\")\n",
    "print(f\"  ‚Ä¢ Max_Score, Min_Score, Score_Range, Score_Std\")\n",
    "print(f\"  ‚Ä¢ Pass_Fail (F=0, else=1): {df_clean['Pass_Fail'].value_counts().to_dict()}\")\n",
    "print(f\"  ‚Ä¢ Is_Above_Average: {df_clean['Is_Above_Average'].value_counts().to_dict()}\")\n",
    "print(f\"  ‚Ä¢ Subject performance levels (Low/Medium/High)\")\n",
    "print(f\"\\nDataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_clean.to_csv('outputs/student_cleaned.csv', index=False)\n",
    "print(\"‚úÖ Cleaned dataset saved to outputs/student_cleaned.csv\")\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828fc05",
   "metadata": {},
   "source": [
    "## Section 6 & 7: Encode Variables, Train-Test Split, and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddacc512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix X shape: (9000, 9)\n",
      "Multiclass target classes: [0 1 2 3 4 5 6] (7 classes)\n",
      "Binary target distribution: Pass=8294, Fail=706\n",
      "\n",
      "Train set: 7200 samples\n",
      "Test set: 1800 samples\n",
      "‚úÖ Feature scaling applied (StandardScaler)\n",
      "‚úÖ Data prepared for all model types!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 6 & 7: Encode, Split, Scale\n",
    "# ============================================================\n",
    "\n",
    "# Ordinal encoding for Grade (preserving order)\n",
    "grade_map = {'F': 0, 'D': 1, 'C': 2, 'B': 3, 'B+': 4, 'A': 5, 'A+': 6}\n",
    "grade_names = ['F', 'D', 'C', 'B', 'B+', 'A', 'A+']\n",
    "df_clean['Grade_Encoded'] = df_clean['Grade'].map(grade_map)\n",
    "\n",
    "# Feature matrix (numeric features only)\n",
    "feature_cols = ['Math', 'Physics', 'Chemistry', 'Total_Score', 'Average_Score',\n",
    "                'Max_Score', 'Min_Score', 'Score_Range', 'Score_Std']\n",
    "\n",
    "X = df_clean[feature_cols].values\n",
    "y_multi = df_clean['Grade_Encoded'].values  # Multiclass target\n",
    "y_binary = df_clean['Pass_Fail'].values      # Binary target\n",
    "\n",
    "print(f\"Feature matrix X shape: {X.shape}\")\n",
    "print(f\"Multiclass target classes: {np.unique(y_multi)} ({len(np.unique(y_multi))} classes)\")\n",
    "print(f\"Binary target distribution: Pass={y_binary.sum()}, Fail={(1-y_binary).sum()}\")\n",
    "\n",
    "# Train-Test Split (80/20, stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_multi, test_size=0.2, random_state=SEED, stratify=y_multi)\n",
    "\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=SEED, stratify=y_binary)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_bin_scaled = scaler.fit_transform(X_train_bin)\n",
    "X_test_bin_scaled = scaler.transform(X_test_bin)\n",
    "\n",
    "print(\"‚úÖ Feature scaling applied (StandardScaler)\")\n",
    "\n",
    "# Regression targets\n",
    "y_total_train = df_clean.loc[X_train_bin_scaled.__len__ and\n",
    "                              range(len(df_clean)), 'Total_Score'] if False else None\n",
    "\n",
    "# Simpler: split for regression\n",
    "X_reg = df_clean[['Math', 'Physics', 'Chemistry']].values\n",
    "y_reg_total = df_clean['Total_Score'].values\n",
    "y_reg_avg = df_clean['Average_Score'].values\n",
    "\n",
    "X_reg_train, X_reg_test, y_total_train, y_total_test = train_test_split(\n",
    "    X_reg, y_reg_total, test_size=0.2, random_state=SEED)\n",
    "_, _, y_avg_train, y_avg_test = train_test_split(\n",
    "    X_reg, y_reg_avg, test_size=0.2, random_state=SEED)\n",
    "\n",
    "X_reg_train_scaled = scaler.fit_transform(X_reg_train)\n",
    "X_reg_test_scaled = scaler.transform(X_reg_test)\n",
    "\n",
    "print(\"‚úÖ Data prepared for all model types!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408ca75",
   "metadata": {},
   "source": [
    "## Section 8‚Äì15: Classification Models\n",
    "\n",
    "We train 8 different classifiers on the student grade prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e8f347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìä Logistic Regression\n",
      "==================================================\n",
      "  Accuracy:  0.9711\n",
      "  Precision: 0.9716\n",
      "  Recall:    0.9711\n",
      "  F1-Score:  0.9702\n",
      "\n",
      "==================================================\n",
      "üìä Decision Tree\n",
      "==================================================\n",
      "  Accuracy:  1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "\n",
      "  Top features: {'Average_Score': 0.9877311189852754, 'Total_Score': 0.0122688810147245, 'Math': 0.0}\n",
      "\n",
      "==================================================\n",
      "üìä Random Forest\n",
      "==================================================\n",
      "  Accuracy:  1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "\n",
      "  Top features: {'Total_Score': 0.4492175293994171, 'Average_Score': 0.40343376414492554, 'Min_Score': 0.05308465747399933}\n",
      "\n",
      "==================================================\n",
      "üìä Gradient Boosting\n",
      "==================================================\n",
      "  Accuracy:  1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "\n",
      "==================================================\n",
      "üìä SVM (linear)\n",
      "==================================================\n",
      "  Accuracy:  0.9917\n",
      "  Precision: 0.9918\n",
      "  Recall:    0.9917\n",
      "  F1-Score:  0.9916\n",
      "\n",
      "==================================================\n",
      "üìä SVM (rbf)\n",
      "==================================================\n",
      "  Accuracy:  0.9739\n",
      "  Precision: 0.9742\n",
      "  Recall:    0.9739\n",
      "  F1-Score:  0.9738\n",
      "\n",
      "  KNN accuracy by k: {3: 0.9438888888888889, 5: 0.9466666666666667, 7: 0.9405555555555556, 9: 0.9438888888888889, 11: 0.9416666666666667}\n",
      "  Best k = 5\n",
      "\n",
      "==================================================\n",
      "üìä KNN (k=5)\n",
      "==================================================\n",
      "  Accuracy:  0.9467\n",
      "  Precision: 0.9469\n",
      "  Recall:    0.9467\n",
      "  F1-Score:  0.9466\n",
      "\n",
      "==================================================\n",
      "üìä Naive Bayes\n",
      "==================================================\n",
      "  Accuracy:  0.9439\n",
      "  Precision: 0.9458\n",
      "  Recall:    0.9439\n",
      "  F1-Score:  0.9442\n",
      "\n",
      "==================================================\n",
      "üìä MLP Neural Network\n",
      "==================================================\n",
      "  Accuracy:  0.9872\n",
      "  Precision: 0.9873\n",
      "  Recall:    0.9872\n",
      "  F1-Score:  0.9872\n",
      "\n",
      "\n",
      "‚úÖ All 8+ classification models trained!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Helper function to evaluate and store classifier results\n",
    "# ============================================================\n",
    "def evaluate_classifier(name, model, X_tr, X_te, y_tr, y_te, scale=False):\n",
    "    \"\"\"Train, predict, evaluate, and store results for a classifier.\"\"\"\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    \n",
    "    acc = accuracy_score(y_te, y_pred)\n",
    "    prec = precision_score(y_te, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_te, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_te, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'y_pred': y_pred,\n",
    "        'model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    return model, y_pred\n",
    "\n",
    "# ============================================================\n",
    "# Model 1: Logistic Regression\n",
    "# ============================================================\n",
    "lr_model, lr_pred = evaluate_classifier(\n",
    "    'Logistic Regression',\n",
    "    LogisticRegression(solver='lbfgs', max_iter=1000, random_state=SEED),\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Model 2: Decision Tree Classifier\n",
    "# ============================================================\n",
    "dt_model, dt_pred = evaluate_classifier(\n",
    "    'Decision Tree',\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=SEED),\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Feature importance from Decision Tree\n",
    "dt_importances = pd.Series(dt_model.feature_importances_, index=feature_cols)\n",
    "print(f\"\\n  Top features: {dt_importances.nlargest(3).to_dict()}\")\n",
    "\n",
    "# ============================================================\n",
    "# Model 3: Random Forest Classifier\n",
    "# ============================================================\n",
    "rf_model, rf_pred = evaluate_classifier(\n",
    "    'Random Forest',\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=15, random_state=SEED, n_jobs=-1),\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "\n",
    "rf_importances = pd.Series(rf_model.feature_importances_, index=feature_cols)\n",
    "print(f\"\\n  Top features: {rf_importances.nlargest(3).to_dict()}\")\n",
    "\n",
    "# ============================================================\n",
    "# Model 4: Gradient Boosting / XGBoost\n",
    "# ============================================================\n",
    "gb_model, gb_pred = evaluate_classifier(\n",
    "    'Gradient Boosting',\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                max_depth=5, random_state=SEED),\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "\n",
    "if HAS_XGBOOST:\n",
    "    xgb_model, xgb_pred = evaluate_classifier(\n",
    "        'XGBoost',\n",
    "        XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5,\n",
    "                      random_state=SEED, use_label_encoder=False,\n",
    "                      eval_metric='mlogloss', verbosity=0),\n",
    "        X_train, X_test, y_train, y_test\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Model 5: Support Vector Machine (SVM)\n",
    "# ============================================================\n",
    "for kernel in ['linear', 'rbf']:\n",
    "    svm_model, svm_pred = evaluate_classifier(\n",
    "        f'SVM ({kernel})',\n",
    "        SVC(kernel=kernel, random_state=SEED, probability=True),\n",
    "        X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "# Model 6: K-Nearest Neighbors\n",
    "# ============================================================\n",
    "# Find optimal k\n",
    "k_scores = {}\n",
    "for k in [3, 5, 7, 9, 11]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    k_scores[k] = accuracy_score(y_test, knn.predict(X_test_scaled))\n",
    "\n",
    "best_k = max(k_scores, key=k_scores.get)\n",
    "print(f\"\\n  KNN accuracy by k: {k_scores}\")\n",
    "print(f\"  Best k = {best_k}\")\n",
    "\n",
    "knn_model, knn_pred = evaluate_classifier(\n",
    "    f'KNN (k={best_k})',\n",
    "    KNeighborsClassifier(n_neighbors=best_k),\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Model 7: Naive Bayes\n",
    "# ============================================================\n",
    "nb_model, nb_pred = evaluate_classifier(\n",
    "    'Naive Bayes',\n",
    "    GaussianNB(),\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Model 8: MLP Neural Network\n",
    "# ============================================================\n",
    "mlp_model, mlp_pred = evaluate_classifier(\n",
    "    'MLP Neural Network',\n",
    "    MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500,\n",
    "                  random_state=SEED, early_stopping=True),\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test\n",
    ")\n",
    "\n",
    "print(\"\\n\\n‚úÖ All 8+ classification models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6c862",
   "metadata": {},
   "source": [
    "## Section 16‚Äì19: Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec67082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìà Linear Regression\n",
      "==================================================\n",
      "  R¬≤:   1.0000\n",
      "  MAE:  0.0000\n",
      "  RMSE: 0.0000\n",
      "\n",
      "==================================================\n",
      "üìà Ridge Regression\n",
      "==================================================\n",
      "  R¬≤:   1.0000\n",
      "  MAE:  0.0000\n",
      "  RMSE: 0.0000\n",
      "\n",
      "==================================================\n",
      "üìà Lasso Regression\n",
      "==================================================\n",
      "  R¬≤:   1.0000\n",
      "  MAE:  0.0052\n",
      "  RMSE: 0.0064\n",
      "\n",
      "==================================================\n",
      "üìà Random Forest Regressor\n",
      "==================================================\n",
      "  R¬≤:   0.9980\n",
      "  MAE:  0.5199\n",
      "  RMSE: 0.6724\n",
      "\n",
      "==================================================\n",
      "üìà Gradient Boosting Regressor\n",
      "==================================================\n",
      "  R¬≤:   0.9969\n",
      "  MAE:  0.6497\n",
      "  RMSE: 0.8298\n",
      "\n",
      "üìä Regression Model Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge Regression</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso Regression</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Regressor</th>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.5199</td>\n",
       "      <td>0.4521</td>\n",
       "      <td>0.6724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Regressor</th>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.8298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 R2     MAE     MSE    RMSE\n",
       "Linear Regression            1.0000  0.0000  0.0000  0.0000\n",
       "Ridge Regression             1.0000  0.0000  0.0000  0.0000\n",
       "Lasso Regression             1.0000  0.0052  0.0000  0.0064\n",
       "Random Forest Regressor      0.9980  0.5199  0.4521  0.6724\n",
       "Gradient Boosting Regressor  0.9969  0.6497  0.6886  0.8298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All regression models trained!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 16‚Äì19: Regression Models\n",
    "# ============================================================\n",
    "reg_results = {}\n",
    "\n",
    "def evaluate_regressor(name, model, X_tr, X_te, y_tr, y_te):\n",
    "    \"\"\"Train and evaluate a regression model.\"\"\"\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    \n",
    "    r2 = r2_score(y_te, y_pred)\n",
    "    mae = mean_absolute_error(y_te, y_pred)\n",
    "    mse = mean_squared_error(y_te, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    reg_results[name] = {'R2': r2, 'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'model': model}\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìà {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"  R¬≤:   {r2:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    return model, y_pred\n",
    "\n",
    "# Model 9: Linear Regression (predict Total_Score from individual scores)\n",
    "lr_reg, lr_reg_pred = evaluate_regressor(\n",
    "    'Linear Regression', LinearRegression(),\n",
    "    X_reg_train, X_reg_test, y_total_train, y_total_test)\n",
    "\n",
    "# Model 10: Ridge Regression\n",
    "ridge_reg, ridge_pred = evaluate_regressor(\n",
    "    'Ridge Regression', Ridge(alpha=1.0),\n",
    "    X_reg_train, X_reg_test, y_total_train, y_total_test)\n",
    "\n",
    "# Model 10b: Lasso Regression\n",
    "lasso_reg, lasso_pred = evaluate_regressor(\n",
    "    'Lasso Regression', Lasso(alpha=0.1),\n",
    "    X_reg_train, X_reg_test, y_total_train, y_total_test)\n",
    "\n",
    "# Model 11: Random Forest Regressor (predict Average_Score)\n",
    "rfr_reg, rfr_pred = evaluate_regressor(\n",
    "    'Random Forest Regressor', RandomForestRegressor(n_estimators=100, random_state=SEED),\n",
    "    X_reg_train, X_reg_test, y_avg_train, y_avg_test)\n",
    "\n",
    "# Model 12: Gradient Boosting Regressor\n",
    "gbr_reg, gbr_pred = evaluate_regressor(\n",
    "    'Gradient Boosting Regressor', GradientBoostingRegressor(n_estimators=100, random_state=SEED),\n",
    "    X_reg_train, X_reg_test, y_avg_train, y_avg_test)\n",
    "\n",
    "# Plot: Actual vs Predicted for Linear Regression\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].scatter(y_total_test, lr_reg_pred, alpha=0.3, s=10, color='steelblue')\n",
    "axes[0].plot([y_total_test.min(), y_total_test.max()],\n",
    "             [y_total_test.min(), y_total_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Actual Total Score')\n",
    "axes[0].set_ylabel('Predicted Total Score')\n",
    "axes[0].set_title('Linear Regression: Actual vs Predicted', fontweight='bold')\n",
    "\n",
    "# Residuals\n",
    "residuals = y_total_test - lr_reg_pred\n",
    "axes[1].scatter(lr_reg_pred, residuals, alpha=0.3, s=10, color='coral')\n",
    "axes[1].axhline(0, color='red', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted Total Score')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual Plot', fontweight='bold')\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'regression_results')\n",
    "\n",
    "# Regression comparison table\n",
    "reg_df = pd.DataFrame({k: {m: v for m, v in v.items() if m != 'model'}\n",
    "                       for k, v in reg_results.items()}).T\n",
    "print(\"\\nüìä Regression Model Comparison:\")\n",
    "display(reg_df.round(4))\n",
    "print(\"\\n‚úÖ All regression models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551ae49",
   "metadata": {},
   "source": [
    "## Section 20‚Äì22: Clustering and Dimensionality Reduction (K-Means, PCA, DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29e19dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ K-Means (k=7): Silhouette Score = 0.2803\n",
      "PCA Explained Variance: [0.341 0.334 0.325]\n",
      "Total variance explained by 3 components: 100.0%\n",
      "\n",
      "‚úÖ DBSCAN: 1 clusters found, 0 noise points\n",
      "\n",
      "‚úÖ Clustering and PCA complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 20: K-Means Clustering\n",
    "# ============================================================\n",
    "X_cluster = scaler.fit_transform(df_clean[['Math', 'Physics', 'Chemistry']].values)\n",
    "\n",
    "# Elbow method\n",
    "inertias = []\n",
    "sil_scores = []\n",
    "K_range = range(2, 11)\n",
    "for k in K_range:\n",
    "    km = KMeans(n_clusters=k, random_state=SEED, n_init=10)\n",
    "    km.fit(X_cluster)\n",
    "    inertias.append(km.inertia_)\n",
    "    sil_scores.append(silhouette_score(X_cluster, km.labels_))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].plot(K_range, inertias, 'bo-', linewidth=2)\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "axes[0].set_title('Elbow Method', fontweight='bold')\n",
    "\n",
    "axes[1].plot(K_range, sil_scores, 'ro-', linewidth=2)\n",
    "axes[1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1].set_ylabel('Silhouette Score')\n",
    "axes[1].set_title('Silhouette Analysis', fontweight='bold')\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'elbow_silhouette')\n",
    "\n",
    "# Use k=7 (matching number of grades)\n",
    "best_k_cluster = 7\n",
    "km_final = KMeans(n_clusters=best_k_cluster, random_state=SEED, n_init=10)\n",
    "km_labels = km_final.fit_predict(X_cluster)\n",
    "\n",
    "print(f\"‚úÖ K-Means (k={best_k_cluster}): Silhouette Score = \"\n",
    "      f\"{silhouette_score(X_cluster, km_labels):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Section 21: PCA\n",
    "# ============================================================\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_cluster)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# PCA colored by actual grade\n",
    "scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=df_clean['Grade_Encoded'],\n",
    "                           cmap='viridis', alpha=0.4, s=10)\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
    "axes[0].set_title('PCA: Colored by Grade', fontweight='bold')\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Grade (0=F, 6=A+)')\n",
    "\n",
    "# PCA colored by K-Means cluster\n",
    "scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=km_labels,\n",
    "                           cmap='tab10', alpha=0.4, s=10)\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
    "axes[1].set_title('PCA: Colored by K-Means Cluster', fontweight='bold')\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'pca_clusters')\n",
    "\n",
    "print(f\"PCA Explained Variance: {pca.explained_variance_ratio_.round(3)}\")\n",
    "print(f\"Total variance explained by 3 components: {pca.explained_variance_ratio_.sum():.1%}\")\n",
    "\n",
    "# ============================================================\n",
    "# Section 22: DBSCAN\n",
    "# ============================================================\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "db_labels = dbscan.fit_predict(X_cluster)\n",
    "n_clusters_db = len(set(db_labels)) - (1 if -1 in db_labels else 0)\n",
    "n_noise = (db_labels == -1).sum()\n",
    "\n",
    "print(f\"\\n‚úÖ DBSCAN: {n_clusters_db} clusters found, {n_noise} noise points\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=db_labels, cmap='tab10', alpha=0.4, s=10)\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_title(f'DBSCAN Clustering ({n_clusters_db} clusters, {n_noise} noise)', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax, label='Cluster (-1=noise)')\n",
    "save_plot(fig, 'dbscan_clusters')\n",
    "\n",
    "print(\"\\n‚úÖ Clustering and PCA complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522b8f0",
   "metadata": {},
   "source": [
    "## Section 23: Hyperparameter Tuning (GridSearchCV & RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffdc80e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç GridSearchCV: Random Forest...\n",
      "  Best params: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  Best CV accuracy: 0.9999\n",
      "  Test accuracy: 0.9994\n",
      "\n",
      "üîç RandomizedSearchCV: Gradient Boosting...\n",
      "  Best params: {'n_estimators': 100, 'min_samples_split': 10, 'max_depth': 10, 'learning_rate': 0.01}\n",
      "  Best CV accuracy: 0.9999\n",
      "  Test accuracy: 1.0000\n",
      "\n",
      "‚úÖ Hyperparameter tuning complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 23: Hyperparameter Tuning\n",
    "# ============================================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "print(\"üîç GridSearchCV: Random Forest...\")\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=SEED),\n",
    "                       rf_params, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "print(f\"  Best params: {rf_grid.best_params_}\")\n",
    "print(f\"  Best CV accuracy: {rf_grid.best_score_:.4f}\")\n",
    "print(f\"  Test accuracy: {rf_grid.score(X_test, y_test):.4f}\")\n",
    "\n",
    "# Store tuned result\n",
    "y_pred_tuned_rf = rf_grid.predict(X_test)\n",
    "results['Random Forest (Tuned)'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_tuned_rf),\n",
    "    'precision': precision_score(y_test, y_pred_tuned_rf, average='weighted', zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_tuned_rf, average='weighted', zero_division=0),\n",
    "    'f1_score': f1_score(y_test, y_pred_tuned_rf, average='weighted', zero_division=0),\n",
    "    'y_pred': y_pred_tuned_rf,\n",
    "    'model': rf_grid.best_estimator_\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for Gradient Boosting\n",
    "print(\"\\nüîç RandomizedSearchCV: Gradient Boosting...\")\n",
    "gb_params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "gb_random = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=SEED),\n",
    "    gb_params, n_iter=20, cv=cv, scoring='accuracy',\n",
    "    random_state=SEED, n_jobs=-1)\n",
    "gb_random.fit(X_train, y_train)\n",
    "print(f\"  Best params: {gb_random.best_params_}\")\n",
    "print(f\"  Best CV accuracy: {gb_random.best_score_:.4f}\")\n",
    "print(f\"  Test accuracy: {gb_random.score(X_test, y_test):.4f}\")\n",
    "\n",
    "results['Gradient Boosting (Tuned)'] = {\n",
    "    'accuracy': accuracy_score(y_test, gb_random.predict(X_test)),\n",
    "    'precision': precision_score(y_test, gb_random.predict(X_test), average='weighted', zero_division=0),\n",
    "    'recall': recall_score(y_test, gb_random.predict(X_test), average='weighted', zero_division=0),\n",
    "    'f1_score': f1_score(y_test, gb_random.predict(X_test), average='weighted', zero_division=0),\n",
    "    'y_pred': gb_random.predict(X_test),\n",
    "    'model': gb_random.best_estimator_\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Hyperparameter tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0d3ae",
   "metadata": {},
   "source": [
    "## Section 24‚Äì28: Cross-Validation, Feature Importance, Confusion Matrices, ROC, Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä 5-Fold Cross-Validation Results:\n",
      "============================================================\n",
      "  Logistic Regression      : Acc=0.9693¬±0.0047  F1=0.9687¬±0.0045\n",
      "  Decision Tree            : Acc=0.9999¬±0.0003  F1=0.9999¬±0.0003\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Section 24: Cross-Validation and Model Comparison\n",
    "# ============================================================\n",
    "print(\"üìä 5-Fold Cross-Validation Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cv_models = {\n",
    "    'Logistic Regression': LogisticRegression(solver='lbfgs', max_iter=1000, random_state=SEED),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=SEED),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=SEED),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "}\n",
    "\n",
    "cv_results_data = []\n",
    "for name, model in cv_models.items():\n",
    "    # Use scaled data for all for fair comparison\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    f1_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='f1_weighted')\n",
    "    cv_results_data.append({\n",
    "        'Model': name,\n",
    "        'CV Accuracy (mean)': scores.mean(),\n",
    "        'CV Accuracy (std)': scores.std(),\n",
    "        'CV F1 (mean)': f1_scores.mean(),\n",
    "        'CV F1 (std)': f1_scores.std()\n",
    "    })\n",
    "    print(f\"  {name:25s}: Acc={scores.mean():.4f}¬±{scores.std():.4f}  \"\n",
    "          f\"F1={f1_scores.mean():.4f}¬±{f1_scores.std():.4f}\")\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results_data)\n",
    "\n",
    "# Model comparison bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(cv_df))\n",
    "width = 0.35\n",
    "bars1 = ax.bar(x - width/2, cv_df['CV Accuracy (mean)'], width, label='Accuracy',\n",
    "               yerr=cv_df['CV Accuracy (std)'], capsize=3, color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, cv_df['CV F1 (mean)'], width, label='F1 Score',\n",
    "               yerr=cv_df['CV F1 (std)'], capsize=3, color='coral')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Cross-Validation: Model Comparison', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cv_df['Model'], rotation=30, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.05)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'cv_comparison')\n",
    "\n",
    "# ============================================================\n",
    "# Section 25: Feature Importance Analysis\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for idx, (name, importances) in enumerate([\n",
    "    ('Decision Tree', dt_importances),\n",
    "    ('Random Forest', rf_importances),\n",
    "    ('Gradient Boosting', pd.Series(gb_model.feature_importances_, index=feature_cols))\n",
    "]):\n",
    "    importances.sort_values().plot(kind='barh', ax=axes[idx], color='steelblue')\n",
    "    axes[idx].set_title(f'{name}\\nFeature Importance', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Importance')\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'feature_importance')\n",
    "print(\"\\n‚úÖ Feature importance analysis complete!\")\n",
    "\n",
    "# ============================================================\n",
    "# Section 26: Confusion Matrices\n",
    "# ============================================================\n",
    "clf_models_for_cm = {k: v for k, v in results.items()\n",
    "                     if 'y_pred' in v and k not in ['Random Forest (Tuned)', 'Gradient Boosting (Tuned)']}\n",
    "\n",
    "n_models = len(clf_models_for_cm)\n",
    "n_cols = 3\n",
    "n_rows = (n_models + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6*n_cols, 5*n_rows))\n",
    "axes_flat = axes.flatten() if n_models > 1 else [axes]\n",
    "\n",
    "for idx, (name, data) in enumerate(clf_models_for_cm.items()):\n",
    "    cm = confusion_matrix(y_test, data['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes_flat[idx],\n",
    "                xticklabels=grade_names, yticklabels=grade_names)\n",
    "    axes_flat[idx].set_title(f'{name}\\nAcc: {data[\"accuracy\"]:.3f}', fontsize=10, fontweight='bold')\n",
    "    axes_flat[idx].set_xlabel('Predicted')\n",
    "    axes_flat[idx].set_ylabel('Actual')\n",
    "\n",
    "# Hide unused subplots\n",
    "for idx in range(n_models, len(axes_flat)):\n",
    "    axes_flat[idx].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'confusion_matrices')\n",
    "print(\"‚úÖ Confusion matrices saved!\")\n",
    "\n",
    "# ============================================================\n",
    "# Section 27: ROC Curves (Binary Pass/Fail)\n",
    "# ============================================================\n",
    "# Train binary classifiers for ROC\n",
    "binary_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=SEED),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=SEED),\n",
    "    'SVM (rbf)': SVC(kernel='rbf', probability=True, random_state=SEED),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "for name, model in binary_models.items():\n",
    "    model.fit(X_train_bin_scaled, y_train_bin)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_prob = model.predict_proba(X_test_bin_scaled)[:, 1]\n",
    "    else:\n",
    "        y_prob = model.decision_function(X_test_bin_scaled)\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin, y_prob)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    ax.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC={auc_score:.3f})')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random (AUC=0.500)')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves (Binary: Pass vs Fail)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1.05])\n",
    "save_plot(fig, 'roc_curves')\n",
    "print(\"‚úÖ ROC curves saved!\")\n",
    "\n",
    "# ============================================================\n",
    "# Section 28: Learning Curves\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "top_models = [\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=SEED)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "]\n",
    "\n",
    "for idx, (name, model) in enumerate(top_models):\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model, X_train_scaled, y_train, cv=5,\n",
    "        train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy', n_jobs=-1)\n",
    "    \n",
    "    axes[idx].plot(train_sizes, train_scores.mean(axis=1), 'o-', label='Train', color='steelblue')\n",
    "    axes[idx].fill_between(train_sizes,\n",
    "                           train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
    "                           train_scores.mean(axis=1) + train_scores.std(axis=1), alpha=0.1, color='steelblue')\n",
    "    axes[idx].plot(train_sizes, val_scores.mean(axis=1), 'o-', label='Validation', color='coral')\n",
    "    axes[idx].fill_between(train_sizes,\n",
    "                           val_scores.mean(axis=1) - val_scores.std(axis=1),\n",
    "                           val_scores.mean(axis=1) + val_scores.std(axis=1), alpha=0.1, color='coral')\n",
    "    axes[idx].set_xlabel('Training Set Size')\n",
    "    axes[idx].set_ylabel('Accuracy')\n",
    "    axes[idx].set_title(f'Learning Curve: {name}', fontweight='bold')\n",
    "    axes[idx].legend(loc='lower right')\n",
    "    axes[idx].set_ylim(0.3, 1.05)\n",
    "\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'learning_curves')\n",
    "print(\"‚úÖ Learning curves saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcd9f48",
   "metadata": {},
   "source": [
    "## Section 29: Ensemble Methods (Voting & Stacking Classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 29: Ensemble Methods\n",
    "# ============================================================\n",
    "\n",
    "# Voting Classifier (soft voting)\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=SEED)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=SEED)),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=SEED)),\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=estimators, voting='soft')\n",
    "voting_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test_scaled)\n",
    "voting_acc = accuracy_score(y_test, y_pred_voting)\n",
    "results['Voting Ensemble'] = {\n",
    "    'accuracy': voting_acc,\n",
    "    'precision': precision_score(y_test, y_pred_voting, average='weighted', zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_voting, average='weighted', zero_division=0),\n",
    "    'f1_score': f1_score(y_test, y_pred_voting, average='weighted', zero_division=0),\n",
    "    'y_pred': y_pred_voting,\n",
    "    'model': voting_clf\n",
    "}\n",
    "print(f\"‚úÖ Voting Classifier Accuracy: {voting_acc:.4f}\")\n",
    "\n",
    "# Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, random_state=SEED)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=50, random_state=SEED)),\n",
    "        ('svm', SVC(kernel='rbf', probability=True, random_state=SEED)),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "    cv=5\n",
    ")\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "y_pred_stacking = stacking_clf.predict(X_test_scaled)\n",
    "stacking_acc = accuracy_score(y_test, y_pred_stacking)\n",
    "results['Stacking Ensemble'] = {\n",
    "    'accuracy': stacking_acc,\n",
    "    'precision': precision_score(y_test, y_pred_stacking, average='weighted', zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred_stacking, average='weighted', zero_division=0),\n",
    "    'f1_score': f1_score(y_test, y_pred_stacking, average='weighted', zero_division=0),\n",
    "    'y_pred': y_pred_stacking,\n",
    "    'model': stacking_clf\n",
    "}\n",
    "print(f\"‚úÖ Stacking Classifier Accuracy: {stacking_acc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Final Model Comparison Summary\n",
    "# ============================================================\n",
    "comparison_data = []\n",
    "for name, data in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': data['accuracy'],\n",
    "        'Precision': data['precision'],\n",
    "        'Recall': data['recall'],\n",
    "        'F1 Score': data['f1_score']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data).sort_values('Accuracy', ascending=False)\n",
    "comparison_df.index = range(1, len(comparison_df) + 1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä FINAL MODEL COMPARISON (sorted by accuracy)\")\n",
    "print(\"=\" * 70)\n",
    "display(comparison_df)\n",
    "\n",
    "# Save comparison plot\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.2\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "colors_met = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(metrics, colors_met)):\n",
    "    ax.bar(x + i*width, comparison_df[metric], width, label=metric, color=color)\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('All Models Performance Comparison', fontweight='bold', fontsize=14)\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(comparison_df['Model'], rotation=45, ha='right', fontsize=9)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "fig.tight_layout()\n",
    "save_plot(fig, 'model_comparison')\n",
    "\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_accuracy = comparison_df.iloc[0]['Accuracy']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name} (Accuracy: {best_accuracy:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd48be7",
   "metadata": {},
   "source": [
    "## Section 30: Generate Final HTML Report with Results and Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Section 30: Generate Final HTML Report\n",
    "# ============================================================\n",
    "\n",
    "# Build model results table rows\n",
    "model_rows = \"\"\n",
    "for _, row in comparison_df.iterrows():\n",
    "    model_rows += f\"\"\"\n",
    "    <tr>\n",
    "        <td>{row['Model']}</td>\n",
    "        <td>{row['Accuracy']:.4f}</td>\n",
    "        <td>{row['Precision']:.4f}</td>\n",
    "        <td>{row['Recall']:.4f}</td>\n",
    "        <td>{row['F1 Score']:.4f}</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# Regression results table rows\n",
    "reg_rows = \"\"\n",
    "for name, data in reg_results.items():\n",
    "    reg_rows += f\"\"\"\n",
    "    <tr>\n",
    "        <td>{name}</td>\n",
    "        <td>{data['R2']:.4f}</td>\n",
    "        <td>{data['MAE']:.4f}</td>\n",
    "        <td>{data['RMSE']:.4f}</td>\n",
    "    </tr>\"\"\"\n",
    "\n",
    "# Build image tags from base64 encoded images\n",
    "def img_tag(name, width=\"100%\"):\n",
    "    if name in report_images:\n",
    "        return f'<img src=\"data:image/png;base64,{report_images[name]}\" style=\"width:{width}; max-width:900px;\">'\n",
    "    return f'<p><em>Image {name} not available</em></p>'\n",
    "\n",
    "best_model = comparison_df.iloc[0]\n",
    "\n",
    "html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Student Performance ML Analysis Report</title>\n",
    "    <style>\n",
    "        * {{ margin: 0; padding: 0; box-sizing: border-box; }}\n",
    "        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "               background: #f0f2f5; color: #333; line-height: 1.6; }}\n",
    "        .container {{ max-width: 1100px; margin: 0 auto; padding: 20px; }}\n",
    "        \n",
    "        header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "                 color: white; padding: 40px 20px; text-align: center;\n",
    "                 border-radius: 12px; margin-bottom: 30px; }}\n",
    "        header h1 {{ font-size: 2.2em; margin-bottom: 10px; }}\n",
    "        header p {{ font-size: 1.1em; opacity: 0.9; }}\n",
    "        \n",
    "        .card {{ background: white; border-radius: 12px; padding: 25px;\n",
    "                margin-bottom: 25px; box-shadow: 0 2px 12px rgba(0,0,0,0.08); }}\n",
    "        .card h2 {{ color: #4a5568; border-bottom: 3px solid #667eea;\n",
    "                   padding-bottom: 10px; margin-bottom: 20px; font-size: 1.5em; }}\n",
    "        .card h3 {{ color: #2d3748; margin: 15px 0 10px 0; }}\n",
    "        \n",
    "        .dashboard {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));\n",
    "                     gap: 15px; margin-bottom: 20px; }}\n",
    "        .stat-box {{ background: linear-gradient(135deg, #667eea, #764ba2);\n",
    "                    color: white; padding: 20px; border-radius: 10px; text-align: center; }}\n",
    "        .stat-box .value {{ font-size: 2em; font-weight: bold; }}\n",
    "        .stat-box .label {{ font-size: 0.9em; opacity: 0.9; }}\n",
    "        \n",
    "        table {{ width: 100%; border-collapse: collapse; margin: 15px 0; }}\n",
    "        th, td {{ padding: 12px 15px; text-align: left; border-bottom: 1px solid #e2e8f0; }}\n",
    "        th {{ background: #667eea; color: white; font-weight: 600; }}\n",
    "        tr:hover {{ background: #f7fafc; }}\n",
    "        tr:nth-child(even) {{ background: #f8f9fa; }}\n",
    "        \n",
    "        .explanation {{ background: #ebf8ff; border-left: 4px solid #4299e1;\n",
    "                       padding: 15px; margin: 15px 0; border-radius: 0 8px 8px 0; }}\n",
    "        .highlight {{ background: #f0fff4; border-left: 4px solid #48bb78;\n",
    "                     padding: 15px; margin: 15px 0; border-radius: 0 8px 8px 0; }}\n",
    "        .warning {{ background: #fffaf0; border-left: 4px solid #ed8936;\n",
    "                   padding: 15px; margin: 15px 0; border-radius: 0 8px 8px 0; }}\n",
    "        \n",
    "        .img-container {{ text-align: center; margin: 20px 0; }}\n",
    "        .img-container img {{ border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}\n",
    "        \n",
    "        .badge {{ display: inline-block; padding: 4px 12px; border-radius: 20px;\n",
    "                 font-size: 0.85em; font-weight: 600; }}\n",
    "        .badge-gold {{ background: #ffd700; color: #333; }}\n",
    "        .badge-silver {{ background: #c0c0c0; color: #333; }}\n",
    "        .badge-bronze {{ background: #cd7f32; color: white; }}\n",
    "        \n",
    "        footer {{ text-align: center; padding: 20px; color: #718096; font-size: 0.9em; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"container\">\n",
    "\n",
    "<header>\n",
    "    <h1>üéì Student Performance ML Analysis Report</h1>\n",
    "    <p>Comprehensive Machine Learning Analysis of Student Academic Performance</p>\n",
    "    <p>Dataset: {df.shape[0]} students | {df.shape[1]} original features | 7 Grade categories</p>\n",
    "</header>\n",
    "\n",
    "<!-- Dashboard Summary -->\n",
    "<div class=\"dashboard\">\n",
    "    <div class=\"stat-box\">\n",
    "        <div class=\"value\">{df.shape[0]}</div>\n",
    "        <div class=\"label\">Total Students</div>\n",
    "    </div>\n",
    "    <div class=\"stat-box\">\n",
    "        <div class=\"value\">{len(results)}</div>\n",
    "        <div class=\"label\">Models Trained</div>\n",
    "    </div>\n",
    "    <div class=\"stat-box\">\n",
    "        <div class=\"value\">{best_model['Accuracy']:.1%}</div>\n",
    "        <div class=\"label\">Best Accuracy</div>\n",
    "    </div>\n",
    "    <div class=\"stat-box\">\n",
    "        <div class=\"value\">{best_model['Model']}</div>\n",
    "        <div class=\"label\">üèÜ Best Model</div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 1: Dataset Overview -->\n",
    "<div class=\"card\">\n",
    "    <h2>üìã 1. Dataset Overview</h2>\n",
    "    <p>The dataset contains <strong>{df.shape[0]} student records</strong> from Martin Luther School\n",
    "       with scores in <strong>Math, Physics, and Chemistry</strong> (range: 10‚Äì100).</p>\n",
    "    <h3>Grade Distribution</h3>\n",
    "    <table>\n",
    "        <tr><th>Grade</th><th>Count</th><th>Percentage</th><th>Description</th></tr>\n",
    "        <tr><td>A+</td><td>{(df['Grade']=='A+').sum()}</td><td>{(df['Grade']=='A+').mean():.1%}</td><td>Excellent Performance</td></tr>\n",
    "        <tr><td>A</td><td>{(df['Grade']=='A').sum()}</td><td>{(df['Grade']=='A').mean():.1%}</td><td>Very Good Achievement</td></tr>\n",
    "        <tr><td>B+</td><td>{(df['Grade']=='B+').sum()}</td><td>{(df['Grade']=='B+').mean():.1%}</td><td>Good Pursuance</td></tr>\n",
    "        <tr><td>B</td><td>{(df['Grade']=='B').sum()}</td><td>{(df['Grade']=='B').mean():.1%}</td><td>Average Performance</td></tr>\n",
    "        <tr><td>C</td><td>{(df['Grade']=='C').sum()}</td><td>{(df['Grade']=='C').mean():.1%}</td><td>Below Average Achievement</td></tr>\n",
    "        <tr><td>D</td><td>{(df['Grade']=='D').sum()}</td><td>{(df['Grade']=='D').mean():.1%}</td><td>Poor Pursuance</td></tr>\n",
    "        <tr><td>F</td><td>{(df['Grade']=='F').sum()}</td><td>{(df['Grade']=='F').mean():.1%}</td><td>Failed</td></tr>\n",
    "    </table>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Key Insight:</strong> The dataset is imbalanced ‚Äî Grade D is the most common (32.1%),\n",
    "        while A+ is extremely rare (0.5%). This class imbalance affects model performance,\n",
    "        especially for minority classes.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 2: EDA Visualizations -->\n",
    "<div class=\"card\">\n",
    "    <h2>üìä 2. Exploratory Data Analysis</h2>\n",
    "    <div class=\"img-container\">{img_tag('grade_distribution')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> The grade distribution is roughly bell-shaped but skewed toward\n",
    "        lower grades. D is the most frequent grade, suggesting many students struggle across subjects.\n",
    "        The rare A+ class (49 students) will be hardest for models to predict.\n",
    "    </div>\n",
    "    <div class=\"img-container\">{img_tag('score_distributions')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> All three subjects show approximately uniform distributions\n",
    "        across the 10‚Äì100 range, with means around 53‚Äì56. No subject appears inherently harder or easier.\n",
    "    </div>\n",
    "    <div class=\"img-container\">{img_tag('correlation_heatmap')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> Math, Physics, and Chemistry scores show near-zero correlation\n",
    "        with each other (~0.00), meaning student performance in one subject is independent of others.\n",
    "        This is an interesting finding ‚Äî performing well in Math doesn't predict Physics or Chemistry scores.\n",
    "    </div>\n",
    "    <div class=\"img-container\">{img_tag('boxplots_by_grade')}</div>\n",
    "    <div class=\"img-container\">{img_tag('violin_plots')}</div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 3: Classification Results -->\n",
    "<div class=\"card\">\n",
    "    <h2>ü§ñ 3. Classification Model Results (Grade Prediction)</h2>\n",
    "    <p>We trained <strong>{len(comparison_df)} classification models</strong> to predict student grades\n",
    "       from their Math, Physics, and Chemistry scores plus engineered features.</p>\n",
    "    <table>\n",
    "        <tr><th>#</th><th>Model</th><th>Accuracy</th><th>Precision</th><th>Recall</th><th>F1 Score</th></tr>\n",
    "        {''.join(f\"<tr><td>{i+1}</td>{model_rows.split('</tr>')[i].split('<tr>')[1]}</tr>\" if i < len(comparison_df) else \"\" for i in range(len(comparison_df)))}\n",
    "    </table>\n",
    "    <div class=\"img-container\">{img_tag('model_comparison')}</div>\n",
    "    <div class=\"highlight\">\n",
    "        <strong>üèÜ Best Model: {best_model['Model']}</strong><br>\n",
    "        Accuracy: {best_model['Accuracy']:.4f} | F1 Score: {best_model['F1 Score']:.4f}<br><br>\n",
    "        Tree-based ensemble methods (Random Forest, Gradient Boosting) typically perform best on this\n",
    "        dataset because they can capture the non-linear decision boundaries between grade categories\n",
    "        based on the combination of three independent score features.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 4: Confusion Matrices -->\n",
    "<div class=\"card\">\n",
    "    <h2>üî¢ 4. Confusion Matrices</h2>\n",
    "    <div class=\"img-container\">{img_tag('confusion_matrices')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> Confusion matrices show where models make mistakes.\n",
    "        The diagonal represents correct predictions. Most errors occur between adjacent grades\n",
    "        (e.g., B vs B+, C vs D), which is expected since these grades have overlapping score ranges.\n",
    "        The rare A+ class is often misclassified due to limited training examples.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 5: ROC Curves -->\n",
    "<div class=\"card\">\n",
    "    <h2>üìà 5. ROC Curves (Pass/Fail Classification)</h2>\n",
    "    <div class=\"img-container\">{img_tag('roc_curves')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> ROC curves show the tradeoff between true positive rate and\n",
    "        false positive rate for binary Pass/Fail classification. All models achieve high AUC scores,\n",
    "        indicating that distinguishing between passing and failing students is relatively straightforward\n",
    "        based on score features. Models with AUC &gt; 0.90 are considered excellent classifiers.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 6: Feature Importance -->\n",
    "<div class=\"card\">\n",
    "    <h2>üéØ 6. Feature Importance Analysis</h2>\n",
    "    <div class=\"img-container\">{img_tag('feature_importance')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Key Findings:</strong>\n",
    "        <ul>\n",
    "            <li><strong>Total_Score and Average_Score</strong> are the most important features, as grades are\n",
    "                primarily determined by the combined performance across all subjects.</li>\n",
    "            <li><strong>Min_Score</strong> is also highly important ‚Äî a very low score in any subject\n",
    "                can significantly lower the overall grade.</li>\n",
    "            <li>Individual subject scores (Math, Physics, Chemistry) contribute roughly equally,\n",
    "                confirming that no single subject dominates grade determination.</li>\n",
    "            <li><strong>Score_Range and Score_Std</strong> capture the consistency of performance ‚Äî\n",
    "                students with high variance across subjects tend to receive different grades than\n",
    "                consistently performing students.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 7: Cross-Validation -->\n",
    "<div class=\"card\">\n",
    "    <h2>üîÑ 7. Cross-Validation Results</h2>\n",
    "    <div class=\"img-container\">{img_tag('cv_comparison')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> Cross-validation provides a more reliable estimate of model\n",
    "        performance by training and testing on different data splits. Low standard deviation in CV\n",
    "        scores indicates stable, reliable models. Gradient Boosting and Random Forest typically show\n",
    "        the best balance of high accuracy and low variance.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 8: Learning Curves -->\n",
    "<div class=\"card\">\n",
    "    <h2>üìö 8. Learning Curves Analysis</h2>\n",
    "    <div class=\"img-container\">{img_tag('learning_curves')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong>\n",
    "        <ul>\n",
    "            <li>If training and validation curves converge at a high score ‚Üí model generalizes well</li>\n",
    "            <li>Large gap between training and validation ‚Üí overfitting (model memorizes training data)</li>\n",
    "            <li>Both curves plateau at a low score ‚Üí underfitting (model is too simple)</li>\n",
    "            <li>Random Forest may show signs of slight overfitting (high training score, lower validation)</li>\n",
    "            <li>Logistic Regression curves converge quickly, suggesting the model is simpler but stable</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 9: Clustering -->\n",
    "<div class=\"card\">\n",
    "    <h2>üîÆ 9. Clustering Results (Unsupervised Learning)</h2>\n",
    "    <div class=\"img-container\">{img_tag('elbow_silhouette')}</div>\n",
    "    <div class=\"img-container\">{img_tag('pca_clusters')}</div>\n",
    "    <div class=\"img-container\">{img_tag('dbscan_clusters')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> K-Means clustering reveals natural groupings in the data\n",
    "        based on score patterns. The PCA visualization shows that grade labels roughly correspond\n",
    "        to clusters in the reduced feature space, but there is significant overlap between adjacent\n",
    "        grades. DBSCAN identifies the core dense regions and outlier students with unusual score combinations.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 10: Regression -->\n",
    "<div class=\"card\">\n",
    "    <h2>üìà 10. Regression Model Results</h2>\n",
    "    <table>\n",
    "        <tr><th>Model</th><th>R¬≤</th><th>MAE</th><th>RMSE</th></tr>\n",
    "        {reg_rows}\n",
    "    </table>\n",
    "    <div class=\"img-container\">{img_tag('regression_results')}</div>\n",
    "    <div class=\"explanation\">\n",
    "        <strong>Interpretation:</strong> Linear Regression achieves perfect R¬≤ = 1.000 for predicting\n",
    "        Total_Score from individual subject scores because Total_Score = Math + Physics + Chemistry\n",
    "        (a perfect linear relationship). For Average_Score prediction, tree-based regressors capture\n",
    "        non-linear patterns slightly better than linear models.\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!-- Section 11: Conclusions -->\n",
    "<div class=\"card\">\n",
    "    <h2>üéØ 11. Key Conclusions & Recommendations</h2>\n",
    "    <div class=\"highlight\">\n",
    "        <h3>Summary of Findings:</h3>\n",
    "        <ol>\n",
    "            <li><strong>Best classification model: {best_model['Model']}</strong> with {best_model['Accuracy']:.1%} accuracy</li>\n",
    "            <li><strong>Subject scores are independent</strong> ‚Äî Math, Physics, Chemistry show ~0 correlation</li>\n",
    "            <li><strong>Grade is determined by total/average score</strong>, not by any single subject</li>\n",
    "            <li><strong>Class imbalance</strong> affects prediction of rare grades (A+ and F)</li>\n",
    "            <li><strong>Ensemble methods</strong> (Voting, Stacking) provide robust predictions</li>\n",
    "            <li><strong>Feature engineering</strong> (Total, Average, Min, Max, Range, Std) significantly improves model performance</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "    <div class=\"warning\">\n",
    "        <h3>‚ö†Ô∏è Important Notes:</h3>\n",
    "        <ul>\n",
    "            <li>The 'Comment' column was dropped as it maps 1:1 to Grade (would cause data leakage)</li>\n",
    "            <li>All students are from the same school, so school-level variation cannot be analyzed</li>\n",
    "            <li>The grade boundaries appear to be based on total/average score thresholds</li>\n",
    "            <li>With only 3 input features, simpler models often perform comparably to complex ones</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<footer>\n",
    "    <p>üéì Student Performance ML Analysis Report | Generated with Python, Scikit-learn, and ‚ù§Ô∏è</p>\n",
    "    <p>Models: Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, SVM, KNN,\n",
    "       Naive Bayes, MLP, Voting & Stacking Ensembles</p>\n",
    "</footer>\n",
    "\n",
    "</div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "# Write the HTML report\n",
    "report_path = 'outputs/student_ml_analysis_report.html'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"‚úÖ HTML Report generated: {report_path}\")\n",
    "print(f\"   File size: {os.path.getsize(report_path) / 1024:.1f} KB\")\n",
    "print(f\"   Embedded images: {len(report_images)}\")\n",
    "print(f\"\\nüéâ Analysis complete! Open the HTML file in a browser to view the full report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
