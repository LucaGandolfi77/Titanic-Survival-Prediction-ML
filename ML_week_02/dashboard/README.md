# Explainable AI Dashboard

Production-ready **Streamlit** dashboard for model interpretability, fairness analysis, and automated reporting.

## Features

| Stage | Capabilities |
|-------|-------------|
| **ğŸ  Overview** | Load datasets (built-in or upload), train/load models, performance metrics |
| **ğŸŒ Global Explanations** | SHAP importance, beeswarm plots, dependence plots, feature interactions (H-statistic), PDP/ICE |
| **ğŸ”¬ Local Explanations** | SHAP waterfall & force plots, LIME explanations, what-if analysis, counterfactual search, SHAP vs LIME comparison |
| **âš–ï¸ Fairness Analysis** | Demographic parity, equal opportunity, disparate impact (80% rule), equalized odds, bias heatmaps, mitigation recommendations, threshold optimisation, re-weighting |
| **ğŸ“Š Reports** | Executive summary (HTML), technical report (HTML/TXT), one-click download |

## Tech Stack

- **Streamlit 1.30+** â€” dashboard framework
- **SHAP 0.44+** â€” global & local model explanations
- **LIME 0.2+** â€” alternative local explanations
- **Fairlearn 0.9+** â€” fairness metrics & bias detection
- **scikit-learn / XGBoost / LightGBM / CatBoost** â€” model support
- **Plotly** â€” interactive visualisations
- **Jinja2** â€” HTML report templating


## Quick Start

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Generate sample datasets & pre-trained models
python _generate.py

# 3. Run the dashboard
streamlit run app.py --server.port 8502

# 4. Run tests
pytest tests/ -v
```

Or with Makefile:
```bash
make install
make generate
make run
make test
```

Or with Docker:
```bash
docker build -t xai-dashboard .
docker run -p 8502:8502 xai-dashboard
```


## Project Structure

```
dashboard/
â”œâ”€â”€ app.py                          # Main entry point
â”œâ”€â”€ _generate.py                    # Generate sample data & models
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Makefile
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .streamlit/config.toml
â”œâ”€â”€ config/dashboard_config.yaml
â”œâ”€â”€ assets/styles.css
â”‚
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_overview.py               # Data & model setup
â”‚   â”œâ”€â”€ 2_global_explanations.py    # SHAP global analysis
â”‚   â”œâ”€â”€ 3_local_explanations.py     # SHAP + LIME local
â”‚   â”œâ”€â”€ 4_fairness_analysis.py      # Bias detection & mitigation
â”‚   â””â”€â”€ 5_reports.py                # Report generation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ loader.py               # Load/save models
â”‚   â”‚   â”œâ”€â”€ predictor.py            # Unified prediction wrapper
â”‚   â”‚   â””â”€â”€ metadata.py             # Model info & metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ explainability/
â”‚   â”‚   â”œâ”€â”€ shap_explainer.py       # SHAP (auto algorithm selection)
â”‚   â”‚   â”œâ”€â”€ lime_explainer.py       # LIME wrapper
â”‚   â”‚   â”œâ”€â”€ pdp.py                  # Partial dependence & ICE
â”‚   â”‚   â”œâ”€â”€ counterfactuals.py      # What-if & counterfactual search
â”‚   â”‚   â””â”€â”€ feature_interactions.py # H-statistic interactions
â”‚   â”‚
â”‚   â”œâ”€â”€ fairness/
â”‚   â”‚   â”œâ”€â”€ metrics.py              # DP, EO, DI, EOd metrics
â”‚   â”‚   â”œâ”€â”€ bias_detector.py        # Auto bias scan (PASS/WARN/FAIL)
â”‚   â”‚   â””â”€â”€ mitigation.py           # Re-weighting, threshold optimisation
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ shap_plots.py           # SHAP-specific Plotly charts
â”‚   â”‚   â”œâ”€â”€ lime_plots.py           # LIME charts
â”‚   â”‚   â”œâ”€â”€ fairness_plots.py       # Fairness charts & gauges
â”‚   â”‚   â””â”€â”€ custom_plots.py         # General plots (CM, ROC, radar, etc.)
â”‚   â”‚
â”‚   â”œâ”€â”€ reporting/
â”‚   â”‚   â”œâ”€â”€ summary_generator.py    # Build report data dicts
â”‚   â”‚   â”œâ”€â”€ pdf_exporter.py         # HTML rendering & PDF export
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â”œâ”€â”€ executive_summary.html
â”‚   â”‚       â””â”€â”€ technical_report.html
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py          # Dataset loading & preparation
â”‚       â”œâ”€â”€ session_state.py        # Streamlit state management
â”‚       â””â”€â”€ helpers.py              # Config, detection, colour helpers
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ credit_risk_sample.csv      # Generated sample dataset
â”‚   â”œâ”€â”€ medical_sample.csv          # Generated sample dataset
â”‚   â””â”€â”€ protected_attributes.json   # Protected attribute definitions
â”‚
â”œâ”€â”€ models/                         # Pre-trained model .pkl files
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_explainability.py
â”‚   â”œâ”€â”€ test_fairness.py
â”‚   â””â”€â”€ test_reporting.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb           # Interactive exploration notebook
â”‚
â””â”€â”€ outputs/reports/                # Generated reports
```


## Supported Models

| Framework | Types |
|-----------|-------|
| scikit-learn | RandomForest, GradientBoosting, LogisticRegression, SVM, DecisionTree, k-NN, MLP, AdaBoost |
| XGBoost | XGBClassifier, XGBRegressor |
| LightGBM | LGBMClassifier, LGBMRegressor |
| CatBoost | CatBoostClassifier, CatBoostRegressor |

SHAP automatically selects the appropriate explainer (Tree/Linear/Kernel) based on the model type.


## Fairness Metrics

| Metric | Threshold | Description |
|--------|-----------|-------------|
| Demographic Parity Difference | â‰¤ 0.10 | Difference in positive prediction rates |
| Equal Opportunity Difference | â‰¤ 0.10 | Difference in true positive rates |
| Disparate Impact Ratio | â‰¥ 0.80 | 80% rule (EEOC) |
| Equalised Odds Difference | â‰¤ 0.10 | Max of TPR and FPR differences |


## Configuration

Edit `config/dashboard_config.yaml` to customise:
- SHAP background samples and max display features
- LIME number of features and kernel width
- PDP grid resolution
- Fairness thresholds
- Report output directory


## License

MIT
