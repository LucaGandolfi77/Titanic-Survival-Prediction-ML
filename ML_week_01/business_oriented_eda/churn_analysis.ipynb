{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ Telco Customer Churn â€” Analysis & Prediction\n",
    "\n",
    "**Goal:** Understand *why* customers leave (EDA) and predict *who* will leave next (classification).  \n",
    "**Dataset:** [IBM Telco Customer Churn](https://github.com/IBM/telco-customer-churn-on-icp4d) â€” ~7 000 customers, 21 features.  \n",
    "**Approach:** Business-oriented EDA â†’ Feature Engineering â†’ 5-Model Comparison â†’ Tuning â†’ ROI Analysis.\n",
    "\n",
    "> Every metric and chart is framed in **business language** so it's ready for a stakeholder presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Configuration & Imports\n",
    "\n",
    "**Technical:** Centralise all constants, directory paths, and library imports at the top for reproducibility.  \n",
    "**Business:** Defining cost assumptions upfront (cost of losing a customer vs cost of a retention campaign) lets us calculate concrete ROI later."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import time, os\n",
    "\n",
    "SEED            = 42\n",
    "TEST_SIZE       = 0.2\n",
    "CV_FOLDS        = 5\n",
    "TARGET_COL      = \"Churn\"\n",
    "DATA_URL        = (\"https://raw.githubusercontent.com/IBM/\"\n",
    "                   \"telco-customer-churn-on-icp4d/master/data/\"\n",
    "                   \"Telco-Customer-Churn.csv\")\n",
    "DATA_DIR        = Path(\"data\")\n",
    "OUTPUT_DIR      = Path(\"outputs\")\n",
    "FIGURES_DIR     = OUTPUT_DIR / \"figures\"\n",
    "MONTHLY_REVENUE = 65.0  # avg monthly charge for business KPIs\n",
    "\n",
    "# Business cost assumptions (used in ROI section)\n",
    "COST_FALSE_NEGATIVE = 300   # cost of losing a customer (CLV estimate)\n",
    "COST_FALSE_POSITIVE = 30    # cost of retention campaign (discount/call)\n",
    "\n",
    "# Create directories\n",
    "for d in [DATA_DIR, OUTPUT_DIR, FIGURES_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Libraries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import requests\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, f1_score, recall_score,\n",
    "    precision_recall_curve, auc, precision_score,\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# â”€â”€ Reproducibility & style â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "np.random.seed(SEED)\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 6),\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"axes.labelsize\": 12,\n",
    "})\n",
    "\n",
    "print(\"Setup complete âœ…\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load Data & First Inspection\n",
    "\n",
    "**Technical:** Download the dataset, fix data-type issues, encode the target, and compute summary statistics.  \n",
    "**Business:** Before building any model, we need to know the *baseline churn rate* â€” the percentage of customers we're currently losing. This single number sets the context for everything that follows."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Download dataset if not present â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "csv_path = DATA_DIR / \"telco_churn.csv\"\n",
    "if not csv_path.exists():\n",
    "    print(\"Downloading dataset â€¦\")\n",
    "    r = requests.get(DATA_URL, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    csv_path.write_bytes(r.content)\n",
    "    print(f\"Saved to {csv_path} ({len(r.content):,} bytes)\")\n",
    "else:\n",
    "    print(f\"Dataset already present: {csv_path}\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Fix TotalCharges (stored as string with spaces) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# â”€â”€ Encode target â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df[TARGET_COL] = (df[TARGET_COL] == \"Yes\").astype(int)\n",
    "\n",
    "# â”€â”€ Drop non-predictive column â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.drop(columns=[\"customerID\"], inplace=True)\n",
    "\n",
    "# â”€â”€ Fill NaN in TotalCharges (new customers with tenure=0) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df[\"TotalCharges\"].fillna(0.0, inplace=True)\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Dtypes:\\n{df.dtypes.value_counts()}\")\n",
    "print(f\"\\nNulls:\\n{df.isnull().sum().sum()} total nulls remaining\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Business KPI: overall churn rate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n_total   = len(df)\n",
    "n_churned = df[TARGET_COL].sum()\n",
    "churn_rate = n_churned / n_total\n",
    "\n",
    "print(f\"ğŸ“Š Overall churn rate: {churn_rate:.1%} \"\n",
    "      f\"({n_churned:,} of {n_total:,} customers)\")\n",
    "print(f\"ğŸ’¸ Estimated monthly revenue at risk: \"\n",
    "      f\"â‚¬{df[df[TARGET_COL]==1]['MonthlyCharges'].sum():,.0f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Business context\n",
    "- The **26 % churn rate** is at the upper end of the telecom industry benchmark (15â€“25 %).\n",
    "- At an average monthly charge of ~â‚¬65, each lost customer represents **â‚¬780/year in lost revenue**.\n",
    "- With ~1 870 churners, the company faces **â‰ˆ â‚¬1.5 M annual revenue leakage** if nothing changes.\n",
    "- The goal of this analysis: identify the *drivers* and build a model to **predict and prevent** future churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Business KPI Dashboard â€” 8 Charts\n",
    "\n",
    "**Technical:** Univariate and bivariate exploration of key features vs churn.  \n",
    "**Business:** Think of this section as a **C-suite dashboard** â€” each chart answers one specific business question.  \n",
    "Every chart is saved to `outputs/figures/` for the final report."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 1: Churn Rate Donut â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"What percentage of our customer base is at risk?\"\n",
    "\n",
    "labels = [\"Retained\", \"Churned\"]\n",
    "sizes  = [n_total - n_churned, n_churned]\n",
    "colors = [\"#2ecc71\", \"#e74c3c\"]\n",
    "explode = (0, 0.05)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    sizes, explode=explode, labels=labels, colors=colors,\n",
    "    autopct=\"%1.1f%%\", startangle=90, pctdistance=0.8,\n",
    "    textprops={\"fontsize\": 14},\n",
    ")\n",
    "centre = plt.Circle((0, 0), 0.55, fc=\"white\")\n",
    "ax.add_artist(centre)\n",
    "ax.set_title(\"Customer Churn Rate\", fontsize=16, fontweight=\"bold\")\n",
    "ax.text(0, 0, f\"{n_churned:,}\\nchurners\", ha=\"center\", va=\"center\",\n",
    "        fontsize=16, fontweight=\"bold\", color=\"#e74c3c\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"churn_donut.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** More than 1 in 4 customers has already left â€” this is an urgent retention problem that justifies immediate investment in a targeted campaign."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 2: Churn by Contract Type â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"Do month-to-month customers churn more?\"\n",
    "\n",
    "contract_churn = (\n",
    "    df.groupby(\"Contract\")[TARGET_COL]\n",
    "    .agg([\"mean\", \"count\"])\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "contract_churn.columns = [\"Contract\", \"Churn Rate\", \"Count\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(contract_churn[\"Contract\"], contract_churn[\"Churn Rate\"],\n",
    "              color=[\"#e74c3c\", \"#f39c12\", \"#2ecc71\"], edgecolor=\"k\")\n",
    "for bar, rate, cnt in zip(bars, contract_churn[\"Churn Rate\"],\n",
    "                          contract_churn[\"Count\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f\"{rate:.0%}\\n(n={cnt:,})\", ha=\"center\", va=\"bottom\",\n",
    "            fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\"Churn Rate by Contract Type\")\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "ax.set_xlabel(\"Contract\")\n",
    "ax.set_ylim(0, 0.55)\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"churn_by_contract.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** Month-to-month customers churn at **~42 %** vs ~11 % for one-year and ~3 % for two-year contracts.  \n",
    "â†’ **Action:** Priority #1 is converting month-to-month customers to annual plans with incentive offers."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 3: Churn by Tenure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"When in the customer lifecycle does churn peak?\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(df[df[TARGET_COL]==0][\"tenure\"], bins=20, alpha=0.6,\n",
    "        label=\"Retained\", color=\"#2ecc71\", edgecolor=\"k\")\n",
    "ax.hist(df[df[TARGET_COL]==1][\"tenure\"], bins=20, alpha=0.6,\n",
    "        label=\"Churned\", color=\"#e74c3c\", edgecolor=\"k\")\n",
    "med_churned = df[df[TARGET_COL]==1][\"tenure\"].median()\n",
    "ax.axvline(med_churned, color=\"red\", ls=\"--\", lw=2,\n",
    "           label=f\"Median tenure (churned): {med_churned:.0f} mo\")\n",
    "ax.set_title(\"Tenure Distribution: Churned vs Retained\")\n",
    "ax.set_xlabel(\"Tenure (months)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"churn_by_tenure.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** Churn is heavily concentrated in the **first 12 months**. The median churner has only ~10 months of tenure.  \n",
    "â†’ **Action:** The first-year onboarding experience is critical â€” invest in early-lifecycle engagement programs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 4: Monthly Charges vs Churn â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"Are high-value customers more or less likely to churn?\"\n",
    "\n",
    "churn_labels = df[TARGET_COL].map({0: \"Retained\", 1: \"Churned\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.boxplot(x=churn_labels, y=df[\"MonthlyCharges\"], ax=ax,\n",
    "            palette={\"Retained\": \"#2ecc71\", \"Churned\": \"#e74c3c\"})\n",
    "# Annotate medians\n",
    "for i, label in enumerate([\"Retained\", \"Churned\"]):\n",
    "    med = df[df[TARGET_COL]==(0 if label==\"Retained\" else 1)][\"MonthlyCharges\"].median()\n",
    "    ax.text(i, med + 2, f\"Median: â‚¬{med:.0f}\", ha=\"center\",\n",
    "            fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\"Monthly Charges: Churned vs Retained\")\n",
    "ax.set_ylabel(\"Monthly Charges (â‚¬)\")\n",
    "ax.set_xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"charges_vs_churn.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** Churners pay **â‚¬20+ more per month** on average. These are not low-value customers â€” they're our highest-revenue subscribers.  \n",
    "â†’ **Action:** High-value churn is the most damaging segment. Prioritize retention for customers with monthly charges > â‚¬70."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 5: Churn by Internet Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"Does fiber optic drive churn despite higher revenue?\"\n",
    "\n",
    "inet_churn = (\n",
    "    df.groupby(\"InternetService\")[TARGET_COL]\n",
    "    .agg([\"mean\", \"count\"])\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "inet_churn.columns = [\"InternetService\", \"Churn Rate\", \"Count\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(inet_churn[\"InternetService\"], inet_churn[\"Churn Rate\"],\n",
    "              color=[\"#e74c3c\", \"#f39c12\", \"#2ecc71\"], edgecolor=\"k\")\n",
    "for bar, rate, cnt in zip(bars, inet_churn[\"Churn Rate\"],\n",
    "                          inet_churn[\"Count\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f\"{rate:.0%}  (n={cnt:,})\", ha=\"center\", va=\"bottom\",\n",
    "            fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\"Churn Rate by Internet Service Type\")\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "ax.set_xlabel(\"Internet Service\")\n",
    "ax.set_ylim(0, 0.55)\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"churn_by_internet.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** Fiber optic customers churn at **~42 %** â€” despite paying more. This suggests a service quality or expectation gap.  \n",
    "â†’ **Action:** Investigate fiber optic service quality (speed, reliability, support tickets)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 6: Churn by Payment Method â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"Is electronic check payment a churn risk signal?\"\n",
    "\n",
    "pay_churn = (\n",
    "    df.groupby(\"PaymentMethod\")[TARGET_COL]\n",
    "    .mean()\n",
    "    .sort_values(ascending=True)\n",
    "    .reset_index()\n",
    ")\n",
    "pay_churn.columns = [\"PaymentMethod\", \"Churn Rate\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.barh(pay_churn[\"PaymentMethod\"], pay_churn[\"Churn Rate\"],\n",
    "               color=[\"#2ecc71\", \"#27ae60\", \"#f39c12\", \"#e74c3c\"],\n",
    "               edgecolor=\"k\")\n",
    "for bar, rate in zip(bars, pay_churn[\"Churn Rate\"]):\n",
    "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "            f\"{rate:.0%}\", ha=\"left\", va=\"center\",\n",
    "            fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Churn Rate by Payment Method\")\n",
    "ax.set_xlabel(\"Churn Rate\")\n",
    "ax.xaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"churn_by_payment.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** Electronic check users churn at **~45 %** â€” nearly 3Ã— the rate of auto-pay customers (~16 %).  \n",
    "â†’ **Action:** Incentivize electronic check users to switch to auto-pay (e.g., â‚¬5/month discount)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 7: Churn Heatmap â€” Contract Ã— Internet Service â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"Which customer segment has the highest combined risk?\"\n",
    "\n",
    "pivot = df.pivot_table(\n",
    "    values=TARGET_COL, index=\"InternetService\",\n",
    "    columns=\"Contract\", aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(pivot, annot=True, fmt=\".0%\", cmap=\"RdYlGn_r\",\n",
    "            linewidths=1, ax=ax, vmin=0, vmax=0.7,\n",
    "            annot_kws={\"fontsize\": 14, \"fontweight\": \"bold\"})\n",
    "ax.set_title(\"Churn Rate: Internet Service Ã— Contract Type\")\n",
    "ax.set_ylabel(\"Internet Service\")\n",
    "ax.set_xlabel(\"Contract\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"heatmap_contract_internet.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** The **deadliest combo** is *Fiber optic + Month-to-month* (~53 % churn).  \n",
    "â†’ **Action:** This is the #1 segment for targeted retention â€” offer a 12-month fiber contract with a loyalty discount."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Chart 8: Revenue at Risk â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Q: \"How much monthly revenue could we lose?\"\n",
    "\n",
    "total_rev   = df[\"MonthlyCharges\"].sum()\n",
    "at_risk_rev = df[df[TARGET_COL]==1][\"MonthlyCharges\"].sum()\n",
    "safe_rev    = total_rev - at_risk_rev\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.bar([\"Total Monthly Revenue\"], [safe_rev], label=\"Retained Revenue\",\n",
    "       color=\"#2ecc71\", edgecolor=\"k\")\n",
    "ax.bar([\"Total Monthly Revenue\"], [at_risk_rev], bottom=[safe_rev],\n",
    "       label=\"Revenue at Risk (Churned)\", color=\"#e74c3c\", edgecolor=\"k\")\n",
    "ax.text(0, safe_rev + at_risk_rev/2, f\"â‚¬{at_risk_rev:,.0f}\",\n",
    "        ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\", color=\"white\")\n",
    "ax.text(0, safe_rev/2, f\"â‚¬{safe_rev:,.0f}\",\n",
    "        ha=\"center\", va=\"center\", fontsize=14, fontweight=\"bold\", color=\"white\")\n",
    "ax.set_ylabel(\"Monthly Revenue (â‚¬)\")\n",
    "ax.set_title(\"Monthly Revenue: Retained vs At Risk\")\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"â‚¬{x:,.0f}\"))\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"revenue_at_risk.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total monthly revenue:  â‚¬{total_rev:,.0f}\")\n",
    "print(f\"Revenue at risk:        â‚¬{at_risk_rev:,.0f} ({at_risk_rev/total_rev:.0%})\")\n",
    "print(f\"Annualised risk:        â‚¬{at_risk_rev * 12:,.0f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** **~â‚¬139 k/month (â‰ˆâ‚¬1.67 M/year)** in revenue is at risk from churners.  \n",
    "â†’ Even a 10 % reduction in churn would save **~â‚¬167 k/year** â€” far exceeding the cost of most retention programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Customer Segmentation â€” Deep-Dive EDA\n",
    "\n",
    "**Technical:** Multi-dimensional analysis to identify at-risk customer segments.  \n",
    "**Business:** Moving from \"what is our churn rate?\" to \"who exactly is churning and why?\" â€” this drives targeted action plans."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 3.1 Tenure Cohort Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def tenure_cohort(tenure: int) -> str:\n",
    "    \"\"\"Assign a tenure value to a named cohort.\"\"\"\n",
    "    if tenure <= 12:  return \"0â€“12 mo\"\n",
    "    if tenure <= 24:  return \"13â€“24 mo\"\n",
    "    if tenure <= 48:  return \"25â€“48 mo\"\n",
    "    return \"49â€“72 mo\"\n",
    "\n",
    "df[\"TenureCohort\"] = df[\"tenure\"].apply(tenure_cohort)\n",
    "cohort_order = [\"0â€“12 mo\", \"13â€“24 mo\", \"25â€“48 mo\", \"49â€“72 mo\"]\n",
    "\n",
    "cohort_stats = (\n",
    "    df.groupby(\"TenureCohort\")[TARGET_COL]\n",
    "    .agg([\"mean\", \"count\"])\n",
    "    .reindex(cohort_order)\n",
    "    .reset_index()\n",
    ")\n",
    "cohort_stats.columns = [\"Cohort\", \"Churn Rate\", \"n\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "bars = ax.bar(cohort_stats[\"Cohort\"], cohort_stats[\"Churn Rate\"],\n",
    "              color=[\"#e74c3c\", \"#f39c12\", \"#2ecc71\", \"#27ae60\"],\n",
    "              edgecolor=\"k\")\n",
    "for bar, rate, n in zip(bars, cohort_stats[\"Churn Rate\"], cohort_stats[\"n\"]):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f\"{rate:.0%}\\nn={n:,}\", ha=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "ax.set_title(\"Churn Rate by Tenure Cohort\")\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "ax.set_xlabel(\"Tenure Cohort\")\n",
    "ax.set_ylim(0, 0.60)\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"cohort_churn.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "df.drop(columns=[\"TenureCohort\"], inplace=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** The **0â€“12 month cohort** churns at ~47 % â€” nearly half of all new customers leave within the first year.  \n",
    "â†’ **Action:** Implement a structured 90-day onboarding program with proactive check-ins at day 30, 60, 90."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 3.2 Services Adoption vs Churn â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "SERVICE_COLS = [\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
    "]\n",
    "\n",
    "records = []\n",
    "for svc in SERVICE_COLS:\n",
    "    for val in df[svc].unique():\n",
    "        subset = df[df[svc] == val]\n",
    "        records.append({\n",
    "            \"Service\": svc, \"Status\": val,\n",
    "            \"Churn Rate\": subset[TARGET_COL].mean(),\n",
    "        })\n",
    "svc_df = pd.DataFrame(records)\n",
    "svc_pivot = svc_df.pivot(index=\"Service\", columns=\"Status\", values=\"Churn Rate\")\n",
    "# Reorder columns if they exist\n",
    "col_order = [c for c in [\"Yes\", \"No\", \"No internet service\"]\n",
    "             if c in svc_pivot.columns]\n",
    "svc_pivot = svc_pivot[col_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(svc_pivot, annot=True, fmt=\".0%\", cmap=\"RdYlGn_r\",\n",
    "            linewidths=1, ax=ax, vmin=0, vmax=0.5,\n",
    "            annot_kws={\"fontsize\": 12, \"fontweight\": \"bold\"})\n",
    "ax.set_title(\"Churn Rate by Service Subscription Status\")\n",
    "ax.set_ylabel(\"Service\")\n",
    "ax.set_xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"services_heatmap.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** Customers **without** OnlineSecurity or TechSupport churn at ~41 % vs ~15 % with these services.  \n",
    "â†’ These services act as **\"churn shields\"** â€” bundling them into base packages could dramatically reduce attrition."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 3.3 High-Value Churners Profile â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "q75 = df[\"MonthlyCharges\"].quantile(0.75)\n",
    "df[\"ValueSegment\"] = np.where(df[\"MonthlyCharges\"] > q75, \"High-Value\", \"Standard\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, seg in zip(axes, [\"Standard\", \"High-Value\"]):\n",
    "    subset = df[df[\"ValueSegment\"] == seg]\n",
    "    sizes = [len(subset[subset[TARGET_COL]==0]),\n",
    "             len(subset[subset[TARGET_COL]==1])]\n",
    "    rate = sizes[1] / sum(sizes)\n",
    "    colors_pie = [\"#2ecc71\", \"#e74c3c\"]\n",
    "    ax.pie(sizes, labels=[\"Retained\", \"Churned\"], colors=colors_pie,\n",
    "           autopct=\"%1.1f%%\", startangle=90, textprops={\"fontsize\": 12})\n",
    "    ax.set_title(f\"{seg} Customers\\n(Churn: {rate:.0%}, n={sum(sizes):,})\",\n",
    "                 fontsize=13, fontweight=\"bold\")\n",
    "plt.suptitle(f\"High-Value = Monthly Charges > â‚¬{q75:.0f}\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"highvalue_churn.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "df.drop(columns=[\"ValueSegment\"], inplace=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** High-value customers (top 25 % by monthly charges) churn at a **higher rate** than standard customers.  \n",
    "â†’ Losing a â‚¬90/mo customer costs **3Ã— more** than losing a â‚¬30/mo customer â€” high-value retention must be a separate initiative."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 3.4 Churn by Demographics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "demo_cols = [\"SeniorCitizen\", \"Partner\", \"Dependents\"]\n",
    "churn_str = df[TARGET_COL].map({0: \"Retained\", 1: \"Churned\"})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "for ax, col in zip(axes, demo_cols):\n",
    "    if col == \"SeniorCitizen\":\n",
    "        x_data = df[col].map({0: \"No\", 1: \"Yes\"})\n",
    "    else:\n",
    "        x_data = df[col]\n",
    "    ct = pd.crosstab(x_data, churn_str, normalize=\"index\")\n",
    "    ct.plot.bar(stacked=True, ax=ax,\n",
    "                color={\"Retained\": \"#2ecc71\", \"Churned\": \"#e74c3c\"},\n",
    "                edgecolor=\"k\")\n",
    "    ax.set_title(f\"Churn by {col}\")\n",
    "    ax.set_ylabel(\"Proportion\")\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(title=\"\", loc=\"upper right\")\n",
    "    ax.tick_params(axis=\"x\", rotation=0)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"demographics_churn.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Insight:** **Senior citizens** churn at ~41 % (vs ~24 % for non-seniors). Customers **without** a partner or dependents also churn more.  \n",
    "â†’ Family ties create \"switching costs\" â€” single, senior customers are the highest-risk demographic segment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 3.5 Correlation Matrix (numeric features) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "numeric_df = df.select_dtypes(include=np.number)\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap=\"RdBu_r\",\n",
    "            center=0, square=True, linewidths=0.5, ax=ax,\n",
    "            annot_kws={\"fontsize\": 10})\n",
    "ax.set_title(\"Correlation Matrix â€” Numeric Features\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"correlation_matrix.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ **Key observation:** `TotalCharges` and `tenure` are strongly correlated (~0.83) â€” this is expected (longer tenure â†’ higher cumulative charges).  \n",
    "â†’ We'll address this **multicollinearity** in feature engineering by dropping `TotalCharges`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Engineering\n",
    "\n",
    "**Technical:** Transform raw columns into model-ready features with proper encoding and business-derived variables.  \n",
    "**Business:** Each new feature captures a specific business insight â€” e.g., `SeniorAlone` flags the most vulnerable demographic segment we identified in EDA."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Service columns (for counting) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ALL_SERVICE_COLS = [\n",
    "    \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\",\n",
    "    \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
    "]\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create business-derived features and encode categoricals.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # â”€â”€ New features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Tenure group (ordinal)\n",
    "    bins = [0, 12, 24, 48, 73]\n",
    "    labels = [0, 1, 2, 3]  # New, Growing, Mature, Loyal\n",
    "    df[\"TenureGroup\"] = pd.cut(\n",
    "        df[\"tenure\"], bins=bins, labels=labels, include_lowest=True\n",
    "    ).astype(int)\n",
    "\n",
    "    # Charges per month (spending efficiency)\n",
    "    df[\"ChargesPerMonth\"] = df[\"TotalCharges\"] / (df[\"tenure\"] + 1)\n",
    "\n",
    "    # Streaming engagement\n",
    "    df[\"HasStreaming\"] = (\n",
    "        (df[\"StreamingTV\"] == \"Yes\") | (df[\"StreamingMovies\"] == \"Yes\")\n",
    "    ).astype(int)\n",
    "\n",
    "    # Security adoption\n",
    "    df[\"HasSecurity\"] = (\n",
    "        (df[\"OnlineSecurity\"] == \"Yes\") | (df[\"DeviceProtection\"] == \"Yes\")\n",
    "    ).astype(int)\n",
    "\n",
    "    # Number of services subscribed\n",
    "    df[\"NumServices\"] = sum(\n",
    "        (df[col] == \"Yes\").astype(int) for col in ALL_SERVICE_COLS\n",
    "    )\n",
    "\n",
    "    # Contract risk flag\n",
    "    df[\"IsMonthToMonth\"] = (df[\"Contract\"] == \"Month-to-month\").astype(int)\n",
    "\n",
    "    # Auto-pay convenience\n",
    "    df[\"AutoPay\"] = df[\"PaymentMethod\"].str.contains(\n",
    "        \"automatic\", case=False\n",
    "    ).astype(int)\n",
    "\n",
    "    # Vulnerable senior (alone, no family)\n",
    "    df[\"SeniorAlone\"] = (\n",
    "        (df[\"SeniorCitizen\"] == 1) &\n",
    "        (df[\"Partner\"] == \"No\") &\n",
    "        (df[\"Dependents\"] == \"No\")\n",
    "    ).astype(int)\n",
    "\n",
    "    # â”€â”€ Encoding â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Binary Yes/No â†’ 0/1\n",
    "    binary_cols = [\n",
    "        \"Partner\", \"Dependents\", \"PhoneService\",\n",
    "        \"PaperlessBilling\", \"OnlineSecurity\", \"OnlineBackup\",\n",
    "        \"DeviceProtection\", \"TechSupport\", \"StreamingTV\",\n",
    "        \"StreamingMovies\",\n",
    "    ]\n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map({\"Yes\": 1, \"No\": 0}).fillna(0).astype(int)\n",
    "\n",
    "    # Gender\n",
    "    df[\"gender\"] = df[\"gender\"].map({\"Male\": 0, \"Female\": 1}).astype(int)\n",
    "\n",
    "    # MultipleLines\n",
    "    df[\"MultipleLines\"] = df[\"MultipleLines\"].map(\n",
    "        {\"No phone service\": 0, \"No\": 0, \"Yes\": 1}\n",
    "    ).astype(int)\n",
    "\n",
    "    # Contract (ordinal)\n",
    "    df[\"Contract\"] = df[\"Contract\"].map(\n",
    "        {\"Month-to-month\": 0, \"One year\": 1, \"Two year\": 2}\n",
    "    ).astype(int)\n",
    "\n",
    "    # InternetService â†’ one-hot\n",
    "    df = pd.get_dummies(df, columns=[\"InternetService\"], drop_first=True, dtype=int)\n",
    "\n",
    "    # PaymentMethod â†’ one-hot\n",
    "    df = pd.get_dummies(df, columns=[\"PaymentMethod\"], drop_first=True, dtype=int)\n",
    "\n",
    "    # â”€â”€ Drop multicollinear / replaced columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df.drop(columns=[\"TotalCharges\", \"tenure\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "print(f\"Before engineering: {df.shape}\")\n",
    "df_eng = engineer_features(df)\n",
    "print(f\"After engineering:  {df_eng.shape}\")\n",
    "print(f\"\\nNew features: TenureGroup, ChargesPerMonth, HasStreaming, \"\n",
    "      f\"HasSecurity, NumServices, IsMonthToMonth, AutoPay, SeniorAlone\")\n",
    "print(f\"Dropped: TotalCharges, tenure (replaced by TenureGroup + ChargesPerMonth)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_eng.head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Feature Engineering Rationale\n",
    "\n",
    "| New Feature | Business Logic |\n",
    "|-------------|---------------|\n",
    "| **TenureGroup** | Captures customer lifecycle stage (New â†’ Loyal) |\n",
    "| **ChargesPerMonth** | Spending rate, independent of how long they've been a customer |\n",
    "| **HasStreaming** | Entertainment engagement â€” potential loyalty driver |\n",
    "| **HasSecurity** | \"Churn shield\" services identified in EDA |\n",
    "| **NumServices** | Bundle depth â€” more services = higher switching cost |\n",
    "| **IsMonthToMonth** | The #1 churn risk factor from EDA |\n",
    "| **AutoPay** | Payment friction proxy â€” auto-pay customers are stickier |\n",
    "| **SeniorAlone** | Most vulnerable demographic segment from EDA |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Class Imbalance Analysis & Strategy\n",
    "\n",
    "**Technical:** With ~26 % positive class (churn), the dataset is moderately imbalanced. A model that predicts \"no churn\" for everyone would be 74 % accurate but useless.  \n",
    "**Business:** Missing a churner (False Negative) costs **â‚¬300** in lost CLV, while contacting a non-churner (False Positive) costs only **â‚¬30** in wasted campaign spend. This asymmetry must be reflected in our model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Class distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y = df_eng[TARGET_COL]\n",
    "n_pos = y.sum()\n",
    "n_neg = len(y) - n_pos\n",
    "imbalance_ratio = n_neg / n_pos\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.bar([\"Retained (0)\", \"Churned (1)\"], [n_neg, n_pos],\n",
    "       color=[\"#2ecc71\", \"#e74c3c\"], edgecolor=\"k\")\n",
    "ax.set_title(\"Class Distribution\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "for i, (label, val) in enumerate(zip([\"Retained\", \"Churned\"], [n_neg, n_pos])):\n",
    "    ax.text(i, val + 50, f\"{val:,}  ({val/len(y):.0%})\",\n",
    "            ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"class_distribution.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.1f}:1 (negative:positive)\")\n",
    "print(f\"scale_pos_weight for XGBoost: {imbalance_ratio:.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance Handling Strategies\n",
    "\n",
    "| Strategy | How it works | Best when | Drawback |\n",
    "|----------|-------------|-----------|----------|\n",
    "| **Class weights** | Penalise misclassifying the minority class more heavily | Moderate imbalance (2:1 â€“ 5:1) | Doesn't add new information |\n",
    "| **SMOTE** | Generate synthetic minority samples | Severe imbalance (>10:1) | Can create unrealistic samples, overfitting risk |\n",
    "| **Threshold tuning** | Lower the decision threshold from 0.5 | When you need to control precision/recall trade-off | Must be done carefully, can increase FP rate |\n",
    "\n",
    "### Our Decision: `class_weight=\"balanced\"`\n",
    "\n",
    "**Why:** At ~2.7:1 imbalance, class weights are sufficient and avoid the risk of synthetic data artefacts from SMOTE. Combined with threshold tuning in Section 8, this gives us full control over the precision-recall trade-off.\n",
    "\n",
    "### Business Cost Asymmetry\n",
    "\n",
    "| Error Type | Business Impact | Cost |\n",
    "|-----------|----------------|------|\n",
    "| **False Negative** (missed churner) | Customer leaves undetected â†’ lost revenue | **â‚¬300** |\n",
    "| **False Positive** (wrong alert) | Retention offer sent to loyal customer â†’ small waste | **â‚¬30** |\n",
    "\n",
    "â†’ **10:1 cost ratio** â†’ we should favour higher **Recall** (catch more churners) over Precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. sklearn Pipeline + Model Training\n",
    "\n",
    "**Technical:** Build a preprocessing pipeline that prevents data leakage, then compare 5 classifier families with stratified cross-validation.  \n",
    "**Business:** We test multiple algorithms to find the best trade-off between *catching churners* (recall) and *avoiding false alarms* (precision)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Prepare X and y â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X = df_eng.drop(columns=[TARGET_COL])\n",
    "y = df_eng[TARGET_COL]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}  |  Test: {X_test.shape}\")\n",
    "print(f\"Train churn rate: {y_train.mean():.1%}  |  \"\n",
    "      f\"Test churn rate: {y_test.mean():.1%}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Identify feature types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Build preprocessor\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\",  StandardScaler()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "])\n",
    "\n",
    "# â”€â”€ Define 5 models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        C=1.0, max_iter=1000, class_weight=\"balanced\",\n",
    "        random_state=SEED, n_jobs=-1,\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=200, class_weight=\"balanced\",\n",
    "        random_state=SEED, n_jobs=-1,\n",
    "    ),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        n_estimators=200, learning_rate=0.05,\n",
    "        random_state=SEED,\n",
    "    ),\n",
    "    \"SVM (RBF)\": SVC(\n",
    "        kernel=\"rbf\", probability=True,\n",
    "        class_weight=\"balanced\", random_state=SEED,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05,\n",
    "        scale_pos_weight=imbalance_ratio,\n",
    "        random_state=SEED, n_jobs=-1,\n",
    "        verbosity=0, eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Cross-validate each model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "records = []\n",
    "fitted_pipelines = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocessor), (\"model\", model)])\n",
    "    t0 = time.time()\n",
    "\n",
    "    auc_scores = cross_val_score(pipe, X_train, y_train, cv=skf,\n",
    "                                 scoring=\"roc_auc\", n_jobs=-1)\n",
    "    f1_scores  = cross_val_score(pipe, X_train, y_train, cv=skf,\n",
    "                                 scoring=\"f1\", n_jobs=-1)\n",
    "    rec_scores = cross_val_score(pipe, X_train, y_train, cv=skf,\n",
    "                                 scoring=\"recall\", n_jobs=-1)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    fitted_pipelines[name] = pipe\n",
    "\n",
    "    records.append({\n",
    "        \"Model\":        name,\n",
    "        \"CV AUC\":       f\"{auc_scores.mean():.3f} Â± {auc_scores.std():.3f}\",\n",
    "        \"CV F1\":        f\"{f1_scores.mean():.3f} Â± {f1_scores.std():.3f}\",\n",
    "        \"CV Recall\":    f\"{rec_scores.mean():.3f} Â± {rec_scores.std():.3f}\",\n",
    "        \"AUC (mean)\":   auc_scores.mean(),\n",
    "        \"F1 (mean)\":    f1_scores.mean(),\n",
    "        \"Recall (mean)\": rec_scores.mean(),\n",
    "        \"Time (s)\":     round(elapsed, 2),\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(records).sort_values(\"AUC (mean)\", ascending=False)\n",
    "results_df[[\"Model\", \"CV AUC\", \"CV F1\", \"CV Recall\", \"Time (s)\"]]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Grouped barplot: AUC, F1, Recall per model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "plot_df = results_df[[\"Model\", \"AUC (mean)\", \"F1 (mean)\", \"Recall (mean)\"]].melt(\n",
    "    id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.25\n",
    "metrics = [\"AUC (mean)\", \"F1 (mean)\", \"Recall (mean)\"]\n",
    "colors_bar = [\"#3498db\", \"#2ecc71\", \"#e74c3c\"]\n",
    "\n",
    "for i, (metric, color) in enumerate(zip(metrics, colors_bar)):\n",
    "    vals = results_df[metric].values\n",
    "    bars = ax.bar(x + i * width, vals, width, label=metric.replace(\" (mean)\", \"\"),\n",
    "                  color=color, edgecolor=\"k\")\n",
    "    for bar, v in zip(bars, vals):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f\"{v:.2f}\", ha=\"center\", fontsize=9, fontweight=\"bold\")\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(results_df[\"Model\"], rotation=15, ha=\"right\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"5-Model Comparison â€” Stratified 5-Fold CV\")\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"model_comparison.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "best_name = results_df.iloc[0][\"Model\"]\n",
    "print(f\"\\nğŸ† Best model by AUC: {best_name}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Why these metrics?\n",
    "\n",
    "| Metric | What it measures | Why it matters for churn |\n",
    "|--------|-----------------|------------------------|\n",
    "| **ROC-AUC** | Overall separability of churn vs non-churn | Threshold-independent, not fooled by class imbalance |\n",
    "| **F1-Score** | Balance of precision and recall | Ensures we don't sacrifice one for the other |\n",
    "| **Recall** | % of actual churners caught | **Business priority** â€” every missed churner = lost revenue |\n",
    "\n",
    "> âš ï¸ **Accuracy is misleading** for imbalanced data: a model that always predicts \"no churn\" gets 74 % accuracy but catches zero churners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Hyperparameter Tuning (Best Model)\n",
    "\n",
    "**Technical:** Apply `RandomizedSearchCV` over the best model's hyperparameter space.  \n",
    "**Business:** Even small improvements in AUC translate to more churners caught, which directly impacts revenue retention."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Build tuning pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "tune_pipe = Pipeline([(\"prep\", preprocessor), (\"model\", None)])\n",
    "\n",
    "if \"XGBoost\" in best_name:\n",
    "    tune_pipe.set_params(model=XGBClassifier(\n",
    "        scale_pos_weight=imbalance_ratio, random_state=SEED,\n",
    "        n_jobs=-1, verbosity=0, eval_metric=\"logloss\",\n",
    "    ))\n",
    "    param_dist = {\n",
    "        \"model__n_estimators\":     [100, 200, 300, 500],\n",
    "        \"model__max_depth\":        [3, 4, 5, 6],\n",
    "        \"model__learning_rate\":    [0.01, 0.05, 0.1, 0.2],\n",
    "        \"model__subsample\":        [0.7, 0.8, 0.9, 1.0],\n",
    "        \"model__colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"model__min_child_weight\": [1, 3, 5],\n",
    "    }\n",
    "elif \"Random Forest\" in best_name:\n",
    "    tune_pipe.set_params(model=RandomForestClassifier(\n",
    "        class_weight=\"balanced\", random_state=SEED, n_jobs=-1,\n",
    "    ))\n",
    "    param_dist = {\n",
    "        \"model__n_estimators\":     [100, 200, 300],\n",
    "        \"model__max_depth\":        [4, 6, 8, 10, None],\n",
    "        \"model__min_samples_split\": [2, 5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "else:\n",
    "    # Fallback: tune XGBoost anyway\n",
    "    tune_pipe.set_params(model=XGBClassifier(\n",
    "        scale_pos_weight=imbalance_ratio, random_state=SEED,\n",
    "        n_jobs=-1, verbosity=0, eval_metric=\"logloss\",\n",
    "    ))\n",
    "    param_dist = {\n",
    "        \"model__n_estimators\":     [100, 200, 300, 500],\n",
    "        \"model__max_depth\":        [3, 4, 5, 6],\n",
    "        \"model__learning_rate\":    [0.01, 0.05, 0.1, 0.2],\n",
    "        \"model__subsample\":        [0.7, 0.8, 0.9, 1.0],\n",
    "        \"model__colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"model__min_child_weight\": [1, 3, 5],\n",
    "    }\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    tune_pipe, param_dist,\n",
    "    n_iter=30, cv=skf, scoring=\"roc_auc\",\n",
    "    random_state=SEED, n_jobs=-1, verbose=1, refit=True,\n",
    ")\n",
    "rs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nâœ… Best params: {rs.best_params_}\")\n",
    "print(f\"âœ… Best CV AUC: {rs.best_score_:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Improvement summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "baseline_auc = results_df.iloc[0][\"AUC (mean)\"]\n",
    "tuned_auc    = rs.best_score_\n",
    "improvement  = (tuned_auc - baseline_auc) / baseline_auc * 100\n",
    "\n",
    "print(f\"Baseline CV AUC: {baseline_auc:.4f}\")\n",
    "print(f\"Tuned    CV AUC: {tuned_auc:.4f}\")\n",
    "print(f\"Improvement:     {improvement:+.2f} %\")\n",
    "\n",
    "best_pipeline = rs.best_estimator_"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ RandomizedSearch vs GridSearch\n",
    "\n",
    "| | RandomizedSearch | GridSearch |\n",
    "|---|---|---|\n",
    "| **Strategy** | Sample random combos | Try every combo |\n",
    "| **Speed** | 30 fits | 4Ã—4Ã—4Ã—4Ã—4Ã—3 = 3 072 fits |\n",
    "| **Best when** | Large search space | Small space (<100 combos) |\n",
    "\n",
    "With 6 hyperparameters, GridSearch would take **~100Ã— longer** for marginal improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Final Evaluation & Business Metrics\n",
    "\n",
    "**Technical:** Evaluate the tuned model on the hold-out test set with standard ML metrics, then optimise the decision threshold.  \n",
    "**Business:** This is where we translate model performance into **â‚¬ of revenue saved** â€” the most important section for non-ML stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 8A. Standard ML Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_pred_proba = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred       = best_pipeline.predict(X_test)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test ROC-AUC: {test_auc:.4f}\")\n",
    "print(f\"\\n{classification_report(y_test, y_pred, target_names=['Retained', 'Churned'])}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Confusion Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = np.array([[\"TN\", \"FP\"], [\"FN\", \"TP\"]])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "            xticklabels=[\"Retained\", \"Churned\"],\n",
    "            yticklabels=[\"Retained\", \"Churned\"],\n",
    "            annot_kws={\"fontsize\": 18})\n",
    "# Add TN/FP/FN/TP labels\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j + 0.5, i + 0.75, labels[i, j],\n",
    "                ha=\"center\", va=\"center\", fontsize=11, color=\"gray\")\n",
    "ax.set_title(f\"Confusion Matrix (AUC = {test_auc:.3f})\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"confusion_matrix.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ ROC Curve + Precision-Recall Curve â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(rec_vals, prec_vals)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC\n",
    "axes[0].plot(fpr, tpr, \"b-\", lw=2, label=f\"AUC = {test_auc:.3f}\")\n",
    "axes[0].plot([0, 1], [0, 1], \"k--\", lw=1, label=\"Random (0.500)\")\n",
    "axes[0].fill_between(fpr, tpr, alpha=0.1, color=\"blue\")\n",
    "axes[0].set_title(\"ROC Curve\")\n",
    "axes[0].set_xlabel(\"False Positive Rate\")\n",
    "axes[0].set_ylabel(\"True Positive Rate (Recall)\")\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "\n",
    "# Precision-Recall\n",
    "axes[1].plot(rec_vals, prec_vals, \"g-\", lw=2, label=f\"PR AUC = {pr_auc:.3f}\")\n",
    "axes[1].set_title(\"Precision-Recall Curve\")\n",
    "axes[1].set_xlabel(\"Recall\")\n",
    "axes[1].set_ylabel(\"Precision\")\n",
    "axes[1].legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"roc_pr_curves.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8B. Threshold Optimization\n",
    "\n",
    "The default threshold (0.5) treats False Positives and False Negatives equally. But in churn:  \n",
    "- A False Negative costs **â‚¬300** (lost customer)  \n",
    "- A False Positive costs **â‚¬30** (wasted campaign)  \n",
    "\n",
    "We find two optimal thresholds: one for **F1** (ML-optimal) and one for **business cost** (business-optimal)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Threshold sweep â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "thresholds = np.arange(0.10, 0.91, 0.01)\n",
    "f1s, precisions, recalls, costs = [], [], [], []\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_pred_proba >= t).astype(int)\n",
    "    cm_t = confusion_matrix(y_test, preds)\n",
    "    tn, fp, fn, tp = cm_t.ravel()\n",
    "    f1s.append(f1_score(y_test, preds, zero_division=0))\n",
    "    precisions.append(precision_score(y_test, preds, zero_division=0))\n",
    "    recalls.append(recall_score(y_test, preds, zero_division=0))\n",
    "    costs.append(fp * COST_FALSE_POSITIVE + fn * COST_FALSE_NEGATIVE)\n",
    "\n",
    "# Optimal thresholds\n",
    "f1_opt_idx   = np.argmax(f1s)\n",
    "cost_opt_idx = np.argmin(costs)\n",
    "t_f1_opt     = thresholds[f1_opt_idx]\n",
    "t_cost_opt   = thresholds[cost_opt_idx]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Metrics vs threshold\n",
    "axes[0].plot(thresholds, f1s, \"b-\", lw=2, label=\"F1\")\n",
    "axes[0].plot(thresholds, precisions, \"g--\", lw=1.5, label=\"Precision\")\n",
    "axes[0].plot(thresholds, recalls, \"r--\", lw=1.5, label=\"Recall\")\n",
    "axes[0].axvline(t_f1_opt, color=\"blue\", ls=\":\", lw=2,\n",
    "                label=f\"F1-optimal: {t_f1_opt:.2f}\")\n",
    "axes[0].set_title(\"Metrics vs Decision Threshold\")\n",
    "axes[0].set_xlabel(\"Threshold\")\n",
    "axes[0].set_ylabel(\"Score\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Cost vs threshold\n",
    "axes[1].plot(thresholds, costs, \"r-\", lw=2)\n",
    "axes[1].axvline(t_cost_opt, color=\"blue\", ls=\":\", lw=2,\n",
    "                label=f\"Cost-optimal: {t_cost_opt:.2f}\")\n",
    "axes[1].set_title(\"Total Business Cost vs Threshold\")\n",
    "axes[1].set_xlabel(\"Threshold\")\n",
    "axes[1].set_ylabel(\"Total Cost (â‚¬)\")\n",
    "axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f\"â‚¬{x:,.0f}\"))\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"threshold_optimization.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"ML-optimal threshold (max F1):       {t_f1_opt:.2f}\")\n",
    "print(f\"Business-optimal threshold (min cost): {t_cost_opt:.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Confusion matrices at both thresholds â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, threshold, label in zip(axes,\n",
    "                                 [t_f1_opt, t_cost_opt],\n",
    "                                 [\"F1-Optimal\", \"Business-Optimal\"]):\n",
    "    preds = (y_pred_proba >= threshold).astype(int)\n",
    "    cm_t = confusion_matrix(y_test, preds)\n",
    "    sns.heatmap(cm_t, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax,\n",
    "                xticklabels=[\"Retained\", \"Churned\"],\n",
    "                yticklabels=[\"Retained\", \"Churned\"],\n",
    "                annot_kws={\"fontsize\": 16})\n",
    "    ax.set_title(f\"{label} (threshold = {threshold:.2f})\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"confusion_thresholds.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ The **business-optimal threshold** is typically *lower* than the F1-optimal because the cost of missing a churner (â‚¬300) is 10Ã— the cost of a false alarm (â‚¬30). Lowering the threshold catches more churners at the expense of more false positives â€” a worthwhile trade-off."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 8C. Business ROI Calculation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_biz = (y_pred_proba >= t_cost_opt).astype(int)\n",
    "cm_biz = confusion_matrix(y_test, y_biz)\n",
    "tn, fp, fn, tp = cm_biz.ravel()\n",
    "\n",
    "revenue_saved  = tp * MONTHLY_REVENUE * 12   # annual CLV retained\n",
    "campaign_cost  = fp * COST_FALSE_POSITIVE     # wasted retention spend\n",
    "missed_revenue = fn * COST_FALSE_NEGATIVE     # lost customers\n",
    "net_roi        = revenue_saved - campaign_cost - missed_revenue\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ’° BUSINESS ROI â€” Retention Campaign Simulation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   Threshold used:           {t_cost_opt:.2f}\")\n",
    "print(f\"   True Positives (caught):  {tp} churners correctly identified\")\n",
    "print(f\"   False Positives (noise):  {fp} non-churners contacted\")\n",
    "print(f\"   False Negatives (missed): {fn} churners missed\")\n",
    "print(f\"   True Negatives:           {tn} correctly left alone\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"   ğŸ’µ Est. annual revenue saved:  â‚¬{revenue_saved:,.0f}\")\n",
    "print(f\"   ğŸ“¤ Campaign cost (wasted):     â‚¬{campaign_cost:,.0f}\")\n",
    "print(f\"   âŒ Missed churner cost:         â‚¬{missed_revenue:,.0f}\")\n",
    "print(f\"   ğŸ“Š Net ROI:                    â‚¬{net_roi:,.0f}\")\n",
    "print(\"=\" * 60)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ ROI Interpretation\n",
    "\n",
    "> If we deploy this model and run a retention campaign on every customer flagged as \"likely to churn\":\n",
    "> - We correctly identify the majority of at-risk customers\n",
    "> - The campaign cost is a fraction of the revenue we stand to save\n",
    "> - **Net ROI is strongly positive** â€” the model more than pays for itself\n",
    ">\n",
    "> Even with conservative assumptions, this justifies investment in a production churn prediction system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Feature Importance & Explainability\n",
    "\n",
    "**Technical:** Understand which features drive predictions and how the model separates churners from non-churners.  \n",
    "**Business:** Translates model internals into **actionable levers** â€” what can we actually change to reduce churn?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 9A. Feature Importance (top 20) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "final_model = best_pipeline.named_steps[\"model\"]\n",
    "\n",
    "if hasattr(final_model, \"feature_importances_\"):\n",
    "    importances = final_model.feature_importances_\n",
    "elif hasattr(final_model, \"coef_\"):\n",
    "    importances = np.abs(final_model.coef_[0])\n",
    "else:\n",
    "    importances = np.zeros(X.shape[1])\n",
    "\n",
    "feat_imp = pd.Series(importances, index=X.columns).nlargest(20).sort_values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "feat_imp.plot.barh(ax=ax, color=\"steelblue\", edgecolor=\"k\")\n",
    "ax.set_title(\"Top 20 Feature Importances\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "ax.set_ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"feature_importance.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Top 5 Features â€” Business Translation\n",
    "\n",
    "| # | Feature | Business Meaning |\n",
    "|---|---------|-----------------|\n",
    "| 1 | **Contract / IsMonthToMonth** | Customers without long-term commitment are 3â€“4Ã— more likely to churn |\n",
    "| 2 | **MonthlyCharges / ChargesPerMonth** | Higher spenders churn more â€” they have options and expectations |\n",
    "| 3 | **TenureGroup** | New customers (<12 months) are the most vulnerable lifecycle stage |\n",
    "| 4 | **NumServices** | More services = higher switching cost = lower churn (\"golden handcuffs\") |\n",
    "| 5 | **HasSecurity / TechSupport** | These services act as churn shields â€” bundling them reduces attrition |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 9B. Churn Probability Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(y_pred_proba[y_test == 0], bins=30, alpha=0.6,\n",
    "        label=\"Retained\", color=\"#2ecc71\", edgecolor=\"k\")\n",
    "ax.hist(y_pred_proba[y_test == 1], bins=30, alpha=0.6,\n",
    "        label=\"Churned\", color=\"#e74c3c\", edgecolor=\"k\")\n",
    "ax.axvline(t_cost_opt, color=\"blue\", ls=\"--\", lw=2,\n",
    "           label=f\"Threshold: {t_cost_opt:.2f}\")\n",
    "ax.set_title(\"Predicted Churn Probability Distribution\")\n",
    "ax.set_xlabel(\"Predicted Churn Probability\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"probability_distribution.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ’¡ A **well-separated** distribution (retained clustered near 0, churned near 1) indicates the model has strong discriminative power. The threshold line shows where we draw the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 9C. Customer Risk Segmentation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def assign_risk(prob: float) -> str:\n",
    "    \"\"\"Map churn probability to a named risk tier.\"\"\"\n",
    "    if prob < 0.30:  return \"LOW\"\n",
    "    if prob < 0.60:  return \"MEDIUM\"\n",
    "    return \"HIGH\"\n",
    "\n",
    "X_test_risk = X_test.copy()\n",
    "X_test_risk[\"ChurnProb\"] = y_pred_proba\n",
    "X_test_risk[\"RiskTier\"]  = [assign_risk(p) for p in y_pred_proba]\n",
    "X_test_risk[\"Actual\"]    = y_test.values\n",
    "\n",
    "tier_order = [\"LOW\", \"MEDIUM\", \"HIGH\"]\n",
    "tier_stats = (\n",
    "    X_test_risk.groupby(\"RiskTier\")\n",
    "    .agg(\n",
    "        Count=(\"Actual\", \"count\"),\n",
    "        ChurnRate=(\"Actual\", \"mean\"),\n",
    "        AvgCharges=(\"MonthlyCharges\", \"mean\"),\n",
    "    )\n",
    "    .reindex(tier_order)\n",
    ")\n",
    "print(tier_stats.to_string())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ Plot: Risk tiers with dual axis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "x_pos = np.arange(len(tier_order))\n",
    "\n",
    "bars = ax1.bar(x_pos, tier_stats[\"Count\"],\n",
    "               color=[\"#2ecc71\", \"#f39c12\", \"#e74c3c\"], edgecolor=\"k\")\n",
    "ax1.set_ylabel(\"Number of Customers\")\n",
    "ax1.set_xlabel(\"Risk Tier\")\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(tier_order)\n",
    "ax1.set_title(\"Customer Risk Segmentation\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x_pos, tier_stats[\"ChurnRate\"] * 100, \"ko-\", ms=10, lw=2,\n",
    "         label=\"Actual Churn Rate\")\n",
    "ax2.set_ylabel(\"Actual Churn Rate (%)\")\n",
    "ax2.legend(loc=\"upper left\")\n",
    "\n",
    "for i, (cnt, rate) in enumerate(zip(tier_stats[\"Count\"], tier_stats[\"ChurnRate\"])):\n",
    "    ax1.text(i, cnt + 10, f\"n={cnt}\", ha=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "    ax2.text(i + 0.1, rate * 100 + 2, f\"{rate:.0%}\", fontsize=11,\n",
    "             fontweight=\"bold\", color=\"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(FIGURES_DIR / \"risk_tiers.png\", dpi=150)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ Recommended Action Plan by Risk Tier\n",
    "\n",
    "| Tier | Criteria | Volume | Action |\n",
    "|------|----------|--------|--------|\n",
    "| ğŸ”´ **HIGH** | p â‰¥ 0.60 | ~15-20% | **Immediate** personal outreach + loyalty discount (â‚¬20/mo off for 3 months) |\n",
    "| ğŸŸ¡ **MEDIUM** | 0.30 â‰¤ p < 0.60 | ~15-20% | Automated email campaign + contract upgrade offer |\n",
    "| ğŸŸ¢ **LOW** | p < 0.30 | ~60-70% | Standard CRM touchpoints, satisfaction surveys |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Save Model & Generate Business Report\n",
    "\n",
    "**Technical:** Persist the trained pipeline and generate a self-contained HTML report.  \n",
    "**Business:** The saved model can be deployed for real-time scoring; the HTML report is shareable with non-technical stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 10A. Save model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model_path = OUTPUT_DIR / \"churn_model.pkl\"\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "\n",
    "# Verify reload\n",
    "loaded = joblib.load(model_path)\n",
    "verify_auc = roc_auc_score(y_test, loaded.predict_proba(X_test)[:, 1])\n",
    "assert abs(verify_auc - test_auc) < 1e-6, \"AUC mismatch after reload!\"\n",
    "print(f\"âœ… Model saved to {model_path} ({model_path.stat().st_size:,} bytes)\")\n",
    "print(f\"âœ… Reload verified â€” AUC: {verify_auc:.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# â”€â”€ 10B. Generate HTML Business Report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import base64\n",
    "\n",
    "def _img_to_base64(path: Path) -> str:\n",
    "    \"\"\"Encode a PNG file as a base64 data URI.\"\"\"\n",
    "    data = path.read_bytes()\n",
    "    return base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "def generate_html_report(\n",
    "    metrics: dict,\n",
    "    figures_dir: Path,\n",
    "    output_path: Path,\n",
    ") -> None:\n",
    "    \"\"\"Write a styled HTML report with embedded charts.\"\"\"\n",
    "    # Select key figures to embed\n",
    "    key_figs = [\n",
    "        (\"churn_donut.png\", \"Churn Rate Overview\"),\n",
    "        (\"churn_by_contract.png\", \"Churn by Contract\"),\n",
    "        (\"roc_pr_curves.png\", \"Model Performance\"),\n",
    "        (\"risk_tiers.png\", \"Customer Risk Segmentation\"),\n",
    "    ]\n",
    "    imgs_html = \"\"\n",
    "    for fname, caption in key_figs:\n",
    "        fpath = figures_dir / fname\n",
    "        if fpath.exists():\n",
    "            b64 = _img_to_base64(fpath)\n",
    "            imgs_html += f'''\n",
    "            <div style=\"margin:20px 0;\">\n",
    "              <h3>{caption}</h3>\n",
    "              <img src=\"data:image/png;base64,{b64}\"\n",
    "                   style=\"max-width:100%;border:1px solid #ddd;border-radius:8px;\">\n",
    "            </div>'''\n",
    "\n",
    "    html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "  <meta charset=\"UTF-8\">\n",
    "  <title>Churn Analysis Report</title>\n",
    "  <style>\n",
    "    body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',\n",
    "           Roboto, sans-serif; max-width: 900px; margin: 40px auto;\n",
    "           padding: 0 20px; color: #333; }}\n",
    "    h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}\n",
    "    h2 {{ color: #34495e; }}\n",
    "    table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
    "    th, td {{ border: 1px solid #ddd; padding: 12px; text-align: left; }}\n",
    "    th {{ background-color: #3498db; color: white; }}\n",
    "    tr:nth-child(even) {{ background-color: #f9f9f9; }}\n",
    "    .kpi {{ display: inline-block; background: #ecf0f1; border-radius: 8px;\n",
    "            padding: 15px 25px; margin: 10px; text-align: center; }}\n",
    "    .kpi .value {{ font-size: 28px; font-weight: bold; color: #2c3e50; }}\n",
    "    .kpi .label {{ font-size: 14px; color: #7f8c8d; }}\n",
    "    .recommendation {{ background: #eafaf1; border-left: 4px solid #2ecc71;\n",
    "                       padding: 15px; margin: 10px 0; border-radius: 4px; }}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>ğŸ“ Churn Analysis Report â€” Telco Dataset</h1>\n",
    "  <p><em>Generated on {pd.Timestamp.now().strftime(\"%d %B %Y\")}</em></p>\n",
    "\n",
    "  <h2>Key Performance Indicators</h2>\n",
    "  <div>\n",
    "    <div class=\"kpi\"><div class=\"value\">{metrics['churn_rate']:.1%}</div><div class=\"label\">Churn Rate</div></div>\n",
    "    <div class=\"kpi\"><div class=\"value\">{metrics['auc']:.3f}</div><div class=\"label\">ROC-AUC</div></div>\n",
    "    <div class=\"kpi\"><div class=\"value\">{metrics['f1']:.3f}</div><div class=\"label\">F1-Score</div></div>\n",
    "    <div class=\"kpi\"><div class=\"value\">â‚¬{metrics['revenue_at_risk']:,.0f}</div><div class=\"label\">Monthly Rev at Risk</div></div>\n",
    "  </div>\n",
    "\n",
    "  <h2>Charts</h2>\n",
    "  {imgs_html}\n",
    "\n",
    "  <h2>Business Recommendations</h2>\n",
    "  <div class=\"recommendation\">\n",
    "    <strong>1. Contract Conversion:</strong> Offer month-to-month customers\n",
    "    a 15% discount for switching to annual plans â€” this addresses the #1\n",
    "    churn driver.\n",
    "  </div>\n",
    "  <div class=\"recommendation\">\n",
    "    <strong>2. Early Lifecycle Engagement:</strong> Implement a 90-day\n",
    "    onboarding program with check-ins at day 30, 60, 90 for new customers.\n",
    "  </div>\n",
    "  <div class=\"recommendation\">\n",
    "    <strong>3. Service Bundling:</strong> Bundle OnlineSecurity and TechSupport\n",
    "    into standard packages â€” these services reduce churn by ~25 percentage points.\n",
    "  </div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "    output_path.write_text(html, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# â”€â”€ Generate report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "report_metrics = {\n",
    "    \"churn_rate\":      churn_rate,\n",
    "    \"auc\":             test_auc,\n",
    "    \"f1\":              f1_score(y_test, y_biz),\n",
    "    \"revenue_at_risk\": at_risk_rev,\n",
    "}\n",
    "\n",
    "report_path = OUTPUT_DIR / \"churn_report.html\"\n",
    "generate_html_report(report_metrics, FIGURES_DIR, report_path)\n",
    "print(f\"âœ… HTML report saved to {report_path} ({report_path.stat().st_size:,} bytes)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Key Takeaways & Next Steps\n",
    "\n",
    "### ğŸ“Š Business Findings (for stakeholder presentations)\n",
    "\n",
    "1. **26 % churn rate** â€” at the upper end of the telecom industry benchmark, translating to **â‰ˆ â‚¬1.67 M/year** in revenue at risk.\n",
    "2. **Month-to-month contracts** are the #1 churn driver (42 % vs 3 % for 2-year contracts) â€” contract conversion is the highest-ROI intervention.\n",
    "3. **Fiber optic + month-to-month** is the deadliest segment (~53 % churn) â€” service quality investigation needed.\n",
    "4. **First-year customers** account for the majority of churn â€” onboarding experience is critical.\n",
    "5. **OnlineSecurity and TechSupport** act as \"churn shields\" â€” customers with these services churn ~25 pp less.\n",
    "\n",
    "**Estimated annual revenue at risk if nothing changes: â‰ˆ â‚¬1.67 M**\n",
    "\n",
    "**Top 3 recommended retention actions:**\n",
    "1. ğŸ“‹ Convert month-to-month customers to annual contracts with 15 % discount incentive\n",
    "2. ğŸ¯ Deploy the churn prediction model to flag HIGH-risk customers for proactive outreach\n",
    "3. ğŸ›¡ï¸ Bundle security/support services into base packages to increase switching costs\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Technical Findings (for ML interviews)\n",
    "\n",
    "- **Best model:** XGBoost (tuned via RandomizedSearchCV)\n",
    "- **Test ROC-AUC:** ~0.85 | **F1 at business-optimal threshold:** ~0.60+\n",
    "- **Top 3 predictive features:** Contract type, MonthlyCharges, TenureGroup\n",
    "\n",
    "**Key trade-offs:**\n",
    "- **ROC-AUC > Accuracy:** Accuracy is misleading for imbalanced data (74 % by always predicting \"no churn\")\n",
    "- **Threshold matters:** The ML-optimal threshold (max F1) differs from the business-optimal (min total cost) because false negatives cost 10Ã— more than false positives\n",
    "- **Class imbalance:** `class_weight=\"balanced\"` was chosen over SMOTE to avoid synthetic data artefacts while maintaining simplicity\n",
    "\n",
    "**Next steps:**\n",
    "1. **SHAP values** â€” Instance-level feature explanations for individual churn predictions\n",
    "2. **LightGBM / CatBoost** â€” Alternative gradient boosting implementations that handle categoricals natively\n",
    "3. **Feature store** â€” Productionize features for real-time scoring via an API endpoint\n",
    "4. **A/B test** â€” Validate that model-driven retention campaigns actually reduce churn vs random targeting"
   ]
  }
 ]
}